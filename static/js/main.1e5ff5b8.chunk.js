(this["webpackJsonpmonaco-editor-nginx"]=this["webpackJsonpmonaco-editor-nginx"]||[]).push([[2],{236:function(e){e.exports=JSON.parse('[{"m":"Core functionality","n":"accept_mutex","d":"If `accept_mutex` is enabled, worker processes will accept new connections by turn. Otherwise, all worker processes will be notified about new connections, and if volume of new connections is low, some of the worker processes may just waste system resources.\\nThere is no need to enable `accept_mutex` on systems that support the [EPOLLEXCLUSIVE](events.html#epoll) flag (1.11.3) or when using [reuseport](http/ngx_http_core_module.html#reuseport).\\n\\nPrior to version 1.11.3, the default value was `on`.\\n"},{"m":"Core functionality","n":"accept_mutex_delay","d":"If [accept\\\\_mutex](#accept_mutex) is enabled, specifies the maximum time during which a worker process will try to restart accepting new connections if another worker process is currently accepting new connections."},{"m":"Core functionality","n":"daemon","d":"Determines whether nginx should become a daemon. Mainly used during development."},{"m":"Core functionality","n":"debug_connection","d":"Enables debugging log for selected client connections. Other connections will use logging level set by the [error\\\\_log](#error_log) directive. Debugged connections are specified by IPv4 or IPv6 (1.3.0, 1.2.1) address or network. A connection may also be specified using a hostname. For connections using UNIX-domain sockets (1.3.0, 1.2.1), debugging log is enabled by the \u201c`unix:`\u201d parameter.\\n```\\nevents {\\n    debug_connection 127.0.0.1;\\n    debug_connection localhost;\\n    debug_connection 192.0.2.0/24;\\n    debug_connection ::1;\\n    debug_connection 2001:0db8::/32;\\n    debug_connection unix:;\\n    ...\\n}\\n\\n```\\n\\nFor this directive to work, nginx needs to be built with `--with-debug`, see \u201c[A debugging log](debugging_log.html)\u201d.\\n"},{"m":"Core functionality","n":"debug_points","d":"This directive is used for debugging.\\nWhen internal error is detected, e.g. the leak of sockets on restart of working processes, enabling `debug_points` leads to a core file creation (`abort`) or to stopping of a process (`stop`) for further analysis using a system debugger."},{"m":"Core functionality","n":"env","d":"By default, nginx removes all environment variables inherited from its parent process except the TZ variable. This directive allows preserving some of the inherited variables, changing their values, or creating new environment variables. These variables are then:\\n*   inherited during a [live upgrade](control.html#upgrade) of an executable file;\\n*   used by the [ngx\\\\_http\\\\_perl\\\\_module](http/ngx_http_perl_module.html) module;\\n*   used by worker processes. One should bear in mind that controlling system libraries in this way is not always possible as it is common for libraries to check variables only during initialization, well before they can be set using this directive. An exception from this is an above mentioned [live upgrade](control.html#upgrade) of an executable file.\\n\\nThe TZ variable is always inherited and available to the [ngx\\\\_http\\\\_perl\\\\_module](http/ngx_http_perl_module.html) module, unless it is configured explicitly.\\nUsage example:\\n```\\nenv MALLOC_OPTIONS;\\nenv PERL5LIB=/data/site/modules;\\nenv OPENSSL_ALLOW_PROXY_CERTS=1;\\n\\n```\\n\\n\\nThe NGINX environment variable is used internally by nginx and should not be set directly by the user.\\n"},{"m":"Core functionality","n":"error_log","d":"Configures logging. Several logs can be specified on the same configuration level (1.5.2). If on the `main` configuration level writing a log to a file is not explicitly defined, the default file will be used.\\nThe first parameter defines a `_file_` that will store the log. The special value `stderr` selects the standard error file. Logging to [syslog](syslog.html) can be configured by specifying the \u201c`syslog:`\u201d prefix. Logging to a [cyclic memory buffer](debugging_log.html#memory) can be configured by specifying the \u201c`memory:`\u201d prefix and buffer `_size_`, and is generally used for debugging (1.7.11).\\nThe second parameter determines the `_level_` of logging, and can be one of the following: `debug`, `info`, `notice`, `warn`, `error`, `crit`, `alert`, or `emerg`. Log levels above are listed in the order of increasing severity. Setting a certain log level will cause all messages of the specified and more severe log levels to be logged. For example, the default level `error` will cause `error`, `crit`, `alert`, and `emerg` messages to be logged. If this parameter is omitted then `error` is used.\\nFor `debug` logging to work, nginx needs to be built with `--with-debug`, see \u201c[A debugging log](debugging_log.html)\u201d.\\n\\nThe directive can be specified on the `stream` level starting from version 1.7.11, and on the `mail` level starting from version 1.9.0.\\n"},{"m":"Core functionality","n":"events","d":"Provides the configuration file context in which the directives that affect connection processing are specified."},{"m":"Core functionality","n":"include","d":"Includes another `_file_`, or files matching the specified `_mask_`, into configuration. Included files should consist of syntactically correct directives and blocks.\\nUsage example:\\n```\\ninclude mime.types;\\ninclude vhosts/*.conf;\\n\\n```\\n"},{"m":"Core functionality","n":"load_module","d":"Loads a dynamic module.\\nExample:\\n```\\nload_module modules/ngx_mail_module.so;\\n\\n```\\n"},{"m":"Core functionality","n":"lock_file","d":"nginx uses the locking mechanism to implement [accept\\\\_mutex](#accept_mutex) and serialize access to shared memory. On most systems the locks are implemented using atomic operations, and this directive is ignored. On other systems the \u201clock file\u201d mechanism is used. This directive specifies a prefix for the names of lock files."},{"m":"Core functionality","n":"master_process","d":"Determines whether worker processes are started. This directive is intended for nginx developers."},{"m":"Core functionality","n":"multi_accept","d":"If `multi_accept` is disabled, a worker process will accept one new connection at a time. Otherwise, a worker process will accept all new connections at a time.\\nThe directive is ignored if [kqueue](events.html#kqueue) connection processing method is used, because it reports the number of new connections waiting to be accepted.\\n"},{"m":"Core functionality","n":"pcre_jit","d":"Enables or disables the use of \u201cjust-in-time compilation\u201d (PCRE JIT) for the regular expressions known by the time of configuration parsing.\\nPCRE JIT can speed up processing of regular expressions significantly.\\nThe JIT is available in PCRE libraries starting from version 8.20 built with the `--enable-jit` configuration parameter. When the PCRE library is built with nginx (`--with-pcre=`), the JIT support is enabled via the `--with-pcre-jit` configuration parameter.\\n"},{"m":"Core functionality","n":"pid","d":"Defines a `_file_` that will store the process ID of the main process."},{"m":"Core functionality","n":"ssl_engine","d":"Defines the name of the hardware SSL accelerator."},{"m":"Core functionality","n":"thread_pool","d":"Defines the `_name_` and parameters of a thread pool used for multi-threaded reading and sending of files [without blocking](http/ngx_http_core_module.html#aio) worker processes.\\nThe `threads` parameter defines the number of threads in the pool.\\nIn the event that all threads in the pool are busy, a new task will wait in the queue. The `max_queue` parameter limits the number of tasks allowed to be waiting in the queue. By default, up to 65536 tasks can wait in the queue. When the queue overflows, the task is completed with an error."},{"m":"Core functionality","n":"timer_resolution","d":"Reduces timer resolution in worker processes, thus reducing the number of `gettimeofday()` system calls made. By default, `gettimeofday()` is called each time a kernel event is received. With reduced resolution, `gettimeofday()` is only called once per specified `_interval_`.\\nExample:\\n```\\ntimer_resolution 100ms;\\n\\n```\\n\\nInternal implementation of the interval depends on the method used:\\n*   the `EVFILT_TIMER` filter if `kqueue` is used;\\n*   `timer_create()` if `eventport` is used;\\n*   `setitimer()` otherwise.\\n"},{"m":"Core functionality","n":"use","d":"Specifies the [connection processing](events.html) `_method_` to use. There is normally no need to specify it explicitly, because nginx will by default use the most efficient method."},{"m":"Core functionality","n":"user","d":"Defines `_user_` and `_group_` credentials used by worker processes. If `_group_` is omitted, a group whose name equals that of `_user_` is used."},{"m":"Core functionality","n":"worker_aio_requests","d":"When using [aio](http/ngx_http_core_module.html#aio) with the [epoll](../docs/events.html#epoll) connection processing method, sets the maximum `_number_` of outstanding asynchronous I/O operations for a single worker process."},{"m":"Core functionality","n":"worker_connections","d":"Sets the maximum number of simultaneous connections that can be opened by a worker process.\\nIt should be kept in mind that this number includes all connections (e.g. connections with proxied servers, among others), not only connections with clients. Another consideration is that the actual number of simultaneous connections cannot exceed the current limit on the maximum number of open files, which can be changed by [worker\\\\_rlimit\\\\_nofile](#worker_rlimit_nofile)."},{"m":"Core functionality","n":"worker_cpu_affinity","d":"Binds worker processes to the sets of CPUs. Each CPU set is represented by a bitmask of allowed CPUs. There should be a separate set defined for each of the worker processes. By default, worker processes are not bound to any specific CPUs.\\nFor example,\\n```\\nworker_processes    4;\\nworker_cpu_affinity 0001 0010 0100 1000;\\n\\n```\\nbinds each worker process to a separate CPU, while\\n```\\nworker_processes    2;\\nworker_cpu_affinity 0101 1010;\\n\\n```\\nbinds the first worker process to CPU0/CPU2, and the second worker process to CPU1/CPU3. The second example is suitable for hyper-threading.\\nThe special value `auto` (1.9.10) allows binding worker processes automatically to available CPUs:\\n```\\nworker_processes auto;\\nworker_cpu_affinity auto;\\n\\n```\\nThe optional mask parameter can be used to limit the CPUs available for automatic binding:\\n```\\nworker_cpu_affinity auto 01010101;\\n\\n```\\n\\n\\nThe directive is only available on FreeBSD and Linux.\\n"},{"m":"Core functionality","n":"worker_priority","d":"Defines the scheduling priority for worker processes like it is done by the `nice` command: a negative `_number_` means higher priority. Allowed range normally varies from -20 to 20.\\nExample:\\n```\\nworker_priority -10;\\n\\n```\\n"},{"m":"Core functionality","n":"worker_processes","d":"Defines the number of worker processes.\\nThe optimal value depends on many factors including (but not limited to) the number of CPU cores, the number of hard disk drives that store data, and load pattern. When one is in doubt, setting it to the number of available CPU cores would be a good start (the value \u201c`auto`\u201d will try to autodetect it).\\nThe `auto` parameter is supported starting from versions 1.3.8 and 1.2.5.\\n"},{"m":"Core functionality","n":"worker_rlimit_core","d":"Changes the limit on the largest size of a core file (`RLIMIT_CORE`) for worker processes. Used to increase the limit without restarting the main process."},{"m":"Core functionality","n":"worker_rlimit_nofile","d":"Changes the limit on the maximum number of open files (`RLIMIT_NOFILE`) for worker processes. Used to increase the limit without restarting the main process."},{"m":"Core functionality","n":"worker_shutdown_timeout","d":"Configures a timeout for a graceful shutdown of worker processes. When the `_time_` expires, nginx will try to close all the connections currently open to facilitate shutdown."},{"m":"ngx_http_core_module","n":"absolute_redirect","d":"If disabled, redirects issued by nginx will be relative.\\nSee also [server\\\\_name\\\\_in\\\\_redirect](#server_name_in_redirect) and [port\\\\_in\\\\_redirect](#port_in_redirect) directives."},{"m":"ngx_http_core_module","n":"aio","d":"Enables or disables the use of asynchronous file I/O (AIO) on FreeBSD and Linux:\\n```\\nlocation /video/ {\\n    aio            on;\\n    output_buffers 1 64k;\\n}\\n\\n```\\n\\nOn FreeBSD, AIO can be used starting from FreeBSD\xa04.3. Prior to FreeBSD\xa011.0, AIO can either be linked statically into a kernel:\\n```\\noptions VFS_AIO\\n\\n```\\nor loaded dynamically as a kernel loadable module:\\n```\\nkldload aio\\n\\n```\\n\\nOn Linux, AIO can be used starting from kernel version 2.6.22. Also, it is necessary to enable [directio](#directio), or otherwise reading will be blocking:\\n```\\nlocation /video/ {\\n    aio            on;\\n    directio       512;\\n    output_buffers 1 128k;\\n}\\n\\n```\\n\\nOn Linux, [directio](#directio) can only be used for reading blocks that are aligned on 512-byte boundaries (or 4K for XFS). File\u2019s unaligned end is read in blocking mode. The same holds true for byte range requests and for FLV requests not from the beginning of a file: reading of unaligned data at the beginning and end of a file will be blocking.\\nWhen both AIO and [sendfile](#sendfile) are enabled on Linux, AIO is used for files that are larger than or equal to the size specified in the [directio](#directio) directive, while [sendfile](#sendfile) is used for files of smaller sizes or when [directio](#directio) is disabled.\\n```\\nlocation /video/ {\\n    sendfile       on;\\n    aio            on;\\n    directio       8m;\\n}\\n\\n```\\n\\nFinally, files can be read and [sent](#sendfile) using multi-threading (1.7.11), without blocking a worker process:\\n```\\nlocation /video/ {\\n    sendfile       on;\\n    aio            threads;\\n}\\n\\n```\\nRead and send file operations are offloaded to threads of the specified [pool](../ngx_core_module.html#thread_pool). If the pool name is omitted, the pool with the name \u201c`default`\u201d is used. The pool name can also be set with variables:\\n```\\naio threads=pool$disk;\\n\\n```\\nBy default, multi-threading is disabled, it should be enabled with the `--with-threads` configuration parameter. Currently, multi-threading is compatible only with the [epoll](../events.html#epoll), [kqueue](../events.html#kqueue), and [eventport](../events.html#eventport) methods. Multi-threaded sending of files is only supported on Linux.\\nSee also the [sendfile](#sendfile) directive."},{"m":"ngx_http_core_module","n":"aio_write","d":"If [aio](#aio) is enabled, specifies whether it is used for writing files. Currently, this only works when using `aio threads` and is limited to writing temporary files with data received from proxied servers."},{"m":"ngx_http_core_module","n":"alias","d":"Defines a replacement for the specified location. For example, with the following configuration\\n```\\nlocation /i/ {\\n    alias /data/w3/images/;\\n}\\n\\n```\\non request of \u201c`/i/top.gif`\u201d, the file `/data/w3/images/top.gif` will be sent.\\nThe `_path_` value can contain variables, except `$document_root` and `$realpath_root`.\\nIf `alias` is used inside a location defined with a regular expression then such regular expression should contain captures and `alias` should refer to these captures (0.7.40), for example:\\n```\\nlocation ~ ^/users/(.+\\\\.(?:gif|jpe?g|png))$ {\\n    alias /data/w3/images/$1;\\n}\\n\\n```\\n\\nWhen location matches the last part of the directive\u2019s value:\\n```\\nlocation /images/ {\\n    alias /data/w3/images/;\\n}\\n\\n```\\nit is better to use the [root](#root) directive instead:\\n```\\nlocation /images/ {\\n    root /data/w3;\\n}\\n\\n```\\n"},{"m":"ngx_http_core_module","n":"auth_delay","d":"Delays processing of unauthorized requests with 401 response code to prevent timing attacks when access is limited by [password](ngx_http_auth_basic_module.html), by the [result of subrequest](ngx_http_auth_request_module.html), or by [JWT](ngx_http_auth_jwt_module.html)."},{"m":"ngx_http_core_module","n":"chunked_transfer_encoding","d":"Allows disabling chunked transfer encoding in HTTP/1.1. It may come in handy when using a software failing to support chunked encoding despite the standard\u2019s requirement."},{"m":"ngx_http_core_module","n":"client_body_buffer_size","d":"Sets buffer size for reading client request body. In case the request body is larger than the buffer, the whole body or only its part is written to a [temporary file](#client_body_temp_path). By default, buffer size is equal to two memory pages. This is 8K on x86, other 32-bit platforms, and x86-64. It is usually 16K on other 64-bit platforms."},{"m":"ngx_http_core_module","n":"client_body_in_file_only","d":"Determines whether nginx should save the entire client request body into a file. This directive can be used during debugging, or when using the `$request_body_file` variable, or the [$r->request\\\\_body\\\\_file](ngx_http_perl_module.html#methods) method of the module [ngx\\\\_http\\\\_perl\\\\_module](ngx_http_perl_module.html).\\nWhen set to the value `on`, temporary files are not removed after request processing.\\nThe value `clean` will cause the temporary files left after request processing to be removed."},{"m":"ngx_http_core_module","n":"client_body_in_single_buffer","d":"Determines whether nginx should save the entire client request body in a single buffer. The directive is recommended when using the `$request_body` variable, to save the number of copy operations involved."},{"m":"ngx_http_core_module","n":"client_body_temp_path","d":"Defines a directory for storing temporary files holding client request bodies. Up to three-level subdirectory hierarchy can be used under the specified directory. For example, in the following configuration\\n```\\nclient_body_temp_path /spool/nginx/client_temp 1 2;\\n\\n```\\na path to a temporary file might look like this:\\n```\\n/spool/nginx/client_temp/7/45/00000123457\\n\\n```\\n"},{"m":"ngx_http_core_module","n":"client_body_timeout","d":"Defines a timeout for reading client request body. The timeout is set only for a period between two successive read operations, not for the transmission of the whole request body. If a client does not transmit anything within this time, the request is terminated with the 408 (Request Time-out) error."},{"m":"ngx_http_core_module","n":"client_header_buffer_size","d":"Sets buffer size for reading client request header. For most requests, a buffer of 1K bytes is enough. However, if a request includes long cookies, or comes from a WAP client, it may not fit into 1K. If a request line or a request header field does not fit into this buffer then larger buffers, configured by the [large\\\\_client\\\\_header\\\\_buffers](#large_client_header_buffers) directive, are allocated."},{"m":"ngx_http_core_module","n":"client_header_timeout","d":"Defines a timeout for reading client request header. If a client does not transmit the entire header within this time, the request is terminated with the 408 (Request Time-out) error."},{"m":"ngx_http_core_module","n":"client_max_body_size","d":"Sets the maximum allowed size of the client request body, specified in the \u201cContent-Length\u201d request header field. If the size in a request exceeds the configured value, the 413 (Request Entity Too Large) error is returned to the client. Please be aware that browsers cannot correctly display this error. Setting `_size_` to 0 disables checking of client request body size."},{"m":"ngx_http_core_module","n":"connection_pool_size","d":"Allows accurate tuning of per-connection memory allocations. This directive has minimal impact on performance and should not generally be used. By default, the size is equal to 256 bytes on 32-bit platforms and 512 bytes on 64-bit platforms.\\nPrior to version 1.9.8, the default value was 256 on all platforms.\\n"},{"m":"ngx_http_core_module","n":"default_type","d":"Defines the default MIME type of a response. Mapping of file name extensions to MIME types can be set with the [types](#types) directive."},{"m":"ngx_http_core_module","n":"directio","d":"Enables the use of the `O_DIRECT` flag (FreeBSD, Linux), the `F_NOCACHE` flag (macOS), or the `directio()` function (Solaris), when reading files that are larger than or equal to the specified `_size_`. The directive automatically disables (0.7.15) the use of [sendfile](#sendfile) for a given request. It can be useful for serving large files:\\n```\\ndirectio 4m;\\n\\n```\\nor when using [aio](#aio) on Linux."},{"m":"ngx_http_core_module","n":"directio_alignment","d":"Sets the alignment for [directio](#directio). In most cases, a 512-byte alignment is enough. However, when using XFS under Linux, it needs to be increased to 4K."},{"m":"ngx_http_core_module","n":"disable_symlinks","d":"Determines how symbolic links should be treated when opening files:\\n`off`\\n\\nSymbolic links in the pathname are allowed and not checked. This is the default behavior.\\n\\n`on`\\n\\nIf any component of the pathname is a symbolic link, access to a file is denied.\\n\\n`if_not_owner`\\n\\nAccess to a file is denied if any component of the pathname is a symbolic link, and the link and object that the link points to have different owners.\\n\\n`from`\\\\=`_part_`\\n\\nWhen checking symbolic links (parameters `on` and `if_not_owner`), all components of the pathname are normally checked. Checking of symbolic links in the initial part of the pathname may be avoided by specifying additionally the `from`\\\\=`_part_` parameter. In this case, symbolic links are checked only from the pathname component that follows the specified initial part. If the value is not an initial part of the pathname checked, the whole pathname is checked as if this parameter was not specified at all. If the value matches the whole file name, symbolic links are not checked. The parameter value can contain variables.\\n\\nExample:\\n```\\ndisable_symlinks on from=$document_root;\\n\\n```\\n\\nThis directive is only available on systems that have the `openat()` and `fstatat()` interfaces. Such systems include modern versions of FreeBSD, Linux, and Solaris.\\nParameters `on` and `if_not_owner` add a processing overhead.\\nOn systems that do not support opening of directories only for search, to use these parameters it is required that worker processes have read permissions for all directories being checked.\\n\\n\\nThe [ngx\\\\_http\\\\_autoindex\\\\_module](ngx_http_autoindex_module.html), [ngx\\\\_http\\\\_random\\\\_index\\\\_module](ngx_http_random_index_module.html), and [ngx\\\\_http\\\\_dav\\\\_module](ngx_http_dav_module.html) modules currently ignore this directive.\\n"},{"m":"ngx_http_core_module","n":"error_page","d":"Defines the URI that will be shown for the specified errors. A `_uri_` value can contain variables.\\nExample:\\n```\\nerror_page 404             /404.html;\\nerror_page 500 502 503 504 /50x.html;\\n\\n```\\n\\nThis causes an internal redirect to the specified `_uri_` with the client request method changed to \u201c`GET`\u201d (for all methods other than \u201c`GET`\u201d and \u201c`HEAD`\u201d).\\nFurthermore, it is possible to change the response code to another using the \u201c`=``_response_`\u201d syntax, for example:\\n```\\nerror_page 404 =200 /empty.gif;\\n\\n```\\n\\nIf an error response is processed by a proxied server or a FastCGI/uwsgi/SCGI/gRPC server, and the server may return different response codes (e.g., 200, 302, 401 or 404), it is possible to respond with the code it returns:\\n```\\nerror_page 404 = /404.php;\\n\\n```\\n\\nIf there is no need to change URI and method during internal redirection it is possible to pass error processing into a named location:\\n```\\nlocation / {\\n    error_page 404 = @fallback;\\n}\\n\\nlocation @fallback {\\n    proxy_pass http://backend;\\n}\\n\\n```\\n\\n\\nIf `_uri_` processing leads to an error, the status code of the last occurred error is returned to the client.\\n\\nIt is also possible to use URL redirects for error processing:\\n```\\nerror_page 403      http://example.com/forbidden.html;\\nerror_page 404 =301 http://example.com/notfound.html;\\n\\n```\\nIn this case, by default, the response code 302 is returned to the client. It can only be changed to one of the redirect status codes (301, 302, 303, 307, and 308).\\nThe code 307 was not treated as a redirect until versions 1.1.16 and 1.0.13.\\n\\nThe code 308 was not treated as a redirect until version 1.13.0.\\n\\nThese directives are inherited from the previous configuration level if and only if there are no `error_page` directives defined on the current level."},{"m":"ngx_http_core_module","n":"etag","d":"Enables or disables automatic generation of the \u201cETag\u201d response header field for static resources."},{"m":"ngx_http_core_module","n":"http","d":"Provides the configuration file context in which the HTTP server directives are specified."},{"m":"ngx_http_core_module","n":"if_modified_since","d":"Specifies how to compare modification time of a response with the time in the \u201cIf-Modified-Since\u201d request header field:\\n`off`\\n\\nthe \u201cIf-Modified-Since\u201d request header field is ignored (0.7.34);\\n\\n`exact`\\n\\nexact match;\\n\\n`before`\\n\\nmodification time of a response is less than or equal to the time in the \u201cIf-Modified-Since\u201d request header field.\\n"},{"m":"ngx_http_core_module","n":"ignore_invalid_headers","d":"Controls whether header fields with invalid names should be ignored. Valid names are composed of English letters, digits, hyphens, and possibly underscores (as controlled by the [underscores\\\\_in\\\\_headers](#underscores_in_headers) directive).\\nIf the directive is specified on the [server](#server) level, its value is only used if a server is a default one. The value specified also applies to all virtual servers listening on the same address and port."},{"m":"ngx_http_core_module","n":"internal","d":"Specifies that a given location can only be used for internal requests. For external requests, the client error 404 (Not Found) is returned. Internal requests are the following:\\n*   requests redirected by the [error\\\\_page](#error_page), [index](ngx_http_index_module.html#index), [random\\\\_index](ngx_http_random_index_module.html#random_index), and [try\\\\_files](#try_files) directives;\\n*   requests redirected by the \u201cX-Accel-Redirect\u201d response header field from an upstream server;\\n*   subrequests formed by the \u201c`include virtual`\u201d command of the [ngx\\\\_http\\\\_ssi\\\\_module](ngx_http_ssi_module.html) module, by the [ngx\\\\_http\\\\_addition\\\\_module](ngx_http_addition_module.html) module directives, and by [auth\\\\_request](ngx_http_auth_request_module.html#auth_request) and [mirror](ngx_http_mirror_module.html#mirror) directives;\\n*   requests changed by the [rewrite](ngx_http_rewrite_module.html#rewrite) directive.\\n\\nExample:\\n```\\nerror_page 404 /404.html;\\n\\nlocation = /404.html {\\n    internal;\\n}\\n\\n```\\n\\nThere is a limit of 10 internal redirects per request to prevent request processing cycles that can occur in incorrect configurations. If this limit is reached, the error 500 (Internal Server Error) is returned. In such cases, the \u201crewrite or internal redirection cycle\u201d message can be seen in the error log.\\n"},{"m":"ngx_http_core_module","n":"keepalive_disable","d":"Disables keep-alive connections with misbehaving browsers. The `_browser_` parameters specify which browsers will be affected. The value `msie6` disables keep-alive connections with old versions of MSIE, once a POST request is received. The value `safari` disables keep-alive connections with Safari and Safari-like browsers on macOS and macOS-like operating systems. The value `none` enables keep-alive connections with all browsers.\\nPrior to version 1.1.18, the value `safari` matched all Safari and Safari-like browsers on all operating systems, and keep-alive connections with them were disabled by default.\\n"},{"m":"ngx_http_core_module","n":"keepalive_requests","d":"Sets the maximum number of requests that can be served through one keep-alive connection. After the maximum number of requests are made, the connection is closed.\\nClosing connections periodically is necessary to free per-connection memory allocations. Therefore, using too high maximum number of requests could result in excessive memory usage and not recommended."},{"m":"ngx_http_core_module","n":"keepalive_timeout","d":"The first parameter sets a timeout during which a keep-alive client connection will stay open on the server side. The zero value disables keep-alive client connections. The optional second parameter sets a value in the \u201cKeep-Alive: timeout=`_time_`\u201d response header field. Two parameters may differ.\\nThe \u201cKeep-Alive: timeout=`_time_`\u201d header field is recognized by Mozilla and Konqueror. MSIE closes keep-alive connections by itself in about 60 seconds."},{"m":"ngx_http_core_module","n":"large_client_header_buffers","d":"Sets the maximum `_number_` and `_size_` of buffers used for reading large client request header. A request line cannot exceed the size of one buffer, or the 414 (Request-URI Too Large) error is returned to the client. A request header field cannot exceed the size of one buffer as well, or the 400 (Bad Request) error is returned to the client. Buffers are allocated only on demand. By default, the buffer size is equal to 8K bytes. If after the end of request processing a connection is transitioned into the keep-alive state, these buffers are released."},{"m":"ngx_http_core_module","n":"limit_except","d":"Limits allowed HTTP methods inside a location. The `_method_` parameter can be one of the following: `GET`, `HEAD`, `POST`, `PUT`, `DELETE`, `MKCOL`, `COPY`, `MOVE`, `OPTIONS`, `PROPFIND`, `PROPPATCH`, `LOCK`, `UNLOCK`, or `PATCH`. Allowing the `GET` method makes the `HEAD` method also allowed. Access to other methods can be limited using the [ngx\\\\_http\\\\_access\\\\_module](ngx_http_access_module.html), [ngx\\\\_http\\\\_auth\\\\_basic\\\\_module](ngx_http_auth_basic_module.html), and [ngx\\\\_http\\\\_auth\\\\_jwt\\\\_module](ngx_http_auth_jwt_module.html) (1.13.10) modules directives:\\n```\\nlimit_except GET {\\n    allow 192.168.1.0/32;\\n    deny  all;\\n}\\n\\n```\\nPlease note that this will limit access to all methods **except** GET and HEAD."},{"m":"ngx_http_core_module","n":"limit_rate","d":"Limits the rate of response transmission to a client. The `_rate_` is specified in bytes per second. The zero value disables rate limiting. The limit is set per a request, and so if a client simultaneously opens two connections, the overall rate will be twice as much as the specified limit.\\nParameter value can contain variables (1.17.0). It may be useful in cases where rate should be limited depending on a certain condition:\\n```\\nmap $slow $rate {\\n    1     4k;\\n    2     8k;\\n}\\n\\nlimit_rate $rate;\\n\\n```\\n\\nRate limit can also be set in the [`$limit_rate`](#var_limit_rate) variable, however, since version 1.17.0, this method is not recommended:\\n```\\nserver {\\n\\n    if ($slow) {\\n        set $limit_rate 4k;\\n    }\\n\\n    ...\\n}\\n\\n```\\n\\nRate limit can also be set in the \u201cX-Accel-Limit-Rate\u201d header field of a proxied server response. This capability can be disabled using the [proxy\\\\_ignore\\\\_headers](ngx_http_proxy_module.html#proxy_ignore_headers), [fastcgi\\\\_ignore\\\\_headers](ngx_http_fastcgi_module.html#fastcgi_ignore_headers), [uwsgi\\\\_ignore\\\\_headers](ngx_http_uwsgi_module.html#uwsgi_ignore_headers), and [scgi\\\\_ignore\\\\_headers](ngx_http_scgi_module.html#scgi_ignore_headers) directives."},{"m":"ngx_http_core_module","n":"limit_rate_after","d":"Sets the initial amount after which the further transmission of a response to a client will be rate limited. Parameter value can contain variables (1.17.0).\\nExample:\\n```\\nlocation /flv/ {\\n    flv;\\n    limit_rate_after 500k;\\n    limit_rate       50k;\\n}\\n\\n```\\n"},{"m":"ngx_http_core_module","n":"lingering_close","d":"Controls how nginx closes client connections.\\nThe default value \u201c`on`\u201d instructs nginx to [wait for](#lingering_timeout) and [process](#lingering_time) additional data from a client before fully closing a connection, but only if heuristics suggests that a client may be sending more data.\\nThe value \u201c`always`\u201d will cause nginx to unconditionally wait for and process additional client data.\\nThe value \u201c`off`\u201d tells nginx to never wait for more data and close the connection immediately. This behavior breaks the protocol and should not be used under normal circumstances.\\nTo control closing [HTTP/2](ngx_http_v2_module.html) connections, the directive must be specified on the [server](#server) level (1.19.1)."},{"m":"ngx_http_core_module","n":"lingering_time","d":"When [lingering\\\\_close](#lingering_close) is in effect, this directive specifies the maximum time during which nginx will process (read and ignore) additional data coming from a client. After that, the connection will be closed, even if there will be more data."},{"m":"ngx_http_core_module","n":"lingering_timeout","d":"When [lingering\\\\_close](#lingering_close) is in effect, this directive specifies the maximum waiting time for more client data to arrive. If data are not received during this time, the connection is closed. Otherwise, the data are read and ignored, and nginx starts waiting for more data again. The \u201cwait-read-ignore\u201d cycle is repeated, but no longer than specified by the [lingering\\\\_time](#lingering_time) directive."},{"m":"ngx_http_core_module","n":"listen","d":"Sets the `_address_` and `_port_` for IP, or the `_path_` for a UNIX-domain socket on which the server will accept requests. Both `_address_` and `_port_`, or only `_address_` or only `_port_` can be specified. An `_address_` may also be a hostname, for example:\\n```\\nlisten 127.0.0.1:8000;\\nlisten 127.0.0.1;\\nlisten 8000;\\nlisten *:8000;\\nlisten localhost:8000;\\n\\n```\\nIPv6 addresses (0.7.36) are specified in square brackets:\\n```\\nlisten [::]:8000;\\nlisten [::1];\\n\\n```\\nUNIX-domain sockets (0.8.21) are specified with the \u201c`unix:`\u201d prefix:\\n```\\nlisten unix:/var/run/nginx.sock;\\n\\n```\\n\\nIf only `_address_` is given, the port 80 is used.\\nIf the directive is not present then either `*:80` is used if nginx runs with the superuser privileges, or `*:8000` otherwise.\\nThe `default_server` parameter, if present, will cause the server to become the default server for the specified `_address_`:`_port_` pair. If none of the directives have the `default_server` parameter then the first server with the `_address_`:`_port_` pair will be the default server for this pair.\\nIn versions prior to 0.8.21 this parameter is named simply `default`.\\n\\nThe `ssl` parameter (0.7.14) allows specifying that all connections accepted on this port should work in SSL mode. This allows for a more compact [configuration](configuring_https_servers.html#single_http_https_server) for the server that handles both HTTP and HTTPS requests.\\nThe `http2` parameter (1.9.5) configures the port to accept [HTTP/2](ngx_http_v2_module.html) connections. Normally, for this to work the `ssl` parameter should be specified as well, but nginx can also be configured to accept HTTP/2 connections without SSL.\\nThe `spdy` parameter (1.3.15-1.9.4) allows accepting [SPDY](ngx_http_spdy_module.html) connections on this port. Normally, for this to work the `ssl` parameter should be specified as well, but nginx can also be configured to accept SPDY connections without SSL.\\nThe `proxy_protocol` parameter (1.5.12) allows specifying that all connections accepted on this port should use the [PROXY protocol](http://www.haproxy.org/download/1.5/doc/proxy-protocol.txt).\\nThe PROXY protocol version 2 is supported since version 1.13.11.\\n\\nThe `listen` directive can have several additional parameters specific to socket-related system calls. These parameters can be specified in any `listen` directive, but only once for a given `_address_`:`_port_` pair.\\nIn versions prior to 0.8.21, they could only be specified in the `listen` directive together with the `default` parameter.\\n\\n`setfib`\\\\=`_number_`\\n\\nthis parameter (0.8.44) sets the associated routing table, FIB (the `SO_SETFIB` option) for the listening socket. This currently works only on FreeBSD.\\n\\n`fastopen`\\\\=`_number_`\\n\\nenables \u201c[TCP Fast Open](http://en.wikipedia.org/wiki/TCP_Fast_Open)\u201d for the listening socket (1.5.8) and [limits](https://tools.ietf.org/html/rfc7413#section-5.1) the maximum length for the queue of connections that have not yet completed the three-way handshake.\\n\\n> Do not enable this feature unless the server can handle receiving the [same SYN packet with data](https://tools.ietf.org/html/rfc7413#section-6.1) more than once.\\n\\n`backlog`\\\\=`_number_`\\n\\nsets the `backlog` parameter in the `listen()` call that limits the maximum length for the queue of pending connections. By default, `backlog` is set to -1 on FreeBSD, DragonFly BSD, and macOS, and to 511 on other platforms.\\n\\n`rcvbuf`\\\\=`_size_`\\n\\nsets the receive buffer size (the `SO_RCVBUF` option) for the listening socket.\\n\\n`sndbuf`\\\\=`_size_`\\n\\nsets the send buffer size (the `SO_SNDBUF` option) for the listening socket.\\n\\n`accept_filter`\\\\=`_filter_`\\n\\nsets the name of accept filter (the `SO_ACCEPTFILTER` option) for the listening socket that filters incoming connections before passing them to `accept()`. This works only on FreeBSD and NetBSD\xa05.0+. Possible values are [dataready](http://man.freebsd.org/accf_data) and [httpready](http://man.freebsd.org/accf_http).\\n\\n`deferred`\\n\\ninstructs to use a deferred `accept()` (the `TCP_DEFER_ACCEPT` socket option) on Linux.\\n\\n`bind`\\n\\ninstructs to make a separate `bind()` call for a given `_address_`:`_port_` pair. This is useful because if there are several `listen` directives with the same port but different addresses, and one of the `listen` directives listens on all addresses for the given port (`*:``_port_`), nginx will `bind()` only to `*:``_port_`. It should be noted that the `getsockname()` system call will be made in this case to determine the address that accepted the connection. If the `setfib`, `backlog`, `rcvbuf`, `sndbuf`, `accept_filter`, `deferred`, `ipv6only`, or `so_keepalive` parameters are used then for a given `_address_`:`_port_` pair a separate `bind()` call will always be made.\\n\\n`ipv6only`\\\\=`on`|`off`\\n\\nthis parameter (0.7.42) determines (via the `IPV6_V6ONLY` socket option) whether an IPv6 socket listening on a wildcard address `[::]` will accept only IPv6 connections or both IPv6 and IPv4 connections. This parameter is turned on by default. It can only be set once on start.\\n\\n> Prior to version 1.3.4, if this parameter was omitted then the operating system\u2019s settings were in effect for the socket.\\n\\n`reuseport`\\n\\nthis parameter (1.9.1) instructs to create an individual listening socket for each worker process (using the `SO_REUSEPORT` socket option on Linux 3.9+ and DragonFly BSD, or `SO_REUSEPORT_LB` on FreeBSD\xa012+), allowing a kernel to distribute incoming connections between worker processes. This currently works only on Linux\xa03.9+, DragonFly BSD, and FreeBSD 12+ (1.15.1).\\n\\n> Inappropriate use of this option may have its security [implications](http://man7.org/linux/man-pages/man7/socket.7.html).\\n\\n`so_keepalive`\\\\=`on`|`off`|\\\\[`_keepidle_`\\\\]:\\\\[`_keepintvl_`\\\\]:\\\\[`_keepcnt_`\\\\]\\n\\nthis parameter (1.1.11) configures the \u201cTCP keepalive\u201d behavior for the listening socket. If this parameter is omitted then the operating system\u2019s settings will be in effect for the socket. If it is set to the value \u201c`on`\u201d, the `SO_KEEPALIVE` option is turned on for the socket. If it is set to the value \u201c`off`\u201d, the `SO_KEEPALIVE` option is turned off for the socket. Some operating systems support setting of TCP keepalive parameters on a per-socket basis using the `TCP_KEEPIDLE`, `TCP_KEEPINTVL`, and `TCP_KEEPCNT` socket options. On such systems (currently, Linux\xa02.4+, NetBSD\xa05+, and FreeBSD\xa09.0-STABLE), they can be configured using the `_keepidle_`, `_keepintvl_`, and `_keepcnt_` parameters. One or two parameters may be omitted, in which case the system default setting for the corresponding socket option will be in effect. For example,\\n\\n> so\\\\_keepalive=30m::10\\n\\nwill set the idle timeout (`TCP_KEEPIDLE`) to 30 minutes, leave the probe interval (`TCP_KEEPINTVL`) at its system default, and set the probes count (`TCP_KEEPCNT`) to 10 probes.\\n\\nExample:\\n```\\nlisten 127.0.0.1 default_server accept_filter=dataready backlog=1024;\\n\\n```\\n"},{"m":"ngx_http_core_module","n":"location","d":"Sets configuration depending on a request URI.\\nThe matching is performed against a normalized URI, after decoding the text encoded in the \u201c`%XX`\u201d form, resolving references to relative path components \u201c`.`\u201d and \u201c`..`\u201d, and possible [compression](#merge_slashes) of two or more adjacent slashes into a single slash.\\nA location can either be defined by a prefix string, or by a regular expression. Regular expressions are specified with the preceding \u201c`~*`\u201d modifier (for case-insensitive matching), or the \u201c`~`\u201d modifier (for case-sensitive matching). To find location matching a given request, nginx first checks locations defined using the prefix strings (prefix locations). Among them, the location with the longest matching prefix is selected and remembered. Then regular expressions are checked, in the order of their appearance in the configuration file. The search of regular expressions terminates on the first match, and the corresponding configuration is used. If no match with a regular expression is found then the configuration of the prefix location remembered earlier is used.\\n`location` blocks can be nested, with some exceptions mentioned below.\\nFor case-insensitive operating systems such as macOS and Cygwin, matching with prefix strings ignores a case (0.7.7). However, comparison is limited to one-byte locales.\\nRegular expressions can contain captures (0.7.40) that can later be used in other directives.\\nIf the longest matching prefix location has the \u201c`^~`\u201d modifier then regular expressions are not checked.\\nAlso, using the \u201c`=`\u201d modifier it is possible to define an exact match of URI and location. If an exact match is found, the search terminates. For example, if a \u201c`/`\u201d request happens frequently, defining \u201c`location = /`\u201d will speed up the processing of these requests, as search terminates right after the first comparison. Such a location cannot obviously contain nested locations.\\n\\nIn versions from 0.7.1 to 0.8.41, if a request matched the prefix location without the \u201c`=`\u201d and \u201c`^~`\u201d modifiers, the search also terminated and regular expressions were not checked.\\n\\nLet\u2019s illustrate the above by an example:\\n```\\nlocation = / {\\n    [ configuration A ]\\n}\\n\\nlocation / {\\n    [ configuration B ]\\n}\\n\\nlocation /documents/ {\\n    [ configuration C ]\\n}\\n\\nlocation ^~ /images/ {\\n    [ configuration D ]\\n}\\n\\nlocation ~* \\\\.(gif|jpg|jpeg)$ {\\n    [ configuration E ]\\n}\\n\\n```\\nThe \u201c`/`\u201d request will match configuration A, the \u201c`/index.html`\u201d request will match configuration B, the \u201c`/documents/document.html`\u201d request will match configuration C, the \u201c`/images/1.gif`\u201d request will match configuration D, and the \u201c`/documents/1.jpg`\u201d request will match configuration E.\\nThe \u201c`@`\u201d prefix defines a named location. Such a location is not used for a regular request processing, but instead used for request redirection. They cannot be nested, and cannot contain nested locations.\\nIf a location is defined by a prefix string that ends with the slash character, and requests are processed by one of [proxy\\\\_pass](ngx_http_proxy_module.html#proxy_pass), [fastcgi\\\\_pass](ngx_http_fastcgi_module.html#fastcgi_pass), [uwsgi\\\\_pass](ngx_http_uwsgi_module.html#uwsgi_pass), [scgi\\\\_pass](ngx_http_scgi_module.html#scgi_pass), [memcached\\\\_pass](ngx_http_memcached_module.html#memcached_pass), or [grpc\\\\_pass](ngx_http_grpc_module.html#grpc_pass), then the special processing is performed. In response to a request with URI equal to this string, but without the trailing slash, a permanent redirect with the code 301 will be returned to the requested URI with the slash appended. If this is not desired, an exact match of the URI and location could be defined like this:\\n```\\nlocation /user/ {\\n    proxy_pass http://user.example.com;\\n}\\n\\nlocation = /user {\\n    proxy_pass http://login.example.com;\\n}\\n\\n```\\n"},{"m":"ngx_http_core_module","n":"log_not_found","d":"Enables or disables logging of errors about not found files into [error\\\\_log](../ngx_core_module.html#error_log)."},{"m":"ngx_http_core_module","n":"log_subrequest","d":"Enables or disables logging of subrequests into [access\\\\_log](ngx_http_log_module.html#access_log)."},{"m":"ngx_http_core_module","n":"max_ranges","d":"Limits the maximum allowed number of ranges in byte-range requests. Requests that exceed the limit are processed as if there were no byte ranges specified. By default, the number of ranges is not limited. The zero value disables the byte-range support completely."},{"m":"ngx_http_core_module","n":"merge_slashes","d":"Enables or disables compression of two or more adjacent slashes in a URI into a single slash.\\nNote that compression is essential for the correct matching of prefix string and regular expression locations. Without it, the \u201c`//scripts/one.php`\u201d request would not match\\n```\\nlocation /scripts/ {\\n    ...\\n}\\n\\n```\\nand might be processed as a static file. So it gets converted to \u201c`/scripts/one.php`\u201d.\\nTurning the compression `off` can become necessary if a URI contains base64-encoded names, since base64 uses the \u201c`/`\u201d character internally. However, for security considerations, it is better to avoid turning the compression off.\\nIf the directive is specified on the [server](#server) level, its value is only used if a server is a default one. The value specified also applies to all virtual servers listening on the same address and port."},{"m":"ngx_http_core_module","n":"msie_padding","d":"Enables or disables adding comments to responses for MSIE clients with status greater than 400 to increase the response size to 512 bytes."},{"m":"ngx_http_core_module","n":"msie_refresh","d":"Enables or disables issuing refreshes instead of redirects for MSIE clients."},{"m":"ngx_http_core_module","n":"open_file_cache","d":"Configures a cache that can store:\\n*   open file descriptors, their sizes and modification times;\\n*   information on existence of directories;\\n*   file lookup errors, such as \u201cfile not found\u201d, \u201cno read permission\u201d, and so on.\\n    \\n    > Caching of errors should be enabled separately by the [open\\\\_file\\\\_cache\\\\_errors](#open_file_cache_errors) directive.\\n\\nThe directive has the following parameters:\\n`max`\\n\\nsets the maximum number of elements in the cache; on cache overflow the least recently used (LRU) elements are removed;\\n\\n`inactive`\\n\\ndefines a time after which an element is removed from the cache if it has not been accessed during this time; by default, it is 60 seconds;\\n\\n`off`\\n\\ndisables the cache.\\n\\nExample:\\n```\\nopen_file_cache          max=1000 inactive=20s;\\nopen_file_cache_valid    30s;\\nopen_file_cache_min_uses 2;\\nopen_file_cache_errors   on;\\n\\n```\\n"},{"m":"ngx_http_core_module","n":"open_file_cache_errors","d":"Enables or disables caching of file lookup errors by [open\\\\_file\\\\_cache](#open_file_cache)."},{"m":"ngx_http_core_module","n":"open_file_cache_min_uses","d":"Sets the minimum `_number_` of file accesses during the period configured by the `inactive` parameter of the [open\\\\_file\\\\_cache](#open_file_cache) directive, required for a file descriptor to remain open in the cache."},{"m":"ngx_http_core_module","n":"open_file_cache_valid","d":"Sets a time after which [open\\\\_file\\\\_cache](#open_file_cache) elements should be validated."},{"m":"ngx_http_core_module","n":"output_buffers","d":"Sets the `_number_` and `_size_` of the buffers used for reading a response from a disk.\\nPrior to version 1.9.5, the default value was 1 32k.\\n"},{"m":"ngx_http_core_module","n":"port_in_redirect","d":"Enables or disables specifying the port in [absolute](#absolute_redirect) redirects issued by nginx.\\nThe use of the primary server name in redirects is controlled by the [server\\\\_name\\\\_in\\\\_redirect](#server_name_in_redirect) directive."},{"m":"ngx_http_core_module","n":"postpone_output","d":"If possible, the transmission of client data will be postponed until nginx has at least `_size_` bytes of data to send. The zero value disables postponing data transmission."},{"m":"ngx_http_core_module","n":"read_ahead","d":"Sets the amount of pre-reading for the kernel when working with file.\\nOn Linux, the `posix_fadvise(0, 0, 0, POSIX_FADV_SEQUENTIAL)` system call is used, and so the `_size_` parameter is ignored.\\nOn FreeBSD, the `fcntl(O_READAHEAD,` `_size_``)` system call, supported since FreeBSD\xa09.0-CURRENT, is used. FreeBSD\xa07 has to be [patched](http://sysoev.ru/freebsd/patch.readahead.txt)."},{"m":"ngx_http_core_module","n":"recursive_error_pages","d":"Enables or disables doing several redirects using the [error\\\\_page](#error_page) directive. The number of such redirects is [limited](#internal)."},{"m":"ngx_http_core_module","n":"request_pool_size","d":"Allows accurate tuning of per-request memory allocations. This directive has minimal impact on performance and should not generally be used."},{"m":"ngx_http_core_module","n":"reset_timedout_connection","d":"Enables or disables resetting timed out connections and connections [closed](ngx_http_rewrite_module.html#return) with the non-standard code 444 (1.15.2). The reset is performed as follows. Before closing a socket, the `SO_LINGER` option is set on it with a timeout value of 0. When the socket is closed, TCP RST is sent to the client, and all memory occupied by this socket is released. This helps avoid keeping an already closed socket with filled buffers in a FIN\\\\_WAIT1 state for a long time.\\nIt should be noted that timed out keep-alive connections are closed normally."},{"m":"ngx_http_core_module","n":"resolver","d":"Configures name servers used to resolve names of upstream servers into addresses, for example:\\n```\\nresolver 127.0.0.1 [::1]:5353;\\n\\n```\\nThe address can be specified as a domain name or IP address, with an optional port (1.3.1, 1.2.2). If port is not specified, the port 53 is used. Name servers are queried in a round-robin fashion.\\nBefore version 1.1.7, only a single name server could be configured. Specifying name servers using IPv6 addresses is supported starting from versions 1.3.1 and 1.2.2.\\n"},{"m":"ngx_http_core_module","n":"resolver_ipv6","d":"By default, nginx will look up both IPv4 and IPv6 addresses while resolving. If looking up of IPv6 addresses is not desired, the `ipv6=off` parameter can be specified.\\nResolving of names into IPv6 addresses is supported starting from version 1.5.8.\\n"},{"m":"ngx_http_core_module","n":"resolver_valid","d":"By default, nginx caches answers using the TTL value of a response. An optional `valid` parameter allows overriding it:\\n```\\nresolver 127.0.0.1 [::1]:5353 valid=30s;\\n\\n```\\n\\nBefore version 1.1.9, tuning of caching time was not possible, and nginx always cached answers for the duration of 5 minutes.\\n\\nTo prevent DNS spoofing, it is recommended configuring DNS servers in a properly secured trusted local network.\\n"},{"m":"ngx_http_core_module","n":"resolver_status_zone","d":"The optional `status_zone` parameter (1.17.1) enables [collection](ngx_http_api_module.html#resolvers_) of DNS server statistics of requests and responses in the specified `_zone_`. The parameter is available as part of our [commercial subscription](http://nginx.com/products/)."},{"m":"ngx_http_core_module","n":"resolver_timeout","d":"Sets a timeout for name resolution, for example:\\n```\\nresolver_timeout 5s;\\n\\n```\\n"},{"m":"ngx_http_core_module","n":"root","d":"Sets the root directory for requests. For example, with the following configuration\\n```\\nlocation /i/ {\\n    root /data/w3;\\n}\\n\\n```\\nThe `/data/w3/i/top.gif` file will be sent in response to the \u201c`/i/top.gif`\u201d request.\\nThe `_path_` value can contain variables, except `$document_root` and `$realpath_root`.\\nA path to the file is constructed by merely adding a URI to the value of the `root` directive. If a URI has to be modified, the [alias](#alias) directive should be used."},{"m":"ngx_http_core_module","n":"satisfy","d":"Allows access if all (`all`) or at least one (`any`) of the [ngx\\\\_http\\\\_access\\\\_module](ngx_http_access_module.html), [ngx\\\\_http\\\\_auth\\\\_basic\\\\_module](ngx_http_auth_basic_module.html), [ngx\\\\_http\\\\_auth\\\\_request\\\\_module](ngx_http_auth_request_module.html), or [ngx\\\\_http\\\\_auth\\\\_jwt\\\\_module](ngx_http_auth_jwt_module.html) modules allow access.\\nExample:\\n```\\nlocation / {\\n    satisfy any;\\n\\n    allow 192.168.1.0/32;\\n    deny  all;\\n\\n    auth_basic           \\"closed site\\";\\n    auth_basic_user_file conf/htpasswd;\\n}\\n\\n```\\n"},{"m":"ngx_http_core_module","n":"send_lowat","d":"If the directive is set to a non-zero value, nginx will try to minimize the number of send operations on client sockets by using either `NOTE_LOWAT` flag of the [kqueue](../events.html#kqueue) method or the `SO_SNDLOWAT` socket option. In both cases the specified `_size_` is used.\\nThis directive is ignored on Linux, Solaris, and Windows."},{"m":"ngx_http_core_module","n":"send_timeout","d":"Sets a timeout for transmitting a response to the client. The timeout is set only between two successive write operations, not for the transmission of the whole response. If the client does not receive anything within this time, the connection is closed."},{"m":"ngx_http_core_module","n":"sendfile","d":"Enables or disables the use of `sendfile()`.\\nStarting from nginx\xa00.8.12 and FreeBSD\xa05.2.1, [aio](#aio) can be used to pre-load data for `sendfile()`:\\n```\\nlocation /video/ {\\n    sendfile       on;\\n    tcp_nopush     on;\\n    aio            on;\\n}\\n\\n```\\nIn this configuration, `sendfile()` is called with the `SF_NODISKIO` flag which causes it not to block on disk I/O, but, instead, report back that the data are not in memory. nginx then initiates an asynchronous data load by reading one byte. On the first read, the FreeBSD kernel loads the first 128K bytes of a file into memory, although next reads will only load data in 16K chunks. This can be changed using the [read\\\\_ahead](#read_ahead) directive.\\nBefore version 1.7.11, pre-loading could be enabled with `aio sendfile;`.\\n"},{"m":"ngx_http_core_module","n":"sendfile_max_chunk","d":"When set to a non-zero value, limits the amount of data that can be transferred in a single `sendfile()` call. Without the limit, one fast connection may seize the worker process entirely."},{"m":"ngx_http_core_module","n":"server","d":"Sets configuration for a virtual server. There is no clear separation between IP-based (based on the IP address) and name-based (based on the \u201cHost\u201d request header field) virtual servers. Instead, the [listen](#listen) directives describe all addresses and ports that should accept connections for the server, and the [server\\\\_name](#server_name) directive lists all server names. Example configurations are provided in the \u201c[How nginx processes a request](request_processing.html)\u201d document."},{"m":"ngx_http_core_module","n":"server_name","d":"Sets names of a virtual server, for example:\\n```\\nserver {\\n    server_name example.com www.example.com;\\n}\\n\\n```\\n\\nThe first name becomes the primary server name.\\nServer names can include an asterisk (\u201c`*`\u201d) replacing the first or last part of a name:\\n```\\nserver {\\n    server_name example.com *.example.com www.example.*;\\n}\\n\\n```\\nSuch names are called wildcard names.\\nThe first two of the names mentioned above can be combined in one:\\n```\\nserver {\\n    server_name .example.com;\\n}\\n\\n```\\n\\nIt is also possible to use regular expressions in server names, preceding the name with a tilde (\u201c`~`\u201d):\\n```\\nserver {\\n    server_name www.example.com ~^www\\\\d+\\\\.example\\\\.com$;\\n}\\n\\n```\\n\\nRegular expressions can contain captures (0.7.40) that can later be used in other directives:\\n```\\nserver {\\n    server_name ~^(www\\\\.)?(.+)$;\\n\\n    location / {\\n        root /sites/$2;\\n    }\\n}\\n\\nserver {\\n    server_name _;\\n\\n    location / {\\n        root /sites/default;\\n    }\\n}\\n\\n```\\n\\nNamed captures in regular expressions create variables (0.8.25) that can later be used in other directives:\\n```\\nserver {\\n    server_name ~^(www\\\\.)?(?<domain>.+)$;\\n\\n    location / {\\n        root /sites/$domain;\\n    }\\n}\\n\\nserver {\\n    server_name _;\\n\\n    location / {\\n        root /sites/default;\\n    }\\n}\\n\\n```\\n\\nIf the directive\u2019s parameter is set to \u201c`$hostname`\u201d (0.9.4), the machine\u2019s hostname is inserted.\\nIt is also possible to specify an empty server name (0.7.11):\\n```\\nserver {\\n    server_name www.example.com \\"\\";\\n}\\n\\n```\\nIt allows this server to process requests without the \u201cHost\u201d header field\xa0\u2014 instead of the default server\xa0\u2014 for the given address:port pair. This is the default setting.\\nBefore 0.8.48, the machine\u2019s hostname was used by default.\\n\\nDuring searching for a virtual server by name, if the name matches more than one of the specified variants, (e.g. both a wildcard name and regular expression match), the first matching variant will be chosen, in the following order of priority:\\n*   the exact name\\n*   the longest wildcard name starting with an asterisk, e.g. \u201c`*.example.com`\u201d\\n*   the longest wildcard name ending with an asterisk, e.g. \u201c`mail.*`\u201d\\n*   the first matching regular expression (in order of appearance in the configuration file)\\n\\nDetailed description of server names is provided in a separate [Server names](server_names.html) document."},{"m":"ngx_http_core_module","n":"server_name_in_redirect","d":"Enables or disables the use of the primary server name, specified by the [server\\\\_name](#server_name) directive, in [absolute](#absolute_redirect) redirects issued by nginx. When the use of the primary server name is disabled, the name from the \u201cHost\u201d request header field is used. If this field is not present, the IP address of the server is used.\\nThe use of a port in redirects is controlled by the [port\\\\_in\\\\_redirect](#port_in_redirect) directive."},{"m":"ngx_http_core_module","n":"server_names_hash_bucket_size","d":"Sets the bucket size for the server names hash tables. The default value depends on the size of the processor\u2019s cache line. The details of setting up hash tables are provided in a separate [document](../hash.html)."},{"m":"ngx_http_core_module","n":"server_names_hash_max_size","d":"Sets the maximum `_size_` of the server names hash tables. The details of setting up hash tables are provided in a separate [document](../hash.html)."},{"m":"ngx_http_core_module","n":"server_tokens","d":"Enables or disables emitting nginx version on error pages and in the \u201cServer\u201d response header field."},{"m":"ngx_http_core_module","n":"server_tokens_build","d":"The `build` parameter (1.11.10) enables emitting a [build name](../configure.html#build) along with nginx version.\\nAdditionally, as part of our [commercial subscription](http://nginx.com/products/), starting from version 1.9.13 the signature on error pages and the \u201cServer\u201d response header field value can be set explicitly using the `_string_` with variables. An empty string disables the emission of the \u201cServer\u201d field."},{"m":"ngx_http_core_module","n":"subrequest_output_buffer_size","d":"Sets the `_size_` of the buffer used for storing the response body of a subrequest. By default, the buffer size is equal to one memory page. This is either 4K or 8K, depending on a platform. It can be made smaller, however.\\nThe directive is applicable only for subrequests with response bodies saved into memory. For example, such subrequests are created by [SSI](ngx_http_ssi_module.html#ssi_include_set)."},{"m":"ngx_http_core_module","n":"tcp_nodelay","d":"Enables or disables the use of the `TCP_NODELAY` option. The option is enabled when a connection is transitioned into the keep-alive state. Additionally, it is enabled on SSL connections, for unbuffered proxying, and for [WebSocket](websocket.html) proxying."},{"m":"ngx_http_core_module","n":"tcp_nopush","d":"Enables or disables the use of the `TCP_NOPUSH` socket option on FreeBSD or the `TCP_CORK` socket option on Linux. The options are enabled only when [sendfile](#sendfile) is used. Enabling the option allows\\n*   sending the response header and the beginning of a file in one packet, on Linux and FreeBSD\xa04.\\\\*;\\n*   sending a file in full packets.\\n"},{"m":"ngx_http_core_module","n":"try_files","d":"Checks the existence of files in the specified order and uses the first found file for request processing; the processing is performed in the current context. The path to a file is constructed from the `_file_` parameter according to the [root](#root) and [alias](#alias) directives. It is possible to check directory\u2019s existence by specifying a slash at the end of a name, e.g. \u201c`$uri/`\u201d. If none of the files were found, an internal redirect to the `_uri_` specified in the last parameter is made. For example:\\n```\\nlocation /images/ {\\n    try_files $uri /images/default.gif;\\n}\\n\\nlocation = /images/default.gif {\\n    expires 30s;\\n}\\n\\n```\\nThe last parameter can also point to a named location, as shown in examples below. Starting from version 0.7.51, the last parameter can also be a `_code_`:\\n```\\nlocation / {\\n    try_files $uri $uri/index.html $uri.html =404;\\n}\\n\\n```\\n\\nExample in proxying Mongrel:\\n```\\nlocation / {\\n    try_files /system/maintenance.html\\n              $uri $uri/index.html $uri.html\\n              @mongrel;\\n}\\n\\nlocation @mongrel {\\n    proxy_pass http://mongrel;\\n}\\n\\n```\\n\\nExample for Drupal/FastCGI:\\n```\\nlocation / {\\n    try_files $uri $uri/ @drupal;\\n}\\n\\nlocation ~ \\\\.php$ {\\n    try_files $uri @drupal;\\n\\n    fastcgi_pass ...;\\n\\n    fastcgi_param SCRIPT_FILENAME /path/to$fastcgi_script_name;\\n    fastcgi_param SCRIPT_NAME     $fastcgi_script_name;\\n    fastcgi_param QUERY_STRING    $args;\\n\\n    ... other fastcgi_param\'s\\n}\\n\\nlocation @drupal {\\n    fastcgi_pass ...;\\n\\n    fastcgi_param SCRIPT_FILENAME /path/to/index.php;\\n    fastcgi_param SCRIPT_NAME     /index.php;\\n    fastcgi_param QUERY_STRING    q=$uri&$args;\\n\\n    ... other fastcgi_param\'s\\n}\\n\\n```\\nIn the following example,\\n```\\nlocation / {\\n    try_files $uri $uri/ @drupal;\\n}\\n\\n```\\nthe `try_files` directive is equivalent to\\n```\\nlocation / {\\n    error_page 404 = @drupal;\\n    log_not_found off;\\n}\\n\\n```\\nAnd here,\\n```\\nlocation ~ \\\\.php$ {\\n    try_files $uri @drupal;\\n\\n    fastcgi_pass ...;\\n\\n    fastcgi_param SCRIPT_FILENAME /path/to$fastcgi_script_name;\\n\\n    ...\\n}\\n\\n```\\n`try_files` checks the existence of the PHP file before passing the request to the FastCGI server.\\nExample for Wordpress and Joomla:\\n```\\nlocation / {\\n    try_files $uri $uri/ @wordpress;\\n}\\n\\nlocation ~ \\\\.php$ {\\n    try_files $uri @wordpress;\\n\\n    fastcgi_pass ...;\\n\\n    fastcgi_param SCRIPT_FILENAME /path/to$fastcgi_script_name;\\n    ... other fastcgi_param\'s\\n}\\n\\nlocation @wordpress {\\n    fastcgi_pass ...;\\n\\n    fastcgi_param SCRIPT_FILENAME /path/to/index.php;\\n    ... other fastcgi_param\'s\\n}\\n\\n```\\n"},{"m":"ngx_http_core_module","n":"types","d":"Maps file name extensions to MIME types of responses. Extensions are case-insensitive. Several extensions can be mapped to one type, for example:\\n```\\ntypes {\\n    application/octet-stream bin exe dll;\\n    application/octet-stream deb;\\n    application/octet-stream dmg;\\n}\\n\\n```\\n\\nA sufficiently full mapping table is distributed with nginx in the `conf/mime.types` file.\\nTo make a particular location emit the \u201c`application/octet-stream`\u201d MIME type for all requests, the following configuration can be used:\\n```\\nlocation /download/ {\\n    types        { }\\n    default_type application/octet-stream;\\n}\\n\\n```\\n"},{"m":"ngx_http_core_module","n":"types_hash_bucket_size","d":"Sets the bucket size for the types hash tables. The details of setting up hash tables are provided in a separate [document](../hash.html).\\nPrior to version 1.5.13, the default value depended on the size of the processor\u2019s cache line.\\n"},{"m":"ngx_http_core_module","n":"types_hash_max_size","d":"Sets the maximum `_size_` of the types hash tables. The details of setting up hash tables are provided in a separate [document](../hash.html)."},{"m":"ngx_http_core_module","n":"underscores_in_headers","d":"Enables or disables the use of underscores in client request header fields. When the use of underscores is disabled, request header fields whose names contain underscores are marked as invalid and become subject to the [ignore\\\\_invalid\\\\_headers](#ignore_invalid_headers) directive.\\nIf the directive is specified on the [server](#server) level, its value is only used if a server is a default one. The value specified also applies to all virtual servers listening on the same address and port."},{"m":"ngx_http_core_module","n":"variables_hash_bucket_size","d":"Sets the bucket size for the variables hash table. The details of setting up hash tables are provided in a separate [document](../hash.html)."},{"m":"ngx_http_core_module","n":"variables_hash_max_size","d":"Sets the maximum `_size_` of the variables hash table. The details of setting up hash tables are provided in a separate [document](../hash.html).\\nPrior to version 1.5.13, the default value was 512.\\n"},{"m":"ngx_http_core_module","n":"$arg_name","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$args","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$binary_remote_addr","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$body_bytes_sent","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$bytes_sent","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$connection","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$connection_requests","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$content_length","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$content_type","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$cookie_name","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$document_root","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$document_uri","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$host","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$hostname","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$http_name","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$https","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$is_args","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$limit_rate","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$msec","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$nginx_version","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$pid","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$pipe","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$proxy_protocol_addr","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$proxy_protocol_port","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$proxy_protocol_server_addr","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$proxy_protocol_server_port","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$query_string","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$realpath_root","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$remote_addr","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$remote_port","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$remote_user","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$request","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$request_body","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$request_body_file","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$request_completion","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$request_filename","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$request_id","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$request_length","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$request_method","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$request_time","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$request_uri","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$scheme","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$sent_http_name","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$sent_trailer_name","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$server_addr","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$server_name","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$server_port","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$server_protocol","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$status","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"\\n$tcpinfo_rtt,\\n$tcpinfo_rttvar,\\n$tcpinfo_snd_cwnd,\\n$tcpinfo_rcv_space\\n","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$time_iso8601","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$time_local","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_core_module","n":"$uri","d":"current URI in request, [normalized](#location)\\n\\nThe value of `$uri` may change during request processing, e.g. when doing internal redirects, or when using index files."},{"m":"ngx_http_access_module","n":"summary","d":"The `ngx_http_access_module` module allows limiting access to certain client addresses.\\nAccess can also be limited by [password](ngx_http_auth_basic_module.html), by the [result of subrequest](ngx_http_auth_request_module.html), or by [JWT](ngx_http_auth_jwt_module.html). Simultaneous limitation of access by address and by password is controlled by the [satisfy](ngx_http_core_module.html#satisfy) directive."},{"m":"ngx_http_access_module","n":"allow","d":"Allows access for the specified network or address. If the special value `unix:` is specified (1.5.1), allows access for all UNIX-domain sockets."},{"m":"ngx_http_addition_module","n":"summary","d":"The `ngx_http_addition_module` module is a filter that adds text before and after a response. This module is not built by default, it should be enabled with the `--with-http_addition_module` configuration parameter."},{"m":"ngx_http_addition_module","n":"add_before_body","d":"Adds the text returned as a result of processing a given subrequest before the response body. An empty string (`\\"\\"`) as a parameter cancels addition inherited from the previous configuration level."},{"m":"ngx_http_addition_module","n":"add_after_body","d":"Adds the text returned as a result of processing a given subrequest after the response body. An empty string (`\\"\\"`) as a parameter cancels addition inherited from the previous configuration level."},{"m":"ngx_http_api_module","n":"summary","d":"The `ngx_http_api_module` module (1.13.3) provides REST API for accessing various status information, configuring upstream server groups on-the-fly, and managing [key-value pairs](ngx_http_keyval_module.html) without the need of reconfiguring nginx.\\n\\nThe module supersedes the [ngx\\\\_http\\\\_status\\\\_module](ngx_http_status_module.html) and [ngx\\\\_http\\\\_upstream\\\\_conf\\\\_module](ngx_http_upstream_conf_module.html) modules.\\n\\nWhen using the `PATCH` or `POST` methods, make sure that the payload does not exceed the [buffer size](ngx_http_core_module.html#client_body_buffer_size) for reading the client request body, otherwise, the 413 (Request Entity Too Large) error may be returned.\\n\\nThis module is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_api_module","n":"api","d":"Turns on the REST API interface in the surrounding location. Access to this location should be [limited](ngx_http_core_module.html#satisfy).\\nThe `write` parameter determines whether the API is read-only or read-write. By default, the API is read-only."},{"m":"ngx_http_api_module","n":"api_version","d":"All API requests should contain a supported API version in the URI. If the request URI equals the location prefix, the list of supported API versions is returned. The current API version is \u201c`6`\u201d.\\nThe optional \u201c`fields`\u201d argument in the request line specifies which fields of the requested objects will be output:\\n```\\nhttp://127.0.0.1/api/6/nginx?fields=version,build\\n\\n```\\n"},{"m":"ngx_http_api_module","n":"status_zone","d":"Enables collection of virtual [http](ngx_http_core_module.html#server) or [stream](../stream/ngx_stream_core_module.html#server) server status information in the specified `_zone_`. Several servers may share the same zone."},{"m":"ngx_http_api_module","n":"status_zone_location","d":"Starting from 1.17.0, status information can be collected per [location](ngx_http_core_module.html#location). The special value `off` disables statistics collection in nested location blocks. Note that the statistics is collected in the context of a location where processing ends. It may be different from the original location, if an [internal redirect](ngx_http_core_module.html#internal) happens during request processing."},{"m":"ngx_http_api_module","n":"compatibility","d":"#### Compatibility\\n\\n*   The [/stream/limit\\\\_conns/](#stream_limit_conns_) data were added in [version](#api_version) 6.\\n*   The [/http/limit\\\\_conns/](#http_limit_conns_) data were added in [version](#api_version) 6.\\n*   The [/http/limit\\\\_reqs/](#http_limit_reqs_) data were added in [version](#api_version) 6.\\n*   The \u201c`expire`\u201d parameter of a [key-value](ngx_http_keyval_module.html) pair can be [set](#postHttpKeyvalZoneData) or [changed](#patchHttpKeyvalZoneKeyValue) since [version](#api_version) 5.\\n*   The [/resolvers/](#resolvers_) data were added in [version](#api_version) 5.\\n*   The [/http/location\\\\_zones/](#http_location_zones_) data were added in [version](#api_version) 5.\\n*   The `path` and `method` fields of [nginx error object](#def_nginx_error) were removed in [version](#api_version) 4. These fields continue to exist in earlier api versions, but show an empty value.\\n*   The [/stream/zone\\\\_sync/](#stream_zone_sync_) data were added in [version](#api_version) 3.\\n*   The [drain](#def_nginx_http_upstream_conf_server) parameter was added in [version](#api_version) 2.\\n*   The [/stream/keyvals/](#stream_keyvals_) data were added in [version](#api_version) 2.\\n"},{"m":"ngx_http_api_module","n":"endpoints","d":"#### Endpoints\\n\\n`/`\\n\\nSupported methods:\\n\\n*   `GET` - Return list of root endpoints\\n    \\n    Returns a list of root endpoints.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns an array of strings\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n\\n`/nginx`\\n\\nSupported methods:\\n\\n*   `GET` - Return status of nginx running instance\\n    \\n    Returns nginx version, build name, address, number of configuration reloads, IDs of master and worker processes.\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of nginx running instance will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [nginx](#def_nginx_object)\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n\\n`/processes`\\n\\nSupported methods:\\n\\n*   `GET` - Return nginx processes status\\n    \\n    Returns the number of abnormally terminated and respawned child processes.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [Processes](#def_nginx_processes)\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n*   `DELETE` - Reset nginx processes statistics\\n    \\n    Resets counters of abnormally terminated and respawned child processes.\\n    \\n    Possible responses:\\n    \\n    *   204 - Success\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n\\n`/connections`\\n\\nSupported methods:\\n\\n*   `GET` - Return client connections statistics\\n    \\n    Returns statistics of client connections.\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of the connections statistics will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [Connections](#def_nginx_connections)\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n*   `DELETE` - Reset client connections statistics\\n    \\n    Resets statistics of accepted and dropped client connections.\\n    \\n    Possible responses:\\n    \\n    *   204 - Success\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n\\n`/slabs/`\\n\\nSupported methods:\\n\\n*   `GET` - Return status of all slabs\\n    \\n    Returns status of slabs for each shared memory zone with slab allocator.\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of slab zones will be output. If the \u201c`fields`\u201d value is empty, then only zone names will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns a collection of \\"[Shared memory zone with slab allocator](#def_nginx_slab_zone)\\" objects for all slabs\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n\\n`/slabs/{slabZoneName}`\\n\\nParameters common for all methods:\\n\\n`slabZoneName` (`string`, required)\\n\\nThe name of the shared memory zone with slab allocator.\\n\\nSupported methods:\\n\\n*   `GET` - Return status of a slab\\n    \\n    Returns status of slabs for a particular shared memory zone with slab allocator.\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of the slab zone will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [Shared memory zone with slab allocator](#def_nginx_slab_zone)\\n    *   404 - Slab not found (`SlabNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n*   `DELETE` - Reset slab statistics\\n    \\n    Resets the \u201c`reqs`\u201d and \u201c`fails`\u201d metrics for each memory slot.\\n    \\n    Possible responses:\\n    \\n    *   204 - Success\\n    *   404 - Slab not found (`SlabNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n\\n`/http/`\\n\\nSupported methods:\\n\\n*   `GET` - Return list of HTTP-related endpoints\\n    \\n    Returns a list of first level HTTP endpoints.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns an array of strings\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n\\n`/http/requests`\\n\\nSupported methods:\\n\\n*   `GET` - Return HTTP requests statistics\\n    \\n    Returns status of client HTTP requests.\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of client HTTP requests statistics will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [HTTP Requests](#def_nginx_http_requests)\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n*   `DELETE` - Reset HTTP requests statistics\\n    \\n    Resets the number of total client HTTP requests.\\n    \\n    Possible responses:\\n    \\n    *   204 - Success\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n\\n`/http/server_zones/`\\n\\nSupported methods:\\n\\n*   `GET` - Return status of all HTTP server zones\\n    \\n    Returns status information for each HTTP [server zone](https://nginx.org/en/docs/http/ngx_http_api_module.html#status_zone).\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of server zones will be output. If the \u201c`fields`\u201d value is empty, then only server zone names will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns a collection of \\"[HTTP Server Zone](#def_nginx_http_server_zone)\\" objects for all HTTP server zones\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n\\n`/http/server_zones/{httpServerZoneName}`\\n\\nParameters common for all methods:\\n\\n`httpServerZoneName` (`string`, required)\\n\\nThe name of an HTTP server zone.\\n\\nSupported methods:\\n\\n*   `GET` - Return status of an HTTP server zone\\n    \\n    Returns status of a particular HTTP server zone.\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of the server zone will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [HTTP Server Zone](#def_nginx_http_server_zone)\\n    *   404 - Server zone not found (`ServerZoneNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n*   `DELETE` - Reset statistics for an HTTP server zone\\n    \\n    Resets statistics of accepted and discarded requests, responses, received and sent bytes in a particular HTTP server zone.\\n    \\n    Possible responses:\\n    \\n    *   204 - Success\\n    *   404 - Server zone not found (`ServerZoneNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n\\n`/http/location_zones/`\\n\\nSupported methods:\\n\\n*   `GET` - Return status of all HTTP location zones\\n    \\n    Returns status information for each HTTP [location zone](https://nginx.org/en/docs/http/ngx_http_api_module.html#status_zone_location).\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of location zones will be output. If the \u201c`fields`\u201d value is empty, then only zone names will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns a collection of \\"[HTTP Location Zone](#def_nginx_http_location_zone)\\" objects for all HTTP location zones\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n\\n`/http/location_zones/{httpLocationZoneName}`\\n\\nParameters common for all methods:\\n\\n`httpLocationZoneName` (`string`, required)\\n\\nThe name of an HTTP [location zone](https://nginx.org/en/docs/http/ngx_http_api_module.html#status_zone_location).\\n\\nSupported methods:\\n\\n*   `GET` - Return status of an HTTP location zone\\n    \\n    Returns status of a particular HTTP [location zone](https://nginx.org/en/docs/http/ngx_http_api_module.html#status_zone_location).\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of the location zone will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [HTTP Location Zone](#def_nginx_http_location_zone)\\n    *   404 - Location zone not found (`LocationZoneNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n*   `DELETE` - Reset statistics for a location zone.\\n    \\n    Resets statistics of accepted and discarded requests, responses, received and sent bytes in a particular location zone.\\n    \\n    Possible responses:\\n    \\n    *   204 - Success\\n    *   404 - Location zone not found (`LocationZoneNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n\\n`/http/caches/`\\n\\nSupported methods:\\n\\n*   `GET` - Return status of all caches\\n    \\n    Returns status of each cache configured by [proxy\\\\_cache\\\\_path](https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_path) and other \u201c`*_cache_path`\u201d directives.\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of cache zones will be output. If the \u201c`fields`\u201d value is empty, then only names of cache zones will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns a collection of \\"[HTTP Cache](#def_nginx_http_cache)\\" objects for all HTTP caches\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n\\n`/http/caches/{httpCacheZoneName}`\\n\\nParameters common for all methods:\\n\\n`httpCacheZoneName` (`string`, required)\\n\\nThe name of the cache zone.\\n\\nSupported methods:\\n\\n*   `GET` - Return status of a cache\\n    \\n    Returns status of a particular cache.\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of the cache zone will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [HTTP Cache](#def_nginx_http_cache)\\n    *   404 - Cache not found (`CacheNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n*   `DELETE` - Reset cache statistics\\n    \\n    Resets statistics of cache hits/misses in a particular cache zone.\\n    \\n    Possible responses:\\n    \\n    *   204 - Success\\n    *   404 - Cache not found (`CacheNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n\\n`/http/limit_conns/`\\n\\nSupported methods:\\n\\n*   `GET` - Return status of all HTTP limit\\\\_conn zones\\n    \\n    Returns status information for each HTTP [limit\\\\_conn zone](https://nginx.org/en/docs/http/ngx_http_limit_conn_module.html#limit_conn_zone).\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of limit\\\\_conn zones will be output. If the \u201c`fields`\u201d value is empty, then only zone names will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns a collection of \\"[HTTP Connections Limiting](#def_nginx_http_limit_conn_zone)\\" objects for all HTTP limit conns\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n\\n`/http/limit_conns/{httpLimitConnZoneName}`\\n\\nParameters common for all methods:\\n\\n`httpLimitConnZoneName` (`string`, required)\\n\\nThe name of a [limit\\\\_conn zone](https://nginx.org/en/docs/http/ngx_http_limit_conn_module.html#limit_conn_zone).\\n\\nSupported methods:\\n\\n*   `GET` - Return status of an HTTP limit\\\\_conn zone\\n    \\n    Returns status of a particular HTTP [limit\\\\_conn zone](https://nginx.org/en/docs/http/ngx_http_limit_conn_module.html#limit_conn_zone).\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of the [limit\\\\_conn zone](https://nginx.org/en/docs/http/ngx_http_limit_conn_module.html#limit_conn_zone) will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [HTTP Connections Limiting](#def_nginx_http_limit_conn_zone)\\n    *   404 - limit\\\\_conn not found (`LimitConnNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n*   `DELETE` - Reset statistics for an HTTP limit\\\\_conn zone\\n    \\n    Resets the connection limiting statistics.\\n    \\n    Possible responses:\\n    \\n    *   204 - Success\\n    *   404 - limit\\\\_conn not found (`LimitConnNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n\\n`/http/limit_reqs/`\\n\\nSupported methods:\\n\\n*   `GET` - Return status of all HTTP limit\\\\_req zones\\n    \\n    Returns status information for each HTTP [limit\\\\_req zone](https://nginx.org/en/docs/http/ngx_http_limit_req_module.html#limit_req_zone).\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of limit\\\\_req zones will be output. If the \u201c`fields`\u201d value is empty, then only zone names will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns a collection of \\"[HTTP Requests Rate Limiting](#def_nginx_http_limit_req_zone)\\" objects for all HTTP limit reqs\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n\\n`/http/limit_reqs/{httpLimitReqZoneName}`\\n\\nParameters common for all methods:\\n\\n`httpLimitReqZoneName` (`string`, required)\\n\\nThe name of a [limit\\\\_req zone](https://nginx.org/en/docs/http/ngx_http_limit_req_module.html#limit_req_zone).\\n\\nSupported methods:\\n\\n*   `GET` - Return status of an HTTP limit\\\\_req zone\\n    \\n    Returns status of a particular HTTP [limit\\\\_req zone](https://nginx.org/en/docs/http/ngx_http_limit_req_module.html#limit_req_zone).\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of the [limit\\\\_req zone](https://nginx.org/en/docs/http/ngx_http_limit_req_module.html#limit_req_zone) will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [HTTP Requests Rate Limiting](#def_nginx_http_limit_req_zone)\\n    *   404 - limit\\\\_req not found (`LimitReqNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n*   `DELETE` - Reset statistics for an HTTP limit\\\\_req zone\\n    \\n    Resets the requests limiting statistics.\\n    \\n    Possible responses:\\n    \\n    *   204 - Success\\n    *   404 - limit\\\\_req not found (`LimitReqNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n\\n`/http/upstreams/`\\n\\nSupported methods:\\n\\n*   `GET` - Return status of all HTTP upstream server groups\\n    \\n    Returns status of each HTTP upstream server group and its servers.\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of upstream server groups will be output. If the \u201c`fields`\u201d value is empty, only names of upstreams will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns a collection of \\"[HTTP Upstream](#def_nginx_http_upstream)\\" objects for all HTTP upstreams\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n\\n`/http/upstreams/{httpUpstreamName}/`\\n\\nParameters common for all methods:\\n\\n`httpUpstreamName` (`string`, required)\\n\\nThe name of an HTTP upstream server group.\\n\\nSupported methods:\\n\\n*   `GET` - Return status of an HTTP upstream server group\\n    \\n    Returns status of a particular HTTP upstream server group and its servers.\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of the upstream server group will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [HTTP Upstream](#def_nginx_http_upstream)\\n    *   400 - Upstream is static (`UpstreamStatic`), returns [Error](#def_nginx_error)\\n    *   404 - Unknown version (`UnknownVersion`), upstream not found (`UpstreamNotFound`), returns [Error](#def_nginx_error)\\n*   `DELETE` - Reset statistics of an HTTP upstream server group\\n    \\n    Resets the statistics for each upstream server in an upstream server group and queue statistics.\\n    \\n    Possible responses:\\n    \\n    *   204 - Success\\n    *   400 - Upstream is static (`UpstreamStatic`), returns [Error](#def_nginx_error)\\n    *   404 - Unknown version (`UnknownVersion`), upstream not found (`UpstreamNotFound`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n\\n`/http/upstreams/{httpUpstreamName}/servers/`\\n\\nParameters common for all methods:\\n\\n`httpUpstreamName` (`string`, required)\\n\\nThe name of an upstream server group.\\n\\nSupported methods:\\n\\n*   `GET` - Return configuration of all servers in an HTTP upstream server group\\n    \\n    Returns configuration of each server in a particular HTTP upstream server group.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns an array of [HTTP Upstream Servers](#def_nginx_http_upstream_conf_server)\\n    *   400 - Upstream is static (`UpstreamStatic`), returns [Error](#def_nginx_error)\\n    *   404 - Unknown version (`UnknownVersion`), upstream not found (`UpstreamNotFound`), returns [Error](#def_nginx_error)\\n*   `POST` - Add a server to an HTTP upstream server group\\n    \\n    Adds a new server to an HTTP upstream server group. Server parameters are specified in the JSON format.\\n    \\n    Request parameters:\\n    \\n    `postHttpUpstreamServer` ([HTTP Upstream Server](#def_nginx_http_upstream_conf_server), required)\\n    \\n    Address of a new server and other optional parameters in the JSON format. The \u201c`ID`\u201d, \u201c`backup`\u201d, and \u201c`service`\u201d parameters cannot be changed.\\n    \\n    Possible responses:\\n    \\n    *   201 - Created, returns [HTTP Upstream Server](#def_nginx_http_upstream_conf_server)\\n    *   400 - Upstream is static (`UpstreamStatic`), invalid \u201c`_parameter_`\u201d value (`UpstreamConfFormatError`), missing \u201c`server`\u201d argument (`UpstreamConfFormatError`), unknown parameter \u201c`_name_`\u201d (`UpstreamConfFormatError`), nested object or list (`UpstreamConfFormatError`), \u201c`error`\u201d while parsing (`UpstreamBadAddress`), service upstream \u201c`host`\u201d may not have port (`UpstreamBadAddress`), service upstream \u201c`host`\u201d requires domain name (`UpstreamBadAddress`), invalid \u201c`weight`\u201d (`UpstreamBadWeight`), invalid \u201c`max_conns`\u201d (`UpstreamBadMaxConns`), invalid \u201c`max_fails`\u201d (`UpstreamBadMaxFails`), invalid \u201c`fail_timeout`\u201d (`UpstreamBadFailTimeout`), invalid \u201c`slow_start`\u201d (`UpstreamBadSlowStart`), reading request body failed `BodyReadError`), route is too long (`UpstreamBadRoute`), \u201c`service`\u201d is empty (`UpstreamBadService`), no resolver defined to resolve (`UpstreamConfNoResolver`), upstream \u201c`_name_`\u201d has no backup (`UpstreamNoBackup`), upstream \u201c`_name_`\u201d memory exhausted (`UpstreamOutOfMemory`), returns [Error](#def_nginx_error)\\n    *   404 - Unknown version (`UnknownVersion`), upstream not found (`UpstreamNotFound`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n    *   409 - Entry exists (`EntryExists`), returns [Error](#def_nginx_error)\\n    *   415 - JSON error (`JsonError`), returns [Error](#def_nginx_error)\\n\\n`/http/upstreams/{httpUpstreamName}/servers/{httpUpstreamServerId}`\\n\\nParameters common for all methods:\\n\\n`httpUpstreamName` (`string`, required)\\n\\nThe name of the upstream server group.\\n\\n`httpUpstreamServerId` (`string`, required)\\n\\nThe ID of the server.\\n\\nSupported methods:\\n\\n*   `GET` - Return configuration of a server in an HTTP upstream server group\\n    \\n    Returns configuration of a particular server in the HTTP upstream server group.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [HTTP Upstream Server](#def_nginx_http_upstream_conf_server)\\n    *   400 - Upstream is static (`UpstreamStatic`), invalid server ID (`UpstreamBadServerId`), returns [Error](#def_nginx_error)\\n    *   404 - Server with ID \u201c`_id_`\u201d does not exist (`UpstreamServerNotFound`), unknown version (`UnknownVersion`), upstream not found (`UpstreamNotFound`), returns [Error](#def_nginx_error)\\n*   `PATCH` - Modify a server in an HTTP upstream server group\\n    \\n    Modifies settings of a particular server in an HTTP upstream server group. Server parameters are specified in the JSON format.\\n    \\n    Request parameters:\\n    \\n    `patchHttpUpstreamServer` ([HTTP Upstream Server](#def_nginx_http_upstream_conf_server), required)\\n    \\n    Server parameters, specified in the JSON format. The \u201c`ID`\u201d, \u201c`backup`\u201d, and \u201c`service`\u201d parameters cannot be changed.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [HTTP Upstream Server](#def_nginx_http_upstream_conf_server)\\n    *   400 - Upstream is static (`UpstreamStatic`), invalid \u201c`_parameter_`\u201d value (`UpstreamConfFormatError`), unknown parameter \u201c`_name_`\u201d (`UpstreamConfFormatError`), nested object or list (`UpstreamConfFormatError`), \u201c`error`\u201d while parsing (`UpstreamBadAddress`), invalid \u201c`server`\u201d argument (`UpstreamBadAddress`), invalid server ID (`UpstreamBadServerId`), invalid \u201c`weight`\u201d (`UpstreamBadWeight`), invalid \u201c`max_conns`\u201d (`UpstreamBadMaxConns`), invalid \u201c`max_fails`\u201d (`UpstreamBadMaxFails`), invalid \u201c`fail_timeout`\u201d (`UpstreamBadFailTimeout`), invalid \u201c`slow_start`\u201d (`UpstreamBadSlowStart`), reading request body failed `BodyReadError`), route is too long (`UpstreamBadRoute`), \u201c`service`\u201d is empty (`UpstreamBadService`), server \u201c`_ID_`\u201d address is immutable (`UpstreamServerImmutable`), server \u201c`ID`\u201d weight is immutable (`UpstreamServerWeightImmutable`), upstream \u201c`name`\u201d memory exhausted (`UpstreamOutOfMemory`), returns [Error](#def_nginx_error)\\n    *   404 - Server with ID \u201c`_id_`\u201d does not exist (`UpstreamServerNotFound`), unknown version (`UnknownVersion`), upstream not found (`UpstreamNotFound`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n    *   415 - JSON error (`JsonError`), returns [Error](#def_nginx_error)\\n*   `DELETE` - Remove a server from an HTTP upstream server group\\n    \\n    Removes a server from an HTTP upstream server group.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns an array of [HTTP Upstream Servers](#def_nginx_http_upstream_conf_server)\\n    *   400 - Upstream is static (`UpstreamStatic`), invalid server ID (`UpstreamBadServerId`), server \u201c`_id_`\u201d not removable (`UpstreamServerImmutable`), returns [Error](#def_nginx_error)\\n    *   404 - Server with ID \u201c`_id_`\u201d does not exist (`UpstreamServerNotFound`), unknown version (`UnknownVersion`), upstream not found (`UpstreamNotFound`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n\\n`/http/keyvals/`\\n\\nSupported methods:\\n\\n*   `GET` - Return key-value pairs from all HTTP keyval zones\\n    \\n    Returns key-value pairs for each HTTP keyval shared memory [zone](https://nginx.org/en/docs/http/ngx_http_keyval_module.html#keyval_zone).\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    If the \u201c`fields`\u201d value is empty, then only HTTP keyval zone names will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns a collection of \\"[HTTP Keyval Shared Memory Zone](#def_nginx_http_keyval_zone)\\" objects for all HTTP keyvals\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n\\n`/http/keyvals/{httpKeyvalZoneName}`\\n\\nParameters common for all methods:\\n\\n`httpKeyvalZoneName` (`string`, required)\\n\\nThe name of an HTTP keyval shared memory zone.\\n\\nSupported methods:\\n\\n*   `GET` - Return key-value pairs from an HTTP keyval zone\\n    \\n    Returns key-value pairs stored in a particular HTTP keyval shared memory [zone](https://nginx.org/en/docs/http/ngx_http_keyval_module.html#keyval_zone).\\n    \\n    Request parameters:\\n    \\n    `key` (`string`, optional)\\n    \\n    Get a particular key-value pair from the HTTP keyval zone.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [HTTP Keyval Shared Memory Zone](#def_nginx_http_keyval_zone)\\n    *   404 - Keyval not found (`KeyvalNotFound`), keyval key not found (`KeyvalKeyNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n*   `POST` - Add a key-value pair to the HTTP keyval zone\\n    \\n    Adds a new key-value pair to the HTTP keyval shared memory [zone](https://nginx.org/en/docs/http/ngx_http_keyval_module.html#keyval_zone). Several key-value pairs can be entered if the HTTP keyval shared memory zone is empty.\\n    \\n    Request parameters:\\n    \\n    `Key-value` ([HTTP Keyval Shared Memory Zone](#def_nginx_http_keyval_zone_post_patch), required)\\n    \\n    A key-value pair is specified in the JSON format. Several key-value pairs can be entered if the HTTP keyval shared memory zone is empty. Expiration time in milliseconds can be specified for a key-value pair with the `expire` parameter which overrides the [`timeout`](https://nginx.org/en/docs/http/ngx_http_keyval_module.html#keyval_timeout) parameter of the [keyval\\\\_zone](https://nginx.org/en/docs/http/ngx_http_keyval_module.html#keyval_zone) directive.\\n    \\n    Possible responses:\\n    \\n    *   201 - Created\\n    *   400 - Invalid JSON (`KeyvalFormatError`), invalid key format (`KeyvalFormatError`), key required (`KeyvalFormatError`), keyval timeout is not enabled (`KeyvalFormatError`), only one key can be added (`KeyvalFormatError`), reading request body failed `BodyReadError`), returns [Error](#def_nginx_error)\\n    *   404 - Keyval not found (`KeyvalNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n    *   409 - Entry exists (`EntryExists`), key already exists (`KeyvalKeyExists`), returns [Error](#def_nginx_error)\\n    *   413 - Request Entity Too Large, returns [Error](#def_nginx_error)\\n    *   415 - JSON error (`JsonError`), returns [Error](#def_nginx_error)\\n*   `PATCH` - Modify a key-value or delete a key\\n    \\n    Changes the value of the selected key in the key-value pair, deletes a key by setting the key value to `null`, changes expiration time of a key-value pair. If [synchronization](https://nginx.org/en/docs/stream/ngx_stream_zone_sync_module.html#zone_sync) of keyval zones in a cluster is enabled, deletes a key only on a target cluster node. Expiration time in milliseconds can be specified for a key-value pair with the `expire` parameter which overrides the [`timeout`](https://nginx.org/en/docs/http/ngx_http_keyval_module.html#keyval_timeout) parameter of the [keyval\\\\_zone](https://nginx.org/en/docs/http/ngx_http_keyval_module.html#keyval_zone) directive.\\n    \\n    Request parameters:\\n    \\n    `httpKeyvalZoneKeyValue` ([HTTP Keyval Shared Memory Zone](#def_nginx_http_keyval_zone_post_patch), required)\\n    \\n    A new value for the key is specified in the JSON format.\\n    \\n    Possible responses:\\n    \\n    *   204 - Success\\n    *   400 - Invalid JSON (`KeyvalFormatError`), key required (`KeyvalFormatError`), keyval timeout is not enabled (`KeyvalFormatError`), only one key can be updated (`KeyvalFormatError`), reading request body failed `BodyReadError`), returns [Error](#def_nginx_error)\\n    *   404 - Keyval not found (`KeyvalNotFound`), keyval key not found (`KeyvalKeyNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n    *   413 - Request Entity Too Large, returns [Error](#def_nginx_error)\\n    *   415 - JSON error (`JsonError`), returns [Error](#def_nginx_error)\\n*   `DELETE` - Empty the HTTP keyval zone\\n    \\n    Deletes all key-value pairs from the HTTP keyval shared memory [zone](https://nginx.org/en/docs/http/ngx_http_keyval_module.html#keyval_zone). If [synchronization](https://nginx.org/en/docs/stream/ngx_stream_zone_sync_module.html#zone_sync) of keyval zones in a cluster is enabled, empties the keyval zone only on a target cluster node.\\n    \\n    Possible responses:\\n    \\n    *   204 - Success\\n    *   404 - Keyval not found (`KeyvalNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n\\n`/stream/`\\n\\nSupported methods:\\n\\n*   `GET` - Return list of stream-related endpoints\\n    \\n    Returns a list of first level stream endpoints.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns an array of strings\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n\\n`/stream/server_zones/`\\n\\nSupported methods:\\n\\n*   `GET` - Return status of all stream server zones\\n    \\n    Returns status information for each stream [server zone](https://nginx.org/en/docs/http/ngx_http_api_module.html#status_zone).\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of server zones will be output. If the \u201c`fields`\u201d value is empty, then only server zone names will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns a collection of \\"[Stream Server Zone](#def_nginx_stream_server_zone)\\" objects for all stream server zones\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n\\n`/stream/server_zones/{streamServerZoneName}`\\n\\nParameters common for all methods:\\n\\n`streamServerZoneName` (`string`, required)\\n\\nThe name of a stream server zone.\\n\\nSupported methods:\\n\\n*   `GET` - Return status of a stream server zone\\n    \\n    Returns status of a particular stream server zone.\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of the server zone will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [Stream Server Zone](#def_nginx_stream_server_zone)\\n    *   404 - Server zone not found (`ServerZoneNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n*   `DELETE` - Reset statistics for a stream server zone\\n    \\n    Resets statistics of accepted and discarded connections, sessions, received and sent bytes in a particular stream server zone.\\n    \\n    Possible responses:\\n    \\n    *   204 - Success\\n    *   404 - Server zone not found (`ServerZoneNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n\\n`/stream/limit_conns/`\\n\\nSupported methods:\\n\\n*   `GET` - Return status of all stream limit\\\\_conn zones\\n    \\n    Returns status information for each stream [limit\\\\_conn zone](https://nginx.org/en/docs/stream/ngx_stream_limit_conn_module.html#limit_conn_zone).\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of limit\\\\_conn zones will be output. If the \u201c`fields`\u201d value is empty, then only zone names will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns a collection of \\"[Stream Connections Limiting](#def_nginx_stream_limit_conn_zone)\\" objects for all stream limit conns\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n\\n`/stream/limit_conns/{streamLimitConnZoneName}`\\n\\nParameters common for all methods:\\n\\n`streamLimitConnZoneName` (`string`, required)\\n\\nThe name of a [limit\\\\_conn zone](https://nginx.org/en/docs/stream/ngx_stream_limit_conn_module.html#limit_conn_zone).\\n\\nSupported methods:\\n\\n*   `GET` - Return status of an stream limit\\\\_conn zone\\n    \\n    Returns status of a particular stream [limit\\\\_conn zone](https://nginx.org/en/docs/stream/ngx_stream_limit_conn_module.html#limit_conn_zone).\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of the [limit\\\\_conn zone](https://nginx.org/en/docs/stream/ngx_stream_limit_conn_module.html#limit_conn_zone) will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [Stream Connections Limiting](#def_nginx_stream_limit_conn_zone)\\n    *   404 - limit\\\\_conn not found (`LimitConnNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n*   `DELETE` - Reset statistics for a stream limit\\\\_conn zone\\n    \\n    Resets the connection limiting statistics.\\n    \\n    Possible responses:\\n    \\n    *   204 - Success\\n    *   404 - limit\\\\_conn not found (`LimitConnNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n\\n`/stream/upstreams/`\\n\\nSupported methods:\\n\\n*   `GET` - Return status of all stream upstream server groups\\n    \\n    Returns status of each stream upstream server group and its servers.\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of upstream server groups will be output. If the \u201c`fields`\u201d value is empty, only names of upstreams will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns a collection of \\"[Stream Upstream](#def_nginx_stream_upstream)\\" objects for all stream upstreams\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n\\n`/stream/upstreams/{streamUpstreamName}/`\\n\\nParameters common for all methods:\\n\\n`streamUpstreamName` (`string`, required)\\n\\nThe name of a stream upstream server group.\\n\\nSupported methods:\\n\\n*   `GET` - Return status of a stream upstream server group\\n    \\n    Returns status of a particular stream upstream server group and its servers.\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of the upstream server group will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [Stream Upstream](#def_nginx_stream_upstream)\\n    *   400 - Upstream is static (`UpstreamStatic`), returns [Error](#def_nginx_error)\\n    *   404 - Unknown version (`UnknownVersion`), upstream not found (`UpstreamNotFound`), returns [Error](#def_nginx_error)\\n*   `DELETE` - Reset statistics of a stream upstream server group\\n    \\n    Resets the statistics for each upstream server in an upstream server group.\\n    \\n    Possible responses:\\n    \\n    *   204 - Success\\n    *   400 - Upstream is static (`UpstreamStatic`), returns [Error](#def_nginx_error)\\n    *   404 - Unknown version (`UnknownVersion`), upstream not found (`UpstreamNotFound`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n\\n`/stream/upstreams/{streamUpstreamName}/servers/`\\n\\nParameters common for all methods:\\n\\n`streamUpstreamName` (`string`, required)\\n\\nThe name of an upstream server group.\\n\\nSupported methods:\\n\\n*   `GET` - Return configuration of all servers in a stream upstream server group\\n    \\n    Returns configuration of each server in a particular stream upstream server group.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns an array of [Stream Upstream Servers](#def_nginx_stream_upstream_conf_server)\\n    *   400 - Upstream is static (`UpstreamStatic`), returns [Error](#def_nginx_error)\\n    *   404 - Unknown version (`UnknownVersion`), upstream not found (`UpstreamNotFound`), returns [Error](#def_nginx_error)\\n*   `POST` - Add a server to a stream upstream server group\\n    \\n    Adds a new server to a stream upstream server group. Server parameters are specified in the JSON format.\\n    \\n    Request parameters:\\n    \\n    `postStreamUpstreamServer` ([Stream Upstream Server](#def_nginx_stream_upstream_conf_server), required)\\n    \\n    Address of a new server and other optional parameters in the JSON format. The \u201c`ID`\u201d, \u201c`backup`\u201d, and \u201c`service`\u201d parameters cannot be changed.\\n    \\n    Possible responses:\\n    \\n    *   201 - Created, returns [Stream Upstream Server](#def_nginx_stream_upstream_conf_server)\\n    *   400 - Upstream is static (`UpstreamStatic`), invalid \u201c`_parameter_`\u201d value (`UpstreamConfFormatError`), missing \u201c`server`\u201d argument (`UpstreamConfFormatError`), unknown parameter \u201c`_name_`\u201d (`UpstreamConfFormatError`), nested object or list (`UpstreamConfFormatError`), \u201c`error`\u201d while parsing (`UpstreamBadAddress`), no port in server \u201c`host`\u201d (`UpstreamBadAddress`), service upstream \u201c`host`\u201d may not have port (`UpstreamBadAddress`), service upstream \u201c`host`\u201d requires domain name (`UpstreamBadAddress`), invalid \u201c`weight`\u201d (`UpstreamBadWeight`), invalid \u201c`max_conns`\u201d (`UpstreamBadMaxConns`), invalid \u201c`max_fails`\u201d (`UpstreamBadMaxFails`), invalid \u201c`fail_timeout`\u201d (`UpstreamBadFailTimeout`), invalid \u201c`slow_start`\u201d (`UpstreamBadSlowStart`), \u201c`service`\u201d is empty (`UpstreamBadService`), no resolver defined to resolve (`UpstreamConfNoResolver`), upstream \u201c`_name_`\u201d has no backup (`UpstreamNoBackup`), upstream \u201c`_name_`\u201d memory exhausted (`UpstreamOutOfMemory`), reading request body failed `BodyReadError`), returns [Error](#def_nginx_error)\\n    *   404 - Unknown version (`UnknownVersion`), upstream not found (`UpstreamNotFound`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n    *   409 - Entry exists (`EntryExists`), returns [Error](#def_nginx_error)\\n    *   415 - JSON error (`JsonError`), returns [Error](#def_nginx_error)\\n\\n`/stream/upstreams/{streamUpstreamName}/servers/{streamUpstreamServerId}`\\n\\nParameters common for all methods:\\n\\n`streamUpstreamName` (`string`, required)\\n\\nThe name of the upstream server group.\\n\\n`streamUpstreamServerId` (`string`, required)\\n\\nThe ID of the server.\\n\\nSupported methods:\\n\\n*   `GET` - Return configuration of a server in a stream upstream server group\\n    \\n    Returns configuration of a particular server in the stream upstream server group.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [Stream Upstream Server](#def_nginx_stream_upstream_conf_server)\\n    *   400 - Upstream is static (`UpstreamStatic`), invalid server ID (`UpstreamBadServerId`), returns [Error](#def_nginx_error)\\n    *   404 - Unknown version (`UnknownVersion`), upstream not found (`UpstreamNotFound`), server with ID \u201c`_id_`\u201d does not exist (`UpstreamServerNotFound`), returns [Error](#def_nginx_error)\\n*   `PATCH` - Modify a server in a stream upstream server group\\n    \\n    Modifies settings of a particular server in a stream upstream server group. Server parameters are specified in the JSON format.\\n    \\n    Request parameters:\\n    \\n    `patchStreamUpstreamServer` ([Stream Upstream Server](#def_nginx_stream_upstream_conf_server), required)\\n    \\n    Server parameters, specified in the JSON format. The \u201c`ID`\u201d, \u201c`backup`\u201d, and \u201c`service`\u201d parameters cannot be changed.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [Stream Upstream Server](#def_nginx_stream_upstream_conf_server)\\n    *   400 - Upstream is static (`UpstreamStatic`), invalid \u201c`_parameter_`\u201d value (`UpstreamConfFormatError`), unknown parameter \u201c`_name_`\u201d (`UpstreamConfFormatError`), nested object or list (`UpstreamConfFormatError`), \u201c`error`\u201d while parsing (`UpstreamBadAddress`), invalid \u201c`server`\u201d argument (`UpstreamBadAddress`), no port in server \u201c`host`\u201d (`UpstreamBadAddress`), invalid server ID (`UpstreamBadServerId`), invalid \u201c`weight`\u201d (`UpstreamBadWeight`), invalid \u201c`max_conns`\u201d (`UpstreamBadMaxConns`), invalid \u201c`max_fails`\u201d (`UpstreamBadMaxFails`), invalid \u201c`fail_timeout`\u201d (`UpstreamBadFailTimeout`), invalid \u201c`slow_start`\u201d (`UpstreamBadSlowStart`), reading request body failed `BodyReadError`), \u201c`service`\u201d is empty (`UpstreamBadService`), server \u201c`_ID_`\u201d address is immutable (`UpstreamServerImmutable`), server \u201c`_ID_`\u201d weight is immutable (`UpstreamServerWeightImmutable`), upstream \u201c`name`\u201d memory exhausted (`UpstreamOutOfMemory`), returns [Error](#def_nginx_error)\\n    *   404 - Server with ID \u201c`_id_`\u201d does not exist (`UpstreamServerNotFound`), unknown version (`UnknownVersion`), upstream not found (`UpstreamNotFound`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n    *   415 - JSON error (`JsonError`), returns [Error](#def_nginx_error)\\n*   `DELETE` - Remove a server from a stream upstream server group\\n    \\n    Removes a server from a stream server group.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns an array of [Stream Upstream Servers](#def_nginx_stream_upstream_conf_server)\\n    *   400 - Upstream is static (`UpstreamStatic`), invalid server ID (`UpstreamBadServerId`), server \u201c`_id_`\u201d not removable (`UpstreamServerImmutable`), returns [Error](#def_nginx_error)\\n    *   404 - Server with ID \u201c`_id_`\u201d does not exist (`UpstreamServerNotFound`), unknown version (`UnknownVersion`), upstream not found (`UpstreamNotFound`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n\\n`/stream/keyvals/`\\n\\nSupported methods:\\n\\n*   `GET` - Return key-value pairs from all stream keyval zones\\n    \\n    Returns key-value pairs for each stream keyval shared memory [zone](https://nginx.org/en/docs/stream/ngx_stream_keyval_module.html#keyval_zone).\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    If the \u201c`fields`\u201d value is empty, then only stream keyval zone names will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns a collection of \\"[Stream Keyval Shared Memory Zone](#def_nginx_stream_keyval_zone)\\" objects for all stream keyvals\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n\\n`/stream/keyvals/{streamKeyvalZoneName}`\\n\\nParameters common for all methods:\\n\\n`streamKeyvalZoneName` (`string`, required)\\n\\nThe name of a stream keyval shared memory zone.\\n\\nSupported methods:\\n\\n*   `GET` - Return key-value pairs from a stream keyval zone\\n    \\n    Returns key-value pairs stored in a particular stream keyval shared memory [zone](https://nginx.org/en/docs/stream/ngx_stream_keyval_module.html#keyval_zone).\\n    \\n    Request parameters:\\n    \\n    `key` (`string`, optional)\\n    \\n    Get a particular key-value pair from the stream keyval zone.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [Stream Keyval Shared Memory Zone](#def_nginx_stream_keyval_zone)\\n    *   404 - Keyval not found (`KeyvalNotFound`), keyval key not found (`KeyvalKeyNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n*   `POST` - Add a key-value pair to the stream keyval zone\\n    \\n    Adds a new key-value pair to the stream keyval shared memory [zone](https://nginx.org/en/docs/stream/ngx_stream_keyval_module.html#keyval_zone). Several key-value pairs can be entered if the stream keyval shared memory zone is empty.\\n    \\n    Request parameters:\\n    \\n    `Key-value` ([Stream Keyval Shared Memory Zone](#def_nginx_stream_keyval_zone_post_patch), required)\\n    \\n    A key-value pair is specified in the JSON format. Several key-value pairs can be entered if the stream keyval shared memory zone is empty. Expiration time in milliseconds can be specified for a key-value pair with the `expire` parameter which overrides the [`timeout`](https://nginx.org/en/docs/stream/ngx_stream_keyval_module.html#keyval_timeout) parameter of the [keyval\\\\_zone](https://nginx.org/en/docs/stream/ngx_stream_keyval_module.html#keyval_zone) directive.\\n    \\n    Possible responses:\\n    \\n    *   201 - Created\\n    *   400 - Invalid JSON (`KeyvalFormatError`), invalid key format (`KeyvalFormatError`), key required (`KeyvalFormatError`), keyval timeout is not enabled (`KeyvalFormatError`), only one key can be added (`KeyvalFormatError`), reading request body failed `BodyReadError`), returns [Error](#def_nginx_error)\\n    *   404 - Keyval not found (`KeyvalNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n    *   409 - Entry exists (`EntryExists`), key already exists (`KeyvalKeyExists`), returns [Error](#def_nginx_error)\\n    *   413 - Request Entity Too Large, returns [Error](#def_nginx_error)\\n    *   415 - JSON error (`JsonError`), returns [Error](#def_nginx_error)\\n*   `PATCH` - Modify a key-value or delete a key\\n    \\n    Changes the value of the selected key in the key-value pair, deletes a key by setting the key value to `null`, changes expiration time of a key-value pair. If [synchronization](https://nginx.org/en/docs/stream/ngx_stream_zone_sync_module.html#zone_sync) of keyval zones in a cluster is enabled, deletes a key only on a target cluster node. Expiration time is specified in milliseconds with the `expire` parameter which overrides the [`timeout`](https://nginx.org/en/docs/stream/ngx_stream_keyval_module.html#keyval_timeout) parameter of the [keyval\\\\_zone](https://nginx.org/en/docs/stream/ngx_stream_keyval_module.html#keyval_zone) directive.\\n    \\n    Request parameters:\\n    \\n    `streamKeyvalZoneKeyValue` ([Stream Keyval Shared Memory Zone](#def_nginx_stream_keyval_zone_post_patch), required)\\n    \\n    A new value for the key is specified in the JSON format.\\n    \\n    Possible responses:\\n    \\n    *   204 - Success\\n    *   400 - Invalid JSON (`KeyvalFormatError`), key required (`KeyvalFormatError`), keyval timeout is not enabled (`KeyvalFormatError`), only one key can be updated (`KeyvalFormatError`), reading request body failed `BodyReadError`), returns [Error](#def_nginx_error)\\n    *   404 - Keyval not found (`KeyvalNotFound`), keyval key not found (`KeyvalKeyNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n    *   413 - Request Entity Too Large, returns [Error](#def_nginx_error)\\n    *   415 - JSON error (`JsonError`), returns [Error](#def_nginx_error)\\n*   `DELETE` - Empty the stream keyval zone\\n    \\n    Deletes all key-value pairs from the stream keyval shared memory [zone](https://nginx.org/en/docs/stream/ngx_stream_keyval_module.html#keyval_zone). If [synchronization](https://nginx.org/en/docs/stream/ngx_stream_zone_sync_module.html#zone_sync) of keyval zones in a cluster is enabled, empties the keyval zone only on a target cluster node.\\n    \\n    Possible responses:\\n    \\n    *   204 - Success\\n    *   404 - Keyval not found (`KeyvalNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n\\n`/stream/zone_sync/`\\n\\nSupported methods:\\n\\n*   `GET` - Return sync status of a node\\n    \\n    Returns synchronization status of a cluster node.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [Stream Zone Sync Node](#def_nginx_stream_zone_sync)\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n\\n`/resolvers/`\\n\\nSupported methods:\\n\\n*   `GET` - Return status for all resolver zones\\n    \\n    Returns status information for each [resolver zone](https://nginx.org/en/docs/http/ngx_http_core_module.html#resolver_status_zone).\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of resolvers statistics will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns a collection of \\"[Resolver Zone](#def_nginx_resolver_zone)\\" objects for all resolvers\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n\\n`/resolvers/{resolverZoneName}`\\n\\nParameters common for all methods:\\n\\n`resolverZoneName` (`string`, required)\\n\\nThe name of a resolver zone.\\n\\nSupported methods:\\n\\n*   `GET` - Return statistics of a resolver zone\\n    \\n    Returns statistics stored in a particular resolver [zone](https://nginx.org/en/docs/http/ngx_http_core_module.html#resolver_status_zone).\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of the resolver zone will be output (requests, responses, or both).\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [Resolver Zone](#def_nginx_resolver_zone)\\n    *   404 - Resolver zone not found (`ResolverZoneNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n*   `DELETE` - Reset statistics for a resolver zone.\\n    \\n    Resets statistics in a particular resolver zone.\\n    \\n    Possible responses:\\n    \\n    *   204 - Success\\n    *   404 - Resolver zone not found (`ResolverZoneNotFound`), unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n\\n`/ssl`\\n\\nSupported methods:\\n\\n*   `GET` - Return SSL statistics\\n    \\n    Returns SSL statistics.\\n    \\n    Request parameters:\\n    \\n    `fields` (`string`, optional)\\n    \\n    Limits which fields of SSL statistics will be output.\\n    \\n    Possible responses:\\n    \\n    *   200 - Success, returns [SSL](#def_nginx_ssl_object)\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n*   `DELETE` - Reset SSL statistics\\n    \\n    Resets counters of SSL handshakes and session reuses.\\n    \\n    Possible responses:\\n    \\n    *   204 - Success\\n    *   404 - Unknown version (`UnknownVersion`), returns [Error](#def_nginx_error)\\n    *   405 - Method disabled (`MethodDisabled`), returns [Error](#def_nginx_error)\\n"},{"m":"ngx_http_auth_basic_module","n":"summary","d":"The `ngx_http_auth_basic_module` module allows limiting access to resources by validating the user name and password using the \u201cHTTP Basic Authentication\u201d protocol.\\nAccess can also be limited by [address](ngx_http_access_module.html), by the [result of subrequest](ngx_http_auth_request_module.html), or by [JWT](ngx_http_auth_jwt_module.html). Simultaneous limitation of access by address and by password is controlled by the [satisfy](ngx_http_core_module.html#satisfy) directive."},{"m":"ngx_http_auth_basic_module","n":"auth_basic","d":"Enables validation of user name and password using the \u201cHTTP Basic Authentication\u201d protocol. The specified parameter is used as a `_realm_`. Parameter value can contain variables (1.3.10, 1.2.7). The special value `off` cancels the effect of the `auth_basic` directive inherited from the previous configuration level."},{"m":"ngx_http_auth_jwt_module","n":"summary","d":"The `ngx_http_auth_jwt_module` module (1.11.3) implements client authorization by validating the provided [JSON Web Token](https://tools.ietf.org/html/rfc7519) (JWT) using the specified keys. JWT claims must be encoded in a [JSON Web Signature](https://tools.ietf.org/html/rfc7515) (JWS) structure. The module can be used for [OpenID Connect](http://openid.net/specs/openid-connect-core-1_0.html) authentication.\\nThe module may be combined with other access modules, such as [ngx\\\\_http\\\\_access\\\\_module](ngx_http_access_module.html), [ngx\\\\_http\\\\_auth\\\\_basic\\\\_module](ngx_http_auth_basic_module.html), and [ngx\\\\_http\\\\_auth\\\\_request\\\\_module](ngx_http_auth_request_module.html), via the [satisfy](ngx_http_core_module.html#satisfy) directive.\\nThe module supports the following cryptographic [algorithms](https://www.iana.org/assignments/jose/jose.xhtml#web-signature-encryption-algorithms):\\n*   HS256, HS384, HS512\\n*   RS256, RS384, RS512\\n*   ES256, ES384, ES512\\n*   EdDSA (Ed25519 and Ed448 signatures) (1.15.7)\\nPrior to version 1.13.7, only HS256, RS256, ES256 algorithms were supported.\\n\\nThis module is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_auth_jwt_module","n":"auth_jwt","d":"Enables validation of JSON Web Token. The specified `_string_` is used as a `realm`. Parameter value can contain variables.\\nThe optional `token` parameter specifies a variable that contains JSON Web Token. By default, JWT is passed in the \u201cAuthorization\u201d header as a [Bearer Token](https://tools.ietf.org/html/rfc6750). JWT may be also passed as a cookie or a part of a query string:\\n```\\nauth_jwt \\"closed site\\" token=$cookie_auth_token;\\n\\n```\\n\\nThe special value `off` cancels the effect of the `auth_jwt` directive inherited from the previous configuration level."},{"m":"ngx_http_auth_jwt_module","n":"auth_jwt_claim_set","d":"Sets the `_variable_` to a JWT claim parameter identified by key names. Name matching starts from the top level of the JSON tree. For arrays, the variable keeps a list of array elements separated by commas.\\n```\\nauth_jwt_claim_set $email info e-mail;\\nauth_jwt_claim_set $job info \\"job title\\";\\n\\n```\\n\\nPrior to version 1.13.7, only one key name could be specified, and the result was undefined for arrays.\\n"},{"m":"ngx_http_auth_jwt_module","n":"auth_jwt_header_set","d":"Sets the `_variable_` to a JOSE header parameter identified by key names. Name matching starts from the top level of the JSON tree. For arrays, the variable keeps a list of array elements separated by commas.\\nPrior to version 1.13.7, only one key name could be specified, and the result was undefined for arrays.\\n"},{"m":"ngx_http_auth_jwt_module","n":"auth_jwt_key_file","d":"Specifies a `_file_` in [JSON Web Key Set](https://tools.ietf.org/html/rfc7517#section-5) format for validating JWT signature. Parameter value can contain variables."},{"m":"ngx_http_auth_jwt_module","n":"auth_jwt_key_request","d":"Allows retrieving a [JSON Web Key Set](https://tools.ietf.org/html/rfc7517#section-5) file from a subrequest for validating JWT signature and sets the URI where the subrequest will be sent to. To avoid validation overhead, it is recommended to cache the key file:\\n```\\nproxy_cache_path /data/nginx/cache levels=1 keys_zone=foo:10m;\\n\\nserver {\\n    ...\\n\\n    location / {\\n        auth_jwt             \\"closed site\\";\\n        auth_jwt_key_request /jwks_uri;\\n    }\\n\\n    location = /jwks_uri {\\n        internal;\\n        proxy_cache foo;\\n        proxy_pass  http://idp.example.com/keys;\\n    }\\n}\\n\\n```\\n"},{"m":"ngx_http_auth_jwt_module","n":"auth_jwt_leeway","d":"Sets the maximum allowable leeway to compensate clock skew when verifying the [exp](https://tools.ietf.org/html/rfc7519#section-4.1.4) and [nbf](https://tools.ietf.org/html/rfc7519#section-4.1.5) JWT claims."},{"m":"ngx_http_auth_jwt_module","n":"$jwt_header_name","d":"returns the value of a specified [JWT claim](https://tools.ietf.org/html/rfc7519#section-4)\\n\\nFor nested claims and claims including a dot (\u201c.\u201d), the value of the variable cannot be evaluated; the [auth\\\\_jwt\\\\_claim\\\\_set](#auth_jwt_claim_set) directive should be used instead."},{"m":"ngx_http_auth_jwt_module","n":"$jwt_claim_name","d":"returns the value of a specified [JWT claim](https://tools.ietf.org/html/rfc7519#section-4)\\n\\nFor nested claims and claims including a dot (\u201c.\u201d), the value of the variable cannot be evaluated; the [auth\\\\_jwt\\\\_claim\\\\_set](#auth_jwt_claim_set) directive should be used instead."},{"m":"ngx_http_auth_request_module","n":"summary","d":"The `ngx_http_auth_request_module` module (1.5.4+) implements client authorization based on the result of a subrequest. If the subrequest returns a 2xx response code, the access is allowed. If it returns 401 or 403, the access is denied with the corresponding error code. Any other response code returned by the subrequest is considered an error.\\nFor the 401 error, the client also receives the \u201cWWW-Authenticate\u201d header from the subrequest response.\\nThis module is not built by default, it should be enabled with the `--with-http_auth_request_module` configuration parameter.\\nThe module may be combined with other access modules, such as [ngx\\\\_http\\\\_access\\\\_module](ngx_http_access_module.html), [ngx\\\\_http\\\\_auth\\\\_basic\\\\_module](ngx_http_auth_basic_module.html), and [ngx\\\\_http\\\\_auth\\\\_jwt\\\\_module](ngx_http_auth_jwt_module.html), via the [satisfy](ngx_http_core_module.html#satisfy) directive.\\nBefore version 1.7.3, responses to authorization subrequests could not be cached (using [proxy\\\\_cache](ngx_http_proxy_module.html#proxy_cache), [proxy\\\\_store](ngx_http_proxy_module.html#proxy_store), etc.).\\n"},{"m":"ngx_http_auth_request_module","n":"auth_request","d":"Enables authorization based on the result of a subrequest and sets the URI to which the subrequest will be sent."},{"m":"ngx_http_autoindex_module","n":"summary","d":"The `ngx_http_autoindex_module` module processes requests ending with the slash character (\u2018`/`\u2019) and produces a directory listing. Usually a request is passed to the `ngx_http_autoindex_module` module when the [ngx\\\\_http\\\\_index\\\\_module](ngx_http_index_module.html) module cannot find an index file."},{"m":"ngx_http_autoindex_module","n":"autoindex","d":"Enables or disables the directory listing output."},{"m":"ngx_http_autoindex_module","n":"autoindex_exact_size","d":"For the HTML [format](#autoindex_format), specifies whether exact file sizes should be output in the directory listing, or rather rounded to kilobytes, megabytes, and gigabytes."},{"m":"ngx_http_autoindex_module","n":"autoindex_format","d":"Sets the format of a directory listing.\\nWhen the JSONP format is used, the name of a callback function is set with the `callback` request argument. If the argument is missing or has an empty value, then the JSON format is used.\\nThe XML output can be transformed using the [ngx\\\\_http\\\\_xslt\\\\_module](ngx_http_xslt_module.html) module."},{"m":"ngx_http_browser_module","n":"summary","d":"The `ngx_http_browser_module` module creates variables whose values depend on the value of the \u201cUser-Agent\u201d request header field:\\n`$modern_browser`\\n\\nequals the value set by the [modern\\\\_browser\\\\_value](#modern_browser_value) directive, if a browser was identified as modern;\\n\\n`$ancient_browser`\\n\\nequals the value set by the [ancient\\\\_browser\\\\_value](#ancient_browser_value) directive, if a browser was identified as ancient;\\n\\n`$msie`\\n\\nequals \u201c1\u201d if a browser was identified as MSIE of any version.\\n"},{"m":"ngx_http_browser_module","n":"ancient_browser","d":"If any of the specified substrings is found in the \u201cUser-Agent\u201d request header field, the browser will be considered ancient. The special string \u201c`netscape4`\u201d corresponds to the regular expression \u201c`^Mozilla/[1-4]`\u201d."},{"m":"ngx_http_browser_module","n":"ancient_browser_value","d":"Sets a value for the `$ancient_browser` variables."},{"m":"ngx_http_browser_module","n":"modern_browser","d":"Specifies a version starting from which a browser is considered modern. A browser can be any one of the following: `msie`, `gecko` (browsers based on Mozilla), `opera`, `safari`, or `konqueror`.\\nVersions can be specified in the following formats: X, X.X, X.X.X, or X.X.X.X. The maximum values for each of the format are 4000, 4000.99, 4000.99.99, and 4000.99.99.99, respectively.\\nThe special value `unlisted` specifies to consider a browser as modern if it was not listed by the `modern_browser` and [ancient\\\\_browser](#ancient_browser) directives. Otherwise such a browser is considered ancient. If a request does not provide the \u201cUser-Agent\u201d field in the header, the browser is treated as not being listed."},{"m":"ngx_http_charset_module","n":"summary","d":"The `ngx_http_charset_module` module adds the specified charset to the \u201cContent-Type\u201d response header field. In addition, the module can convert data from one charset to another, with some limitations:\\n*   conversion is performed one way\xa0\u2014 from server to client,\\n*   only single-byte charsets can be converted\\n*   or single-byte charsets to/from UTF-8.\\n"},{"m":"ngx_http_charset_module","n":"charset","d":"Adds the specified charset to the \u201cContent-Type\u201d response header field. If this charset is different from the charset specified in the [source\\\\_charset](#source_charset) directive, a conversion is performed.\\nThe parameter `off` cancels the addition of charset to the \u201cContent-Type\u201d response header field.\\nA charset can be defined with a variable:\\n```\\ncharset $charset;\\n\\n```\\nIn such a case, all possible values of a variable need to be present in the configuration at least once in the form of the [charset\\\\_map](#charset_map), [charset](#charset), or [source\\\\_charset](#source_charset) directives. For `utf-8`, `windows-1251`, and `koi8-r` charsets, it is sufficient to include the files `conf/koi-win`, `conf/koi-utf`, and `conf/win-utf` into configuration. For other charsets, simply making a fictitious conversion table works, for example:\\n```\\ncharset_map iso-8859-5 _ { }\\n\\n```\\n\\nIn addition, a charset can be set in the \u201cX-Accel-Charset\u201d response header field. This capability can be disabled using the [proxy\\\\_ignore\\\\_headers](ngx_http_proxy_module.html#proxy_ignore_headers), [fastcgi\\\\_ignore\\\\_headers](ngx_http_fastcgi_module.html#fastcgi_ignore_headers), [uwsgi\\\\_ignore\\\\_headers](ngx_http_uwsgi_module.html#uwsgi_ignore_headers), [scgi\\\\_ignore\\\\_headers](ngx_http_scgi_module.html#scgi_ignore_headers), and [grpc\\\\_ignore\\\\_headers](ngx_http_grpc_module.html#grpc_ignore_headers) directives."},{"m":"ngx_http_charset_module","n":"charset_map","d":"Describes the conversion table from one charset to another. A reverse conversion table is built using the same data. Character codes are given in hexadecimal. Missing characters in the range 80-FF are replaced with \u201c`?`\u201d. When converting from UTF-8, characters missing in a one-byte charset are replaced with \u201c`&#XXXX;`\u201d.\\nExample:\\n```\\ncharset_map koi8-r windows-1251 {\\n    C0 FE ; # small yu\\n    C1 E0 ; # small a\\n    C2 E1 ; # small b\\n    C3 F6 ; # small ts\\n    ...\\n}\\n\\n```\\n\\nWhen describing a conversion table to UTF-8, codes for the UTF-8 charset should be given in the second column, for example:\\n```\\ncharset_map koi8-r utf-8 {\\n    C0 D18E ; # small yu\\n    C1 D0B0 ; # small a\\n    C2 D0B1 ; # small b\\n    C3 D186 ; # small ts\\n    ...\\n}\\n\\n```\\n\\nFull conversion tables from `koi8-r` to `windows-1251`, and from `koi8-r` and `windows-1251` to `utf-8` are provided in the distribution files `conf/koi-win`, `conf/koi-utf`, and `conf/win-utf`."},{"m":"ngx_http_charset_module","n":"charset_types","d":"Enables module processing in responses with the specified MIME types in addition to \u201c`text/html`\u201d. The special value \u201c`*`\u201d matches any MIME type (0.8.29).\\n\\nUntil version 1.5.4, \u201c`application/x-javascript`\u201d was used as the default MIME type instead of \u201c`application/javascript`\u201d.\\n"},{"m":"ngx_http_charset_module","n":"override_charset","d":"Determines whether a conversion should be performed for answers received from a proxied or a FastCGI/uwsgi/SCGI/gRPC server when the answers already carry a charset in the \u201cContent-Type\u201d response header field. If conversion is enabled, a charset specified in the received response is used as a source charset.\\nIt should be noted that if a response is received in a subrequest then the conversion from the response charset to the main request charset is always performed, regardless of the `override_charset` directive setting.\\n"},{"m":"ngx_http_dav_module","n":"summary","d":"The `ngx_http_dav_module` module is intended for file management automation via the WebDAV protocol. The module processes HTTP and WebDAV methods PUT, DELETE, MKCOL, COPY, and MOVE.\\nThis module is not built by default, it should be enabled with the `--with-http_dav_module` configuration parameter.\\n\\nWebDAV clients that require additional WebDAV methods to operate will not work with this module.\\n"},{"m":"ngx_http_dav_module","n":"create_full_put_path","d":"The WebDAV specification only allows creating files in already existing directories. This directive allows creating all needed intermediate directories."},{"m":"ngx_http_dav_module","n":"dav_access","d":"Sets access permissions for newly created files and directories, e.g.:\\n```\\ndav_access user:rw group:rw all:r;\\n\\n```\\n\\nIf any `group` or `all` access permissions are specified then `user` permissions may be omitted:\\n```\\ndav_access group:rw all:r;\\n\\n```\\n"},{"m":"ngx_http_dav_module","n":"dav_methods","d":"Allows the specified HTTP and WebDAV methods. The parameter `off` denies all methods processed by this module. The following methods are supported: `PUT`, `DELETE`, `MKCOL`, `COPY`, and `MOVE`.\\nA file uploaded with the PUT method is first written to a temporary file, and then the file is renamed. Starting from version 0.8.9, temporary files and the persistent store can be put on different file systems. However, be aware that in this case a file is copied across two file systems instead of the cheap renaming operation. It is thus recommended that for any given location both saved files and a directory holding temporary files, set by the [client\\\\_body\\\\_temp\\\\_path](ngx_http_core_module.html#client_body_temp_path) directive, are put on the same file system.\\nWhen creating a file with the PUT method, it is possible to specify the modification date by passing it in the \u201cDate\u201d header field."},{"m":"ngx_http_empty_gif_module","n":"summary","d":"The `ngx_http_empty_gif_module` module emits single-pixel transparent GIF."},{"m":"ngx_http_f4f_module","n":"summary","d":"The `ngx_http_f4f_module` module provides server-side support for Adobe HTTP Dynamic Streaming (HDS).\\nThis module implements handling of HTTP Dynamic Streaming requests in the \u201c`/videoSeg1-Frag1`\u201d form\xa0\u2014 extracting the needed fragment from the `videoSeg1.f4f` file using the `videoSeg1.f4x` index file. This module is an alternative to the Adobe\u2019s f4f module (HTTP Origin Module) for Apache.\\nUsual pre-processing with Adobe\u2019s f4fpackager is required, see relevant documentation for details.\\n\\nThis module is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_f4f_module","n":"f4f","d":"Turns on module processing in the surrounding location."},{"m":"ngx_http_fastcgi_module","n":"summary","d":"The `ngx_http_fastcgi_module` module allows passing requests to a FastCGI server."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_bind","d":"Makes outgoing connections to a FastCGI server originate from the specified local IP address with an optional port (1.11.2). Parameter value can contain variables (1.3.12). The special value `off` (1.3.12) cancels the effect of the `fastcgi_bind` directive inherited from the previous configuration level, which allows the system to auto-assign the local IP address and port."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_bind_transparent","d":"The `transparent` parameter (1.11.0) allows outgoing connections to a FastCGI server originate from a non-local IP address, for example, from a real IP address of a client:\\n```\\nfastcgi_bind $remote_addr transparent;\\n\\n```\\nIn order for this parameter to work, it is usually necessary to run nginx worker processes with the [superuser](../ngx_core_module.html#user) privileges. On Linux it is not required (1.13.8) as if the `transparent` parameter is specified, worker processes inherit the `CAP_NET_RAW` capability from the master process. It is also necessary to configure kernel routing table to intercept network traffic from the FastCGI server."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_buffer_size","d":"Sets the `_size_` of the buffer used for reading the first part of the response received from the FastCGI server. This part usually contains a small response header. By default, the buffer size is equal to one memory page. This is either 4K or 8K, depending on a platform. It can be made smaller, however."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_buffering","d":"Enables or disables buffering of responses from the FastCGI server.\\nWhen buffering is enabled, nginx receives a response from the FastCGI server as soon as possible, saving it into the buffers set by the [fastcgi\\\\_buffer\\\\_size](#fastcgi_buffer_size) and [fastcgi\\\\_buffers](#fastcgi_buffers) directives. If the whole response does not fit into memory, a part of it can be saved to a [temporary file](#fastcgi_temp_path) on the disk. Writing to temporary files is controlled by the [fastcgi\\\\_max\\\\_temp\\\\_file\\\\_size](#fastcgi_max_temp_file_size) and [fastcgi\\\\_temp\\\\_file\\\\_write\\\\_size](#fastcgi_temp_file_write_size) directives.\\nWhen buffering is disabled, the response is passed to a client synchronously, immediately as it is received. nginx will not try to read the whole response from the FastCGI server. The maximum size of the data that nginx can receive from the server at a time is set by the [fastcgi\\\\_buffer\\\\_size](#fastcgi_buffer_size) directive.\\nBuffering can also be enabled or disabled by passing \u201c`yes`\u201d or \u201c`no`\u201d in the \u201cX-Accel-Buffering\u201d response header field. This capability can be disabled using the [fastcgi\\\\_ignore\\\\_headers](#fastcgi_ignore_headers) directive."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_buffers","d":"Sets the `_number_` and `_size_` of the buffers used for reading a response from the FastCGI server, for a single connection. By default, the buffer size is equal to one memory page. This is either 4K or 8K, depending on a platform."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_busy_buffers_size","d":"When [buffering](#fastcgi_buffering) of responses from the FastCGI server is enabled, limits the total `_size_` of buffers that can be busy sending a response to the client while the response is not yet fully read. In the meantime, the rest of the buffers can be used for reading the response and, if needed, buffering part of the response to a temporary file. By default, `_size_` is limited by the size of two buffers set by the [fastcgi\\\\_buffer\\\\_size](#fastcgi_buffer_size) and [fastcgi\\\\_buffers](#fastcgi_buffers) directives."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_cache","d":"Defines a shared memory zone used for caching. The same zone can be used in several places. Parameter value can contain variables (1.7.9). The `off` parameter disables caching inherited from the previous configuration level."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_cache_background_update","d":"Allows starting a background subrequest to update an expired cache item, while a stale cached response is returned to the client. Note that it is necessary to [allow](#fastcgi_cache_use_stale_updating) the usage of a stale cached response when it is being updated."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_cache_bypass","d":"Defines conditions under which the response will not be taken from a cache. If at least one value of the string parameters is not empty and is not equal to \u201c0\u201d then the response will not be taken from the cache:\\n```\\nfastcgi_cache_bypass $cookie_nocache $arg_nocache$arg_comment;\\nfastcgi_cache_bypass $http_pragma    $http_authorization;\\n\\n```\\nCan be used along with the [fastcgi\\\\_no\\\\_cache](#fastcgi_no_cache) directive."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_cache_key","d":"Defines a key for caching, for example\\n```\\nfastcgi_cache_key localhost:9000$request_uri;\\n\\n```\\n"},{"m":"ngx_http_fastcgi_module","n":"fastcgi_cache_lock","d":"When enabled, only one request at a time will be allowed to populate a new cache element identified according to the [fastcgi\\\\_cache\\\\_key](#fastcgi_cache_key) directive by passing a request to a FastCGI server. Other requests of the same cache element will either wait for a response to appear in the cache or the cache lock for this element to be released, up to the time set by the [fastcgi\\\\_cache\\\\_lock\\\\_timeout](#fastcgi_cache_lock_timeout) directive."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_cache_lock_age","d":"If the last request passed to the FastCGI server for populating a new cache element has not completed for the specified `_time_`, one more request may be passed to the FastCGI server."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_cache_lock_timeout","d":"Sets a timeout for [fastcgi\\\\_cache\\\\_lock](#fastcgi_cache_lock). When the `_time_` expires, the request will be passed to the FastCGI server, however, the response will not be cached.\\nBefore 1.7.8, the response could be cached.\\n"},{"m":"ngx_http_fastcgi_module","n":"fastcgi_cache_max_range_offset","d":"Sets an offset in bytes for byte-range requests. If the range is beyond the offset, the range request will be passed to the FastCGI server and the response will not be cached."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_cache_methods","d":"If the client request method is listed in this directive then the response will be cached. \u201c`GET`\u201d and \u201c`HEAD`\u201d methods are always added to the list, though it is recommended to specify them explicitly. See also the [fastcgi\\\\_no\\\\_cache](#fastcgi_no_cache) directive."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_cache_min_uses","d":"Sets the `_number_` of requests after which the response will be cached."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_cache_path","d":"Sets the path and other parameters of a cache. Cache data are stored in files. Both the key and file name in a cache are a result of applying the MD5 function to the proxied URL. The `levels` parameter defines hierarchy levels of a cache: from 1 to 3, each level accepts values 1 or 2. For example, in the following configuration\\n```\\nfastcgi_cache_path /data/nginx/cache levels=1:2 keys_zone=one:10m;\\n\\n```\\nfile names in a cache will look like this:\\n```\\n/data/nginx/cache/c/29/b7f54b2df7773722d382f4809d65029c\\n\\n```\\n\\nA cached response is first written to a temporary file, and then the file is renamed. Starting from version 0.8.9, temporary files and the cache can be put on different file systems. However, be aware that in this case a file is copied across two file systems instead of the cheap renaming operation. It is thus recommended that for any given location both cache and a directory holding temporary files are put on the same file system. A directory for temporary files is set based on the `use_temp_path` parameter (1.7.10). If this parameter is omitted or set to the value `on`, the directory set by the [fastcgi\\\\_temp\\\\_path](#fastcgi_temp_path) directive for the given location will be used. If the value is set to `off`, temporary files will be put directly in the cache directory.\\nIn addition, all active keys and information about data are stored in a shared memory zone, whose `_name_` and `_size_` are configured by the `keys_zone` parameter. One megabyte zone can store about 8 thousand keys.\\nAs part of [commercial subscription](http://nginx.com/products/), the shared memory zone also stores extended cache [information](ngx_http_api_module.html#http_caches_), thus, it is required to specify a larger zone size for the same number of keys. For example, one megabyte zone can store about 4 thousand keys.\\n\\nCached data that are not accessed during the time specified by the `inactive` parameter get removed from the cache regardless of their freshness. By default, `inactive` is set to 10 minutes."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_cache_path_max_size","d":"The special \u201ccache manager\u201d process monitors the maximum cache size set by the `max_size` parameter, and the minimum amount of free space set by the `min_free` (1.19.1) parameter on the file system with cache. When the size is exceeded or there is not enough free space, it removes the least recently used data. The data is removed in iterations configured by `manager_files`, `manager_threshold`, and `manager_sleep` parameters (1.11.5). During one iteration no more than `manager_files` items are deleted (by default, 100). The duration of one iteration is limited by the `manager_threshold` parameter (by default, 200 milliseconds). Between iterations, a pause configured by the `manager_sleep` parameter (by default, 50 milliseconds) is made.\\nA minute after the start the special \u201ccache loader\u201d process is activated. It loads information about previously cached data stored on file system into a cache zone. The loading is also done in iterations. During one iteration no more than `loader_files` items are loaded (by default, 100). Besides, the duration of one iteration is limited by the `loader_threshold` parameter (by default, 200 milliseconds). Between iterations, a pause configured by the `loader_sleep` parameter (by default, 50 milliseconds) is made.\\nAdditionally, the following parameters are available as part of our [commercial subscription](http://nginx.com/products/):\\n\\n`purger`\\\\=`on`|`off`\\n\\nInstructs whether cache entries that match a [wildcard key](#fastcgi_cache_purge) will be removed from the disk by the cache purger (1.7.12). Setting the parameter to `on` (default is `off`) will activate the \u201ccache purger\u201d process that permanently iterates through all cache entries and deletes the entries that match the wildcard key.\\n\\n`purger_files`\\\\=`_number_`\\n\\nSets the number of items that will be scanned during one iteration (1.7.12). By default, `purger_files` is set to 10.\\n\\n`purger_threshold`\\\\=`_number_`\\n\\nSets the duration of one iteration (1.7.12). By default, `purger_threshold` is set to 50 milliseconds.\\n\\n`purger_sleep`\\\\=`_number_`\\n\\nSets a pause between iterations (1.7.12). By default, `purger_sleep` is set to 50 milliseconds.\\n\\n\\nIn versions 1.7.3, 1.7.7, and 1.11.10 cache header format has been changed. Previously cached responses will be considered invalid after upgrading to a newer nginx version.\\n"},{"m":"ngx_http_fastcgi_module","n":"fastcgi_cache_purge","d":"Defines conditions under which the request will be considered a cache purge request. If at least one value of the string parameters is not empty and is not equal to \u201c0\u201d then the cache entry with a corresponding [cache key](#fastcgi_cache_key) is removed. The result of successful operation is indicated by returning the 204 (No Content) response.\\nIf the [cache key](#fastcgi_cache_key) of a purge request ends with an asterisk (\u201c`*`\u201d), all cache entries matching the wildcard key will be removed from the cache. However, these entries will remain on the disk until they are deleted for either [inactivity](#fastcgi_cache_path), or processed by the [cache purger](#purger) (1.7.12), or a client attempts to access them.\\nExample configuration:\\n```\\nfastcgi_cache_path /data/nginx/cache keys_zone=cache_zone:10m;\\n\\nmap $request_method $purge_method {\\n    PURGE   1;\\n    default 0;\\n}\\n\\nserver {\\n    ...\\n    location / {\\n        fastcgi_pass        backend;\\n        fastcgi_cache       cache_zone;\\n        fastcgi_cache_key   $uri;\\n        fastcgi_cache_purge $purge_method;\\n    }\\n}\\n\\n```\\n\\nThis functionality is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_fastcgi_module","n":"fastcgi_cache_revalidate","d":"Enables revalidation of expired cache items using conditional requests with the \u201cIf-Modified-Since\u201d and \u201cIf-None-Match\u201d header fields."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_cache_use_stale","d":"Determines in which cases a stale cached response can be used when an error occurs during communication with the FastCGI server. The directive\u2019s parameters match the parameters of the [fastcgi\\\\_next\\\\_upstream](#fastcgi_next_upstream) directive.\\nThe `error` parameter also permits using a stale cached response if a FastCGI server to process a request cannot be selected."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_cache_use_stale_updating","d":"Additionally, the `updating` parameter permits using a stale cached response if it is currently being updated. This allows minimizing the number of accesses to FastCGI servers when updating cached data.\\nUsing a stale cached response can also be enabled directly in the response header for a specified number of seconds after the response became stale (1.11.10). This has lower priority than using the directive parameters.\\n*   The \u201c[stale-while-revalidate](https://tools.ietf.org/html/rfc5861#section-3)\u201d extension of the \u201cCache-Control\u201d header field permits using a stale cached response if it is currently being updated.\\n*   The \u201c[stale-if-error](https://tools.ietf.org/html/rfc5861#section-4)\u201d extension of the \u201cCache-Control\u201d header field permits using a stale cached response in case of an error.\\n\\nTo minimize the number of accesses to FastCGI servers when populating a new cache element, the [fastcgi\\\\_cache\\\\_lock](#fastcgi_cache_lock) directive can be used."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_cache_valid","d":"Sets caching time for different response codes. For example, the following directives\\n```\\nfastcgi_cache_valid 200 302 10m;\\nfastcgi_cache_valid 404      1m;\\n\\n```\\nset 10 minutes of caching for responses with codes 200 and 302 and 1 minute for responses with code 404.\\nIf only caching `_time_` is specified\\n```\\nfastcgi_cache_valid 5m;\\n\\n```\\nthen only 200, 301, and 302 responses are cached.\\nIn addition, the `any` parameter can be specified to cache any responses:\\n```\\nfastcgi_cache_valid 200 302 10m;\\nfastcgi_cache_valid 301      1h;\\nfastcgi_cache_valid any      1m;\\n\\n```\\n\\nParameters of caching can also be set directly in the response header. This has higher priority than setting of caching time using the directive.\\n*   The \u201cX-Accel-Expires\u201d header field sets caching time of a response in seconds. The zero value disables caching for a response. If the value starts with the `@` prefix, it sets an absolute time in seconds since Epoch, up to which the response may be cached.\\n*   If the header does not include the \u201cX-Accel-Expires\u201d field, parameters of caching may be set in the header fields \u201cExpires\u201d or \u201cCache-Control\u201d.\\n*   If the header includes the \u201cSet-Cookie\u201d field, such a response will not be cached.\\n*   If the header includes the \u201cVary\u201d field with the special value \u201c`*`\u201d, such a response will not be cached (1.7.7). If the header includes the \u201cVary\u201d field with another value, such a response will be cached taking into account the corresponding request header fields (1.7.7).\\nProcessing of one or more of these response header fields can be disabled using the [fastcgi\\\\_ignore\\\\_headers](#fastcgi_ignore_headers) directive."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_catch_stderr","d":"Sets a string to search for in the error stream of a response received from a FastCGI server. If the `_string_` is found then it is considered that the FastCGI server has returned an [invalid response](#fastcgi_next_upstream). This allows handling application errors in nginx, for example:\\n```\\nlocation /php/ {\\n    fastcgi_pass backend:9000;\\n    ...\\n    fastcgi_catch_stderr \\"PHP Fatal error\\";\\n    fastcgi_next_upstream error timeout invalid_header;\\n}\\n\\n```\\n"},{"m":"ngx_http_fastcgi_module","n":"fastcgi_connect_timeout","d":"Defines a timeout for establishing a connection with a FastCGI server. It should be noted that this timeout cannot usually exceed 75 seconds."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_force_ranges","d":"Enables byte-range support for both cached and uncached responses from the FastCGI server regardless of the \u201cAccept-Ranges\u201d field in these responses."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_hide_header","d":"By default, nginx does not pass the header fields \u201cStatus\u201d and \u201cX-Accel-...\u201d from the response of a FastCGI server to a client. The `fastcgi_hide_header` directive sets additional fields that will not be passed. If, on the contrary, the passing of fields needs to be permitted, the [fastcgi\\\\_pass\\\\_header](#fastcgi_pass_header) directive can be used."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_ignore_client_abort","d":"Determines whether the connection with a FastCGI server should be closed when a client closes the connection without waiting for a response."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_ignore_headers","d":"Disables processing of certain response header fields from the FastCGI server. The following fields can be ignored: \u201cX-Accel-Redirect\u201d, \u201cX-Accel-Expires\u201d, \u201cX-Accel-Limit-Rate\u201d (1.1.6), \u201cX-Accel-Buffering\u201d (1.1.6), \u201cX-Accel-Charset\u201d (1.1.6), \u201cExpires\u201d, \u201cCache-Control\u201d, \u201cSet-Cookie\u201d (0.8.44), and \u201cVary\u201d (1.7.7).\\nIf not disabled, processing of these header fields has the following effect:\\n*   \u201cX-Accel-Expires\u201d, \u201cExpires\u201d, \u201cCache-Control\u201d, \u201cSet-Cookie\u201d, and \u201cVary\u201d set the parameters of response [caching](#fastcgi_cache_valid);\\n*   \u201cX-Accel-Redirect\u201d performs an [internal redirect](ngx_http_core_module.html#internal) to the specified URI;\\n*   \u201cX-Accel-Limit-Rate\u201d sets the [rate limit](ngx_http_core_module.html#limit_rate) for transmission of a response to a client;\\n*   \u201cX-Accel-Buffering\u201d enables or disables [buffering](#fastcgi_buffering) of a response;\\n*   \u201cX-Accel-Charset\u201d sets the desired [charset](ngx_http_charset_module.html#charset) of a response.\\n"},{"m":"ngx_http_fastcgi_module","n":"fastcgi_index","d":"Sets a file name that will be appended after a URI that ends with a slash, in the value of the `$fastcgi_script_name` variable. For example, with these settings\\n```\\nfastcgi_index index.php;\\nfastcgi_param SCRIPT_FILENAME /home/www/scripts/php$fastcgi_script_name;\\n\\n```\\nand the \u201c`/page.php`\u201d request, the `SCRIPT_FILENAME` parameter will be equal to \u201c`/home/www/scripts/php/page.php`\u201d, and with the \u201c`/`\u201d request it will be equal to \u201c`/home/www/scripts/php/index.php`\u201d."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_intercept_errors","d":"Determines whether FastCGI server responses with codes greater than or equal to 300 should be passed to a client or be intercepted and redirected to nginx for processing with the [error\\\\_page](ngx_http_core_module.html#error_page) directive."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_keep_conn","d":"By default, a FastCGI server will close a connection right after sending the response. However, when this directive is set to the value `on`, nginx will instruct a FastCGI server to keep connections open. This is necessary, in particular, for [keepalive](ngx_http_upstream_module.html#keepalive) connections to FastCGI servers to function."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_limit_rate","d":"Limits the speed of reading the response from the FastCGI server. The `_rate_` is specified in bytes per second. The zero value disables rate limiting. The limit is set per a request, and so if nginx simultaneously opens two connections to the FastCFI server, the overall rate will be twice as much as the specified limit. The limitation works only if [buffering](#fastcgi_buffering) of responses from the FastCGI server is enabled."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_max_temp_file_size","d":"When [buffering](#fastcgi_buffering) of responses from the FastCGI server is enabled, and the whole response does not fit into the buffers set by the [fastcgi\\\\_buffer\\\\_size](#fastcgi_buffer_size) and [fastcgi\\\\_buffers](#fastcgi_buffers) directives, a part of the response can be saved to a temporary file. This directive sets the maximum `_size_` of the temporary file. The size of data written to the temporary file at a time is set by the [fastcgi\\\\_temp\\\\_file\\\\_write\\\\_size](#fastcgi_temp_file_write_size) directive.\\nThe zero value disables buffering of responses to temporary files.\\n\\nThis restriction does not apply to responses that will be [cached](#fastcgi_cache) or [stored](#fastcgi_store) on disk.\\n"},{"m":"ngx_http_fastcgi_module","n":"fastcgi_next_upstream","d":"Specifies in which cases a request should be passed to the next server:\\n`error`\\n\\nan error occurred while establishing a connection with the server, passing a request to it, or reading the response header;\\n\\n`timeout`\\n\\na timeout has occurred while establishing a connection with the server, passing a request to it, or reading the response header;\\n\\n`invalid_header`\\n\\na server returned an empty or invalid response;\\n\\n`http_500`\\n\\na server returned a response with the code 500;\\n\\n`http_503`\\n\\na server returned a response with the code 503;\\n\\n`http_403`\\n\\na server returned a response with the code 403;\\n\\n`http_404`\\n\\na server returned a response with the code 404;\\n\\n`http_429`\\n\\na server returned a response with the code 429 (1.11.13);\\n\\n`non_idempotent`\\n\\nnormally, requests with a [non-idempotent](https://tools.ietf.org/html/rfc7231#section-4.2.2) method (`POST`, `LOCK`, `PATCH`) are not passed to the next server if a request has been sent to an upstream server (1.9.13); enabling this option explicitly allows retrying such requests;\\n\\n`off`\\n\\ndisables passing a request to the next server.\\n\\nOne should bear in mind that passing a request to the next server is only possible if nothing has been sent to a client yet. That is, if an error or timeout occurs in the middle of the transferring of a response, fixing this is impossible.\\nThe directive also defines what is considered an [unsuccessful attempt](ngx_http_upstream_module.html#max_fails) of communication with a server. The cases of `error`, `timeout` and `invalid_header` are always considered unsuccessful attempts, even if they are not specified in the directive. The cases of `http_500`, `http_503`, and `http_429` are considered unsuccessful attempts only if they are specified in the directive. The cases of `http_403` and `http_404` are never considered unsuccessful attempts.\\nPassing a request to the next server can be limited by [the number of tries](#fastcgi_next_upstream_tries) and by [time](#fastcgi_next_upstream_timeout)."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_next_upstream_timeout","d":"Limits the time during which a request can be passed to the [next server](#fastcgi_next_upstream). The `0` value turns off this limitation."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_next_upstream_tries","d":"Limits the number of possible tries for passing a request to the [next server](#fastcgi_next_upstream). The `0` value turns off this limitation."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_no_cache","d":"Defines conditions under which the response will not be saved to a cache. If at least one value of the string parameters is not empty and is not equal to \u201c0\u201d then the response will not be saved:\\n```\\nfastcgi_no_cache $cookie_nocache $arg_nocache$arg_comment;\\nfastcgi_no_cache $http_pragma    $http_authorization;\\n\\n```\\nCan be used along with the [fastcgi\\\\_cache\\\\_bypass](#fastcgi_cache_bypass) directive."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_param","d":"Sets a `_parameter_` that should be passed to the FastCGI server. The `_value_` can contain text, variables, and their combination. These directives are inherited from the previous configuration level if and only if there are no `fastcgi_param` directives defined on the current level.\\nThe following example shows the minimum required settings for PHP:\\n```\\nfastcgi_param SCRIPT_FILENAME /home/www/scripts/php$fastcgi_script_name;\\nfastcgi_param QUERY_STRING    $query_string;\\n\\n```\\n\\nThe `SCRIPT_FILENAME` parameter is used in PHP for determining the script name, and the `QUERY_STRING` parameter is used to pass request parameters.\\nFor scripts that process `POST` requests, the following three parameters are also required:\\n```\\nfastcgi_param REQUEST_METHOD  $request_method;\\nfastcgi_param CONTENT_TYPE    $content_type;\\nfastcgi_param CONTENT_LENGTH  $content_length;\\n\\n```\\n\\nIf PHP was built with the `--enable-force-cgi-redirect` configuration parameter, the `REDIRECT_STATUS` parameter should also be passed with the value \u201c200\u201d:\\n```\\nfastcgi_param REDIRECT_STATUS 200;\\n\\n```\\n\\nIf the directive is specified with `if_not_empty` (1.1.11) then such a parameter will be passed to the server only if its value is not empty:\\n```\\nfastcgi_param HTTPS           $https if_not_empty;\\n\\n```\\n"},{"m":"ngx_http_fastcgi_module","n":"fastcgi_pass","d":"Sets the address of a FastCGI server. The address can be specified as a domain name or IP address, and a port:\\n```\\nfastcgi_pass localhost:9000;\\n\\n```\\nor as a UNIX-domain socket path:\\n```\\nfastcgi_pass unix:/tmp/fastcgi.socket;\\n\\n```\\n\\nIf a domain name resolves to several addresses, all of them will be used in a round-robin fashion. In addition, an address can be specified as a [server group](ngx_http_upstream_module.html).\\nParameter value can contain variables. In this case, if an address is specified as a domain name, the name is searched among the described [server groups](ngx_http_upstream_module.html), and, if not found, is determined using a [resolver](ngx_http_core_module.html#resolver)."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_pass_header","d":"Permits passing [otherwise disabled](#fastcgi_hide_header) header fields from a FastCGI server to a client."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_pass_request_body","d":"Indicates whether the original request body is passed to the FastCGI server. See also the [fastcgi\\\\_pass\\\\_request\\\\_headers](#fastcgi_pass_request_headers) directive."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_pass_request_headers","d":"Indicates whether the header fields of the original request are passed to the FastCGI server. See also the [fastcgi\\\\_pass\\\\_request\\\\_body](#fastcgi_pass_request_body) directive."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_read_timeout","d":"Defines a timeout for reading a response from the FastCGI server. The timeout is set only between two successive read operations, not for the transmission of the whole response. If the FastCGI server does not transmit anything within this time, the connection is closed."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_request_buffering","d":"Enables or disables buffering of a client request body.\\nWhen buffering is enabled, the entire request body is [read](ngx_http_core_module.html#client_body_buffer_size) from the client before sending the request to a FastCGI server.\\nWhen buffering is disabled, the request body is sent to the FastCGI server immediately as it is received. In this case, the request cannot be passed to the [next server](#fastcgi_next_upstream) if nginx already started sending the request body."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_send_lowat","d":"If the directive is set to a non-zero value, nginx will try to minimize the number of send operations on outgoing connections to a FastCGI server by using either `NOTE_LOWAT` flag of the [kqueue](../events.html#kqueue) method, or the `SO_SNDLOWAT` socket option, with the specified `_size_`.\\nThis directive is ignored on Linux, Solaris, and Windows."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_send_timeout","d":"Sets a timeout for transmitting a request to the FastCGI server. The timeout is set only between two successive write operations, not for the transmission of the whole request. If the FastCGI server does not receive anything within this time, the connection is closed."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_socket_keepalive","d":"Configures the \u201cTCP keepalive\u201d behavior for outgoing connections to a FastCGI server. By default, the operating system\u2019s settings are in effect for the socket. If the directive is set to the value \u201c`on`\u201d, the `SO_KEEPALIVE` socket option is turned on for the socket."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_split_path_info","d":"Defines a regular expression that captures a value for the `$fastcgi_path_info` variable. The regular expression should have two captures: the first becomes a value of the `$fastcgi_script_name` variable, the second becomes a value of the `$fastcgi_path_info` variable. For example, with these settings\\n```\\nlocation ~ ^(.+\\\\.php)(.*)$ {\\n    fastcgi_split_path_info       ^(.+\\\\.php)(.*)$;\\n    fastcgi_param SCRIPT_FILENAME /path/to/php$fastcgi_script_name;\\n    fastcgi_param PATH_INFO       $fastcgi_path_info;\\n\\n```\\nand the \u201c`/show.php/article/0001`\u201d request, the `SCRIPT_FILENAME` parameter will be equal to \u201c`/path/to/php/show.php`\u201d, and the `PATH_INFO` parameter will be equal to \u201c`/article/0001`\u201d."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_store","d":"Enables saving of files to a disk. The `on` parameter saves files with paths corresponding to the directives [alias](ngx_http_core_module.html#alias) or [root](ngx_http_core_module.html#root). The `off` parameter disables saving of files. In addition, the file name can be set explicitly using the `_string_` with variables:\\n```\\nfastcgi_store /data/www$original_uri;\\n\\n```\\n\\nThe modification time of files is set according to the received \u201cLast-Modified\u201d response header field. The response is first written to a temporary file, and then the file is renamed. Starting from version 0.8.9, temporary files and the persistent store can be put on different file systems. However, be aware that in this case a file is copied across two file systems instead of the cheap renaming operation. It is thus recommended that for any given location both saved files and a directory holding temporary files, set by the [fastcgi\\\\_temp\\\\_path](#fastcgi_temp_path) directive, are put on the same file system.\\nThis directive can be used to create local copies of static unchangeable files, e.g.:\\n```\\nlocation /images/ {\\n    root                 /data/www;\\n    error_page           404 = /fetch$uri;\\n}\\n\\nlocation /fetch/ {\\n    internal;\\n\\n    fastcgi_pass         backend:9000;\\n    ...\\n\\n    fastcgi_store        on;\\n    fastcgi_store_access user:rw group:rw all:r;\\n    fastcgi_temp_path    /data/temp;\\n\\n    alias                /data/www/;\\n}\\n\\n```\\n"},{"m":"ngx_http_fastcgi_module","n":"fastcgi_store_access","d":"Sets access permissions for newly created files and directories, e.g.:\\n```\\nfastcgi_store_access user:rw group:rw all:r;\\n\\n```\\n\\nIf any `group` or `all` access permissions are specified then `user` permissions may be omitted:\\n```\\nfastcgi_store_access group:rw all:r;\\n\\n```\\n"},{"m":"ngx_http_fastcgi_module","n":"fastcgi_temp_file_write_size","d":"Limits the `_size_` of data written to a temporary file at a time, when buffering of responses from the FastCGI server to temporary files is enabled. By default, `_size_` is limited by two buffers set by the [fastcgi\\\\_buffer\\\\_size](#fastcgi_buffer_size) and [fastcgi\\\\_buffers](#fastcgi_buffers) directives. The maximum size of a temporary file is set by the [fastcgi\\\\_max\\\\_temp\\\\_file\\\\_size](#fastcgi_max_temp_file_size) directive."},{"m":"ngx_http_fastcgi_module","n":"fastcgi_temp_path","d":"Defines a directory for storing temporary files with data received from FastCGI servers. Up to three-level subdirectory hierarchy can be used underneath the specified directory. For example, in the following configuration\\n```\\nfastcgi_temp_path /spool/nginx/fastcgi_temp 1 2;\\n\\n```\\na temporary file might look like this:\\n```\\n/spool/nginx/fastcgi_temp/7/45/00000123457\\n\\n```\\n\\nSee also the `use_temp_path` parameter of the [fastcgi\\\\_cache\\\\_path](#fastcgi_cache_path) directive."},{"m":"ngx_http_fastcgi_module","n":"parameters","d":"#### Parameters Passed to a FastCGI Server\\nHTTP request header fields are passed to a FastCGI server as parameters. In applications and scripts running as FastCGI servers, these parameters are usually made available as environment variables. For example, the \u201cUser-Agent\u201d header field is passed as the `HTTP_USER_AGENT` parameter. In addition to HTTP request header fields, it is possible to pass arbitrary parameters using the [fastcgi\\\\_param](#fastcgi_param) directive."},{"m":"ngx_http_fastcgi_module","n":"$fastcgi_script_name\\n","d":"the value of the second capture set by the [fastcgi\\\\_split\\\\_path\\\\_info](#fastcgi_split_path_info) directive. This variable can be used to set the `PATH_INFO` parameter."},{"m":"ngx_http_fastcgi_module","n":"$fastcgi_path_info","d":"the value of the second capture set by the [fastcgi\\\\_split\\\\_path\\\\_info](#fastcgi_split_path_info) directive. This variable can be used to set the `PATH_INFO` parameter."},{"m":"ngx_http_flv_module","n":"summary","d":"The `ngx_http_flv_module` module provides pseudo-streaming server-side support for Flash Video (FLV) files.\\nIt handles requests with the `start` argument in the request URI\u2019s query string specially, by sending back the contents of a file starting from the requested byte offset and with the prepended FLV header.\\nThis module is not built by default, it should be enabled with the `--with-http_flv_module` configuration parameter."},{"m":"ngx_http_geo_module","n":"summary","d":"The `ngx_http_geo_module` module creates variables with values depending on the client IP address."},{"m":"ngx_http_geoip_module","n":"summary","d":"The `ngx_http_geoip_module` module (0.8.6+) creates variables with values depending on the client IP address, using the precompiled [MaxMind](http://www.maxmind.com) databases.\\nWhen using the databases with IPv6 support (1.3.12, 1.2.7), IPv4 addresses are looked up as IPv4-mapped IPv6 addresses.\\nThis module is not built by default, it should be enabled with the `--with-http_geoip_module` configuration parameter.\\nThis module requires the [MaxMind GeoIP](http://www.maxmind.com/app/c) library.\\n"},{"m":"ngx_http_geoip_module","n":"geoip_country","d":"Specifies a database used to determine the country depending on the client IP address. The following variables are available when using this database:\\n`$geoip_country_code`\\n\\ntwo-letter country code, for example, \u201c`RU`\u201d, \u201c`US`\u201d.\\n\\n`$geoip_country_code3`\\n\\nthree-letter country code, for example, \u201c`RUS`\u201d, \u201c`USA`\u201d.\\n\\n`$geoip_country_name`\\n\\ncountry name, for example, \u201c`Russian Federation`\u201d, \u201c`United States`\u201d.\\n"},{"m":"ngx_http_geoip_module","n":"geoip_city","d":"Specifies a database used to determine the country, region, and city depending on the client IP address. The following variables are available when using this database:\\n`$geoip_area_code`\\n\\ntelephone area code (US only).\\n\\n> This variable may contain outdated information since the corresponding database field is deprecated.\\n\\n`$geoip_city_continent_code`\\n\\ntwo-letter continent code, for example, \u201c`EU`\u201d, \u201c`NA`\u201d.\\n\\n`$geoip_city_country_code`\\n\\ntwo-letter country code, for example, \u201c`RU`\u201d, \u201c`US`\u201d.\\n\\n`$geoip_city_country_code3`\\n\\nthree-letter country code, for example, \u201c`RUS`\u201d, \u201c`USA`\u201d.\\n\\n`$geoip_city_country_name`\\n\\ncountry name, for example, \u201c`Russian Federation`\u201d, \u201c`United States`\u201d.\\n\\n`$geoip_dma_code`\\n\\nDMA region code in US (also known as \u201cmetro code\u201d), according to the [geotargeting](https://developers.google.com/adwords/api/docs/appendix/cities-DMAregions) in Google AdWords API.\\n\\n`$geoip_latitude`\\n\\nlatitude.\\n\\n`$geoip_longitude`\\n\\nlongitude.\\n\\n`$geoip_region`\\n\\ntwo-symbol country region code (region, territory, state, province, federal land and the like), for example, \u201c`48`\u201d, \u201c`DC`\u201d.\\n\\n`$geoip_region_name`\\n\\ncountry region name (region, territory, state, province, federal land and the like), for example, \u201c`Moscow City`\u201d, \u201c`District of Columbia`\u201d.\\n\\n`$geoip_city`\\n\\ncity name, for example, \u201c`Moscow`\u201d, \u201c`Washington`\u201d.\\n\\n`$geoip_postal_code`\\n\\npostal code.\\n"},{"m":"ngx_http_geoip_module","n":"geoip_org","d":"Specifies a database used to determine the organization depending on the client IP address. The following variable is available when using this database:\\n`$geoip_org`\\n\\norganization name, for example, \u201cThe University of Melbourne\u201d.\\n"},{"m":"ngx_http_geoip_module","n":"geoip_proxy","d":"Defines trusted addresses. When a request comes from a trusted address, an address from the \u201cX-Forwarded-For\u201d request header field will be used instead."},{"m":"ngx_http_grpc_module","n":"summary","d":"The `ngx_http_grpc_module` module allows passing requests to a gRPC server (1.13.10). The module requires the [ngx\\\\_http\\\\_v2\\\\_module](ngx_http_v2_module.html) module."},{"m":"ngx_http_grpc_module","n":"grpc_bind","d":"Makes outgoing connections to a gRPC server originate from the specified local IP address with an optional port. Parameter value can contain variables. The special value `off` cancels the effect of the `grpc_bind` directive inherited from the previous configuration level, which allows the system to auto-assign the local IP address and port."},{"m":"ngx_http_grpc_module","n":"grpc_bind_transparent","d":"The `transparent` parameter allows outgoing connections to a gRPC server originate from a non-local IP address, for example, from a real IP address of a client:\\n```\\ngrpc_bind $remote_addr transparent;\\n\\n```\\nIn order for this parameter to work, it is usually necessary to run nginx worker processes with the [superuser](../ngx_core_module.html#user) privileges. On Linux it is not required as if the `transparent` parameter is specified, worker processes inherit the `CAP_NET_RAW` capability from the master process. It is also necessary to configure kernel routing table to intercept network traffic from the gRPC server."},{"m":"ngx_http_grpc_module","n":"grpc_buffer_size","d":"Sets the `_size_` of the buffer used for reading the response received from the gRPC server. The response is passed to the client synchronously, as soon as it is received."},{"m":"ngx_http_grpc_module","n":"grpc_connect_timeout","d":"Defines a timeout for establishing a connection with a gRPC server. It should be noted that this timeout cannot usually exceed 75 seconds."},{"m":"ngx_http_grpc_module","n":"grpc_hide_header","d":"By default, nginx does not pass the header fields \u201cDate\u201d, \u201cServer\u201d, and \u201cX-Accel-...\u201d from the response of a gRPC server to a client. The `grpc_hide_header` directive sets additional fields that will not be passed. If, on the contrary, the passing of fields needs to be permitted, the [grpc\\\\_pass\\\\_header](#grpc_pass_header) directive can be used."},{"m":"ngx_http_grpc_module","n":"grpc_ignore_headers","d":"Disables processing of certain response header fields from the gRPC server. The following fields can be ignored: \u201cX-Accel-Redirect\u201d and \u201cX-Accel-Charset\u201d.\\nIf not disabled, processing of these header fields has the following effect:\\n*   \u201cX-Accel-Redirect\u201d performs an [internal redirect](ngx_http_core_module.html#internal) to the specified URI;\\n*   \u201cX-Accel-Charset\u201d sets the desired [charset](ngx_http_charset_module.html#charset) of a response.\\n"},{"m":"ngx_http_grpc_module","n":"grpc_intercept_errors","d":"Determines whether gRPC server responses with codes greater than or equal to 300 should be passed to a client or be intercepted and redirected to nginx for processing with the [error\\\\_page](ngx_http_core_module.html#error_page) directive."},{"m":"ngx_http_grpc_module","n":"grpc_next_upstream","d":"Specifies in which cases a request should be passed to the next server:\\n`error`\\n\\nan error occurred while establishing a connection with the server, passing a request to it, or reading the response header;\\n\\n`timeout`\\n\\na timeout has occurred while establishing a connection with the server, passing a request to it, or reading the response header;\\n\\n`invalid_header`\\n\\na server returned an empty or invalid response;\\n\\n`http_500`\\n\\na server returned a response with the code 500;\\n\\n`http_502`\\n\\na server returned a response with the code 502;\\n\\n`http_503`\\n\\na server returned a response with the code 503;\\n\\n`http_504`\\n\\na server returned a response with the code 504;\\n\\n`http_403`\\n\\na server returned a response with the code 403;\\n\\n`http_404`\\n\\na server returned a response with the code 404;\\n\\n`http_429`\\n\\na server returned a response with the code 429;\\n\\n`non_idempotent`\\n\\nnormally, requests with a [non-idempotent](https://tools.ietf.org/html/rfc7231#section-4.2.2) method (`POST`, `LOCK`, `PATCH`) are not passed to the next server if a request has been sent to an upstream server; enabling this option explicitly allows retrying such requests;\\n\\n`off`\\n\\ndisables passing a request to the next server.\\n\\nOne should bear in mind that passing a request to the next server is only possible if nothing has been sent to a client yet. That is, if an error or timeout occurs in the middle of the transferring of a response, fixing this is impossible.\\nThe directive also defines what is considered an [unsuccessful attempt](ngx_http_upstream_module.html#max_fails) of communication with a server. The cases of `error`, `timeout` and `invalid_header` are always considered unsuccessful attempts, even if they are not specified in the directive. The cases of `http_500`, `http_502`, `http_503`, `http_504`, and `http_429` are considered unsuccessful attempts only if they are specified in the directive. The cases of `http_403` and `http_404` are never considered unsuccessful attempts.\\nPassing a request to the next server can be limited by [the number of tries](#grpc_next_upstream_tries) and by [time](#grpc_next_upstream_timeout)."},{"m":"ngx_http_grpc_module","n":"grpc_next_upstream_timeout","d":"Limits the time during which a request can be passed to the [next server](#grpc_next_upstream). The `0` value turns off this limitation."},{"m":"ngx_http_grpc_module","n":"grpc_next_upstream_tries","d":"Limits the number of possible tries for passing a request to the [next server](#grpc_next_upstream). The `0` value turns off this limitation."},{"m":"ngx_http_grpc_module","n":"grpc_pass","d":"Sets the gRPC server address. The address can be specified as a domain name or IP address, and a port:\\n```\\ngrpc_pass localhost:9000;\\n\\n```\\nor as a UNIX-domain socket path:\\n```\\ngrpc_pass unix:/tmp/grpc.socket;\\n\\n```\\nAlternatively, the \u201c`grpc://`\u201d scheme can be used:\\n```\\ngrpc_pass grpc://127.0.0.1:9000;\\n\\n```\\nTo use gRPC over SSL, the \u201c`grpcs://`\u201d scheme should be used:\\n```\\ngrpc_pass grpcs://127.0.0.1:443;\\n\\n```\\n\\nIf a domain name resolves to several addresses, all of them will be used in a round-robin fashion. In addition, an address can be specified as a [server group](ngx_http_upstream_module.html).\\nParameter value can contain variables (1.17.8). In this case, if an address is specified as a domain name, the name is searched among the described [server groups](ngx_http_upstream_module.html), and, if not found, is determined using a [resolver](ngx_http_core_module.html#resolver)."},{"m":"ngx_http_grpc_module","n":"grpc_pass_header","d":"Permits passing [otherwise disabled](#grpc_hide_header) header fields from a gRPC server to a client."},{"m":"ngx_http_grpc_module","n":"grpc_read_timeout","d":"Defines a timeout for reading a response from the gRPC server. The timeout is set only between two successive read operations, not for the transmission of the whole response. If the gRPC server does not transmit anything within this time, the connection is closed."},{"m":"ngx_http_grpc_module","n":"grpc_send_timeout","d":"Sets a timeout for transmitting a request to the gRPC server. The timeout is set only between two successive write operations, not for the transmission of the whole request. If the gRPC server does not receive anything within this time, the connection is closed."},{"m":"ngx_http_grpc_module","n":"grpc_set_header","d":"Allows redefining or appending fields to the request header [passed](#grpc_pass_request_headers) to the gRPC server. The `_value_` can contain text, variables, and their combinations. These directives are inherited from the previous configuration level if and only if there are no `grpc_set_header` directives defined on the current level.\\nIf the value of a header field is an empty string then this field will not be passed to a gRPC server:\\n```\\ngrpc_set_header Accept-Encoding \\"\\";\\n\\n```\\n"},{"m":"ngx_http_grpc_module","n":"grpc_socket_keepalive","d":"Configures the \u201cTCP keepalive\u201d behavior for outgoing connections to a gRPC server. By default, the operating system\u2019s settings are in effect for the socket. If the directive is set to the value \u201c`on`\u201d, the `SO_KEEPALIVE` socket option is turned on for the socket."},{"m":"ngx_http_grpc_module","n":"grpc_ssl_certificate","d":"Specifies a `_file_` with the certificate in the PEM format used for authentication to a gRPC SSL server."},{"m":"ngx_http_grpc_module","n":"grpc_ssl_certificate_key","d":"Specifies a `_file_` with the secret key in the PEM format used for authentication to a gRPC SSL server.\\nThe value `engine`:`_name_`:`_id_` can be specified instead of the `_file_`, which loads a secret key with a specified `_id_` from the OpenSSL engine `_name_`."},{"m":"ngx_http_grpc_module","n":"grpc_ssl_ciphers","d":"Specifies the enabled ciphers for requests to a gRPC SSL server. The ciphers are specified in the format understood by the OpenSSL library.\\nThe full list can be viewed using the \u201c`openssl ciphers`\u201d command."},{"m":"ngx_http_grpc_module","n":"grpc_ssl_conf_command","d":"Sets arbitrary OpenSSL configuration [commands](https://www.openssl.org/docs/man1.1.1/man3/SSL_CONF_cmd.html) when establishing a connection with the gRPC SSL server.\\nThe directive is supported when using OpenSSL 1.0.2 or higher.\\n\\nSeveral `grpc_ssl_conf_command` directives can be specified on the same level. These directives are inherited from the previous configuration level if and only if there are no `grpc_ssl_conf_command` directives defined on the current level.\\n\\nNote that configuring OpenSSL directly might result in unexpected behavior.\\n"},{"m":"ngx_http_grpc_module","n":"grpc_ssl_crl","d":"Specifies a `_file_` with revoked certificates (CRL) in the PEM format used to [verify](#grpc_ssl_verify) the certificate of the gRPC SSL server."},{"m":"ngx_http_grpc_module","n":"grpc_ssl_name","d":"Allows overriding the server name used to [verify](#grpc_ssl_verify) the certificate of the gRPC SSL server and to be [passed through SNI](#grpc_ssl_server_name) when establishing a connection with the gRPC SSL server.\\nBy default, the host part from [grpc\\\\_pass](#grpc_pass) is used."},{"m":"ngx_http_grpc_module","n":"grpc_ssl_password_file","d":"Specifies a `_file_` with passphrases for [secret keys](#grpc_ssl_certificate_key) where each passphrase is specified on a separate line. Passphrases are tried in turn when loading the key."},{"m":"ngx_http_grpc_module","n":"grpc_ssl_protocols","d":"Enables the specified protocols for requests to a gRPC SSL server."},{"m":"ngx_http_grpc_module","n":"grpc_ssl_server_name","d":"Enables or disables passing of the server name through [TLS Server Name Indication extension](http://en.wikipedia.org/wiki/Server_Name_Indication) (SNI, RFC 6066) when establishing a connection with the gRPC SSL server."},{"m":"ngx_http_grpc_module","n":"grpc_ssl_session_reuse","d":"Determines whether SSL sessions can be reused when working with the gRPC server. If the errors \u201c`SSL3_GET_FINISHED:digest check failed`\u201d appear in the logs, try disabling session reuse."},{"m":"ngx_http_grpc_module","n":"grpc_ssl_trusted_certificate","d":"Specifies a `_file_` with trusted CA certificates in the PEM format used to [verify](#grpc_ssl_verify) the certificate of the gRPC SSL server."},{"m":"ngx_http_grpc_module","n":"grpc_ssl_verify","d":"Enables or disables verification of the gRPC SSL server certificate."},{"m":"ngx_http_gunzip_module","n":"summary","d":"The `ngx_http_gunzip_module` module is a filter that decompresses responses with \u201c`Content-Encoding: gzip`\u201d for clients that do not support \u201cgzip\u201d encoding method. The module will be useful when it is desirable to store data compressed to save space and reduce I/O costs.\\nThis module is not built by default, it should be enabled with the `--with-http_gunzip_module` configuration parameter."},{"m":"ngx_http_gunzip_module","n":"gunzip","d":"Enables or disables decompression of gzipped responses for clients that lack gzip support. If enabled, the following directives are also taken into account when determining if clients support gzip: [gzip\\\\_http\\\\_version](ngx_http_gzip_module.html#gzip_http_version), [gzip\\\\_proxied](ngx_http_gzip_module.html#gzip_proxied), and [gzip\\\\_disable](ngx_http_gzip_module.html#gzip_disable). See also the [gzip\\\\_vary](ngx_http_gzip_module.html#gzip_vary) directive."},{"m":"ngx_http_gzip_module","n":"summary","d":"The `ngx_http_gzip_module` module is a filter that compresses responses using the \u201cgzip\u201d method. This often helps to reduce the size of transmitted data by half or even more.\\nWhen using the SSL/TLS protocol, compressed responses may be subject to [BREACH](https://en.wikipedia.org/wiki/BREACH) attacks.\\n"},{"m":"ngx_http_gzip_module","n":"gzip","d":"Enables or disables gzipping of responses."},{"m":"ngx_http_gzip_module","n":"gzip_buffers","d":"Sets the `_number_` and `_size_` of buffers used to compress a response. By default, the buffer size is equal to one memory page. This is either 4K or 8K, depending on a platform.\\nUntil version 0.7.28, four 4K or 8K buffers were used by default.\\n"},{"m":"ngx_http_gzip_module","n":"gzip_comp_level","d":"Sets a gzip compression `_level_` of a response. Acceptable values are in the range from 1 to 9."},{"m":"ngx_http_gzip_module","n":"gzip_disable","d":"Disables gzipping of responses for requests with \u201cUser-Agent\u201d header fields matching any of the specified regular expressions.\\nThe special mask \u201c`msie6`\u201d (0.7.12) corresponds to the regular expression \u201c`MSIE [4-6]\\\\.`\u201d, but works faster. Starting from version 0.8.11, \u201c`MSIE 6.0; ... SV1`\u201d is excluded from this mask."},{"m":"ngx_http_gzip_module","n":"gzip_http_version","d":"Sets the minimum HTTP version of a request required to compress a response."},{"m":"ngx_http_gzip_module","n":"gzip_min_length","d":"Sets the minimum length of a response that will be gzipped. The length is determined only from the \u201cContent-Length\u201d response header field."},{"m":"ngx_http_gzip_module","n":"gzip_proxied","d":"Enables or disables gzipping of responses for proxied requests depending on the request and response. The fact that the request is proxied is determined by the presence of the \u201cVia\u201d request header field. The directive accepts multiple parameters:\\n`off`\\n\\ndisables compression for all proxied requests, ignoring other parameters;\\n\\n`expired`\\n\\nenables compression if a response header includes the \u201cExpires\u201d field with a value that disables caching;\\n\\n`no-cache`\\n\\nenables compression if a response header includes the \u201cCache-Control\u201d field with the \u201c`no-cache`\u201d parameter;\\n\\n`no-store`\\n\\nenables compression if a response header includes the \u201cCache-Control\u201d field with the \u201c`no-store`\u201d parameter;\\n\\n`private`\\n\\nenables compression if a response header includes the \u201cCache-Control\u201d field with the \u201c`private`\u201d parameter;\\n\\n`no_last_modified`\\n\\nenables compression if a response header does not include the \u201cLast-Modified\u201d field;\\n\\n`no_etag`\\n\\nenables compression if a response header does not include the \u201cETag\u201d field;\\n\\n`auth`\\n\\nenables compression if a request header includes the \u201cAuthorization\u201d field;\\n\\n`any`\\n\\nenables compression for all proxied requests.\\n"},{"m":"ngx_http_gzip_module","n":"gzip_types","d":"Enables gzipping of responses for the specified MIME types in addition to \u201c`text/html`\u201d. The special value \u201c`*`\u201d matches any MIME type (0.8.29). Responses with the \u201c`text/html`\u201d type are always compressed."},{"m":"ngx_http_gzip_module","n":"gzip_vary","d":"Enables or disables inserting the \u201cVary: Accept-Encoding\u201d response header field if the directives [gzip](#gzip), [gzip\\\\_static](ngx_http_gzip_static_module.html#gzip_static), or [gunzip](ngx_http_gunzip_module.html#gunzip) are active."},{"m":"ngx_http_gzip_module","n":"$gzip_ratio","d":"achieved compression ratio, computed as the ratio between the original and compressed response sizes."},{"m":"ngx_http_gzip_static_module","n":"summary","d":"The `ngx_http_gzip_static_module` module allows sending precompressed files with the \u201c`.gz`\u201d filename extension instead of regular files.\\nThis module is not built by default, it should be enabled with the `--with-http_gzip_static_module` configuration parameter."},{"m":"ngx_http_headers_module","n":"summary","d":"The `ngx_http_headers_module` module allows adding the \u201cExpires\u201d and \u201cCache-Control\u201d header fields, and arbitrary fields, to a response header."},{"m":"ngx_http_headers_module","n":"add_header","d":"Adds the specified field to a response header provided that the response code equals 200, 201 (1.3.10), 204, 206, 301, 302, 303, 304, 307 (1.1.16, 1.0.13), or 308 (1.13.0). Parameter value can contain variables.\\nThere could be several `add_header` directives. These directives are inherited from the previous configuration level if and only if there are no `add_header` directives defined on the current level.\\nIf the `always` parameter is specified (1.7.5), the header field will be added regardless of the response code."},{"m":"ngx_http_headers_module","n":"add_trailer","d":"Adds the specified field to the end of a response provided that the response code equals 200, 201, 206, 301, 302, 303, 307, or 308. Parameter value can contain variables.\\nThere could be several `add_trailer` directives. These directives are inherited from the previous configuration level if and only if there are no `add_trailer` directives defined on the current level.\\nIf the `always` parameter is specified the specified field will be added regardless of the response code."},{"m":"ngx_http_hls_module","n":"summary","d":"The `ngx_http_hls_module` module provides HTTP Live Streaming (HLS) server-side support for MP4 and MOV media files. Such files typically have the `.mp4`, `.m4v`, `.m4a`, `.mov`, or `.qt` filename extensions. The module supports H.264 video codec, AAC and MP3 audio codecs.\\nFor each media file, two URIs are supported:\\n*   A playlist URI with the \u201c`.m3u8`\u201d filename extension. The URI can accept optional arguments:\\n    *   \u201c`start`\u201d and \u201c`end`\u201d define playlist boundaries in seconds (1.9.0).\\n    *   \u201c`offset`\u201d shifts an initial playback position to the time offset in seconds (1.9.0). A positive value sets a time offset from the beginning of the playlist. A negative value sets a time offset from the end of the last fragment in the playlist.\\n    *   \u201c`len`\u201d defines the fragment length in seconds.\\n*   A fragment URI with the \u201c`.ts`\u201d filename extension. The URI can accept optional arguments:\\n    *   \u201c`start`\u201d and \u201c`end`\u201d define fragment boundaries in seconds.\\n\\n\\nThis module is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_hls_module","n":"hls","d":"Turns on HLS streaming in the surrounding location."},{"m":"ngx_http_hls_module","n":"hls_buffers","d":"Sets the maximum `_number_` and `_size_` of buffers that are used for reading and writing data frames."},{"m":"ngx_http_hls_module","n":"hls_forward_args","d":"Adds arguments from a playlist request to URIs of fragments. This may be useful for performing client authorization at the moment of requesting a fragment, or when protecting an HLS stream with the [ngx\\\\_http\\\\_secure\\\\_link\\\\_module](ngx_http_secure_link_module.html) module.\\nFor example, if a client requests a playlist `http://example.com/hls/test.mp4.m3u8?a=1&b=2`, the arguments `a=1` and `b=2` will be added to URIs of fragments after the arguments `start` and `end`:\\n```\\n#EXTM3U\\n#EXT-X-VERSION:3\\n#EXT-X-TARGETDURATION:15\\n#EXT-X-PLAYLIST-TYPE:VOD\\n\\n#EXTINF:9.333,\\ntest.mp4.ts?start=0.000&end=9.333&a=1&b=2\\n#EXTINF:7.167,\\ntest.mp4.ts?start=9.333&end=16.500&a=1&b=2\\n#EXTINF:5.416,\\ntest.mp4.ts?start=16.500&end=21.916&a=1&b=2\\n#EXTINF:5.500,\\ntest.mp4.ts?start=21.916&end=27.416&a=1&b=2\\n#EXTINF:15.167,\\ntest.mp4.ts?start=27.416&end=42.583&a=1&b=2\\n#EXTINF:9.626,\\ntest.mp4.ts?start=42.583&end=52.209&a=1&b=2\\n\\n#EXT-X-ENDLIST\\n\\n```\\n\\nIf an HLS stream is protected with the [ngx\\\\_http\\\\_secure\\\\_link\\\\_module](ngx_http_secure_link_module.html) module, `$uri` should not be used in the [secure\\\\_link\\\\_md5](ngx_http_secure_link_module.html#secure_link_md5) expression because this will cause errors when requesting the fragments. [Base URI](ngx_http_map_module.html#map) should be used instead of `$uri` (`$hls_uri` in the example):\\n```\\nhttp {\\n    ...\\n\\n    map $uri $hls_uri {\\n        ~^(?<base_uri>.*).m3u8$ $base_uri;\\n        ~^(?<base_uri>.*).ts$   $base_uri;\\n        default                 $uri;\\n    }\\n\\n    server {\\n        ...\\n\\n        location /hls/ {\\n            hls;\\n            hls_forward_args on;\\n\\n            alias /var/videos/;\\n\\n            secure_link $arg_md5,$arg_expires;\\n            secure_link_md5 \\"$secure_link_expires$hls_uri$remote_addr secret\\";\\n\\n            if ($secure_link = \\"\\") {\\n                return 403;\\n            }\\n\\n            if ($secure_link = \\"0\\") {\\n                return 410;\\n            }\\n        }\\n    }\\n}\\n\\n```\\n"},{"m":"ngx_http_hls_module","n":"hls_fragment","d":"Defines the default fragment length for playlist URIs requested without the \u201c`len`\u201d argument."},{"m":"ngx_http_hls_module","n":"hls_mp4_buffer_size","d":"Sets the initial `_size_` of the buffer used for processing MP4 and MOV files."},{"m":"ngx_http_image_filter_module","n":"summary","d":"The `ngx_http_image_filter_module` module (0.7.54+) is a filter that transforms images in JPEG, GIF, PNG, and WebP formats.\\nThis module is not built by default, it should be enabled with the `--with-http_image_filter_module` configuration parameter.\\nThis module utilizes the [libgd](http://libgd.org) library. It is recommended to use the latest available version of the library.\\n\\nThe WebP format support appeared in version 1.11.6. To transform images in this format, the `libgd` library must be compiled with the WebP support.\\n"},{"m":"ngx_http_image_filter_module","n":"image_filter","d":"Sets the type of transformation to perform on images:\\n`off`\\n\\nturns off module processing in a surrounding location.\\n\\n`test`\\n\\nensures that responses are images in either JPEG, GIF, PNG, or WebP format. Otherwise, the 415 (Unsupported Media Type) error is returned.\\n\\n`size`\\n\\noutputs information about images in a JSON format, e.g.:\\n\\n> { \\"img\\" : { \\"width\\": 100, \\"height\\": 100, \\"type\\": \\"gif\\" } }\\n\\nIn case of an error, the output is as follows:\\n\\n> {}\\n\\n`rotate` `90`|`180`|`270`\\n\\nrotates images counter-clockwise by the specified number of degrees. Parameter value can contain variables. This mode can be used either alone or along with the `resize` and `crop` transformations.\\n\\n`resize` `_width_` `_height_`\\n\\nproportionally reduces an image to the specified sizes. To reduce by only one dimension, another dimension can be specified as \u201c`-`\u201d. In case of an error, the server will return code 415 (Unsupported Media Type). Parameter values can contain variables. When used along with the `rotate` parameter, the rotation happens **after** reduction.\\n\\n`crop` `_width_` `_height_`\\n\\nproportionally reduces an image to the larger side size and crops extraneous edges by another side. To reduce by only one dimension, another dimension can be specified as \u201c`-`\u201d. In case of an error, the server will return code 415 (Unsupported Media Type). Parameter values can contain variables. When used along with the `rotate` parameter, the rotation happens **before** reduction.\\n"},{"m":"ngx_http_image_filter_module","n":"image_filter_buffer","d":"Sets the maximum size of the buffer used for reading images. When the size is exceeded the server returns error 415 (Unsupported Media Type)."},{"m":"ngx_http_image_filter_module","n":"image_filter_interlace","d":"If enabled, final images will be interlaced. For JPEG, final images will be in \u201cprogressive JPEG\u201d format."},{"m":"ngx_http_image_filter_module","n":"image_filter_jpeg_quality","d":"Sets the desired `_quality_` of the transformed JPEG images. Acceptable values are in the range from 1 to 100. Lesser values usually imply both lower image quality and less data to transfer. The maximum recommended value is 95. Parameter value can contain variables."},{"m":"ngx_http_image_filter_module","n":"image_filter_sharpen","d":"Increases sharpness of the final image. The sharpness percentage can exceed 100. The zero value disables sharpening. Parameter value can contain variables."},{"m":"ngx_http_image_filter_module","n":"image_filter_transparency","d":"Defines whether transparency should be preserved when transforming GIF images or PNG images with colors specified by a palette. The loss of transparency results in images of a better quality. The alpha channel transparency in PNG is always preserved."},{"m":"ngx_http_index_module","n":"summary","d":"The `ngx_http_index_module` module processes requests ending with the slash character (\u2018`/`\u2019). Such requests can also be processed by the [ngx\\\\_http\\\\_autoindex\\\\_module](ngx_http_autoindex_module.html) and [ngx\\\\_http\\\\_random\\\\_index\\\\_module](ngx_http_random_index_module.html) modules."},{"m":"ngx_http_js_module","n":"summary","d":"The `ngx_http_js_module` module is used to implement location and variable handlers in [njs](../njs/index.html)\xa0\u2014 a subset of the JavaScript language.\\nDownload and install instructions are available [here](../njs/install.html)."},{"m":"ngx_http_js_module","n":"js_content","d":"Sets an njs function as a location content handler. Since [0.4.0](../njs/changes.html#njs0.4.0), a module function can be referenced."},{"m":"ngx_http_js_module","n":"js_import","d":"Imports a module that implements location and variable handlers in njs. The `export_name` is used as a namespace to access module functions. If the `export_name` is not specified, the module name will be used as a namespace.\\n```\\njs_import http.js;\\n\\n```\\nHere, the module name `http` is used as a namespace while accessing exports. If the imported module contains `foo()`, `http.foo` is used to refer to it.\\nSeveral `js_import` directives can be specified."},{"m":"ngx_http_js_module","n":"js_include","d":"Specifies a file that implements location and variable handlers in njs:\\n```\\nnginx.conf:\\njs_include http.js;\\nlocation   /version {\\n    js_content version;\\n}\\n\\nhttp.js:\\nfunction version(r) {\\n    r.return(200, njs.version);\\n}\\n\\n```\\n\\nThe directive is deprecated since [0.4.0](../njs/changes.html#njs0.4.0), the [js\\\\_import](#js_import) directive should be used instead."},{"m":"ngx_http_js_module","n":"js_path","d":"Sets an additional path for njs modules."},{"m":"ngx_http_js_module","n":"js_set","d":"Sets an njs function for the specified variable. Since [0.4.0](../njs/changes.html#njs0.4.0), a module function can be referenced."},{"m":"ngx_http_keyval_module","n":"summary","d":"The `ngx_http_keyval_module` module (1.13.3) creates variables with values taken from key-value pairs managed by the [API](ngx_http_api_module.html#http_keyvals_) or a variable (1.15.10) that can also be set with [njs](../njs/examples.html#requests).\\n\\nThis module is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_keyval_module","n":"keyval","d":"Creates a new `_$variable_` whose value is looked up by the `_key_` in the key-value database. Matching rules are defined by the [`type`](#keyval_type) parameter of the [`keyval_zone`](#keyval_zone) directive. The database is stored in a shared memory zone specified by the `zone` parameter."},{"m":"ngx_http_keyval_module","n":"keyval_zone","d":"Sets the `_name_` and `_size_` of the shared memory zone that keeps the key-value database. Key-value pairs are managed by the [API](ngx_http_api_module.html#http_keyvals_)."},{"m":"ngx_http_keyval_module","n":"keyval_state","d":"The optional `state` parameter specifies a `_file_` that keeps the current state of the key-value database in the JSON format and makes it persistent across nginx restarts.\\nExamples:\\n```\\nkeyval_zone zone=one:32k state=/var/lib/nginx/state/one.keyval; # path for Linux\\nkeyval_zone zone=one:32k state=/var/db/nginx/state/one.keyval;  # path for FreeBSD\\n\\n```\\n"},{"m":"ngx_http_keyval_module","n":"keyval_timeout","d":"The optional `timeout` parameter (1.15.0) sets the time after which key-value pairs are removed from the zone."},{"m":"ngx_http_keyval_module","n":"keyval_type","d":"The optional `type` parameter (1.17.1) activates an extra index optimized for matching the key of a certain type and defines matching rules when evaluating a [keyval](#keyval) `$variable`.\\nThe index is stored in the same shared memory zone and thus requires additional storage.\\n\\n`type=string`\\n\\ndefault, no index is enabled; variable lookup is performed using exact match of the record key and a search key\\n\\n`type=ip`\\n\\nthe search key is the textual representation of IPv4 or IPv6 address or CIDR range; to match a record key, the search key must belong to a subnet specified by a record key or exactly match an IP address\\n\\n`type=prefix`\\n\\nvariable lookup is performed using prefix match of a record key and a search key (1.17.5); to match a record key, the record key must be a prefix of the search key\\n"},{"m":"ngx_http_limit_conn_module","n":"summary","d":"The `ngx_http_limit_conn_module` module is used to limit the number of connections per the defined key, in particular, the number of connections from a single IP address.\\nNot all connections are counted. A connection is counted only if it has a request being processed by the server and the whole request header has already been read."},{"m":"ngx_http_limit_conn_module","n":"limit_conn","d":"Sets the shared memory zone and the maximum allowed number of connections for a given key value. When this limit is exceeded, the server will return the [error](#limit_conn_status) in reply to a request. For example, the directives\\n```\\nlimit_conn_zone $binary_remote_addr zone=addr:10m;\\n\\nserver {\\n    location /download/ {\\n        limit_conn addr 1;\\n    }\\n\\n```\\nallow only one connection per an IP address at a time.\\nIn HTTP/2 and SPDY, each concurrent request is considered a separate connection.\\n\\nThere could be several `limit_conn` directives. For example, the following configuration will limit the number of connections to the server per a client IP and, at the same time, the total number of connections to the virtual server:\\n```\\nlimit_conn_zone $binary_remote_addr zone=perip:10m;\\nlimit_conn_zone $server_name zone=perserver:10m;\\n\\nserver {\\n    ...\\n    limit_conn perip 10;\\n    limit_conn perserver 100;\\n}\\n\\n```\\n\\nThese directives are inherited from the previous configuration level if and only if there are no `limit_conn` directives defined on the current level."},{"m":"ngx_http_limit_conn_module","n":"limit_conn_dry_run","d":"Enables the dry run mode. In this mode, the number of connections is not limited, however, in the shared memory zone, the number of excessive connections is accounted as usual."},{"m":"ngx_http_limit_conn_module","n":"limit_conn_log_level","d":"Sets the desired logging level for cases when the server limits the number of connections."},{"m":"ngx_http_limit_conn_module","n":"limit_conn_status","d":"Sets the status code to return in response to rejected requests."},{"m":"ngx_http_limit_conn_module","n":"limit_conn_zone","d":"Sets parameters for a shared memory zone that will keep states for various keys. In particular, the state includes the current number of connections. The `_key_` can contain text, variables, and their combination. Requests with an empty key value are not accounted.\\nPrior to version 1.7.6, a `_key_` could contain exactly one variable.\\nUsage example:\\n```\\nlimit_conn_zone $binary_remote_addr zone=addr:10m;\\n\\n```\\nHere, a client IP address serves as a key. Note that instead of `$remote_addr`, the `$binary_remote_addr` variable is used here. The `$remote_addr` variable\u2019s size can vary from 7 to 15 bytes. The stored state occupies either 32 or 64 bytes of memory on 32-bit platforms and always 64 bytes on 64-bit platforms. The `$binary_remote_addr` variable\u2019s size is always 4 bytes for IPv4 addresses or 16 bytes for IPv6 addresses. The stored state always occupies 32 or 64 bytes on 32-bit platforms and 64 bytes on 64-bit platforms. One megabyte zone can keep about 32 thousand 32-byte states or about 16 thousand 64-byte states. If the zone storage is exhausted, the server will return the [error](#limit_conn_status) to all further requests.\\n\\nAdditionally, as part of our [commercial subscription](http://nginx.com/products/), the [status information](ngx_http_api_module.html#http_limit_conns_) for each such shared memory zone can be [obtained](ngx_http_api_module.html#getHttpLimitConnZone) or [reset](ngx_http_api_module.html#deleteHttpLimitConnZoneStat) with the [API](ngx_http_api_module.html) since 1.17.7.\\n"},{"m":"ngx_http_limit_conn_module","n":"limit_zone","d":"This directive was made obsolete in version 1.1.8 and was removed in version 1.7.6. An equivalent [limit\\\\_conn\\\\_zone](#limit_conn_zone) directive with a changed syntax should be used instead:\\n`limit_conn_zone` `_$variable_` `zone`\\\\=`_name_`:`_size_`;\\n"},{"m":"ngx_http_limit_conn_module","n":"$limit_conn_status","d":"keeps the result of limiting the number of connections (1.17.6): `PASSED`, `REJECTED`, or `REJECTED_DRY_RUN`"},{"m":"ngx_http_limit_req_module","n":"summary","d":"The `ngx_http_limit_req_module` module (0.7.21) is used to limit the request processing rate per a defined key, in particular, the processing rate of requests coming from a single IP address. The limitation is done using the \u201cleaky bucket\u201d method."},{"m":"ngx_http_limit_req_module","n":"limit_req","d":"Sets the shared memory zone and the maximum burst size of requests. If the requests rate exceeds the rate configured for a zone, their processing is delayed such that requests are processed at a defined rate. Excessive requests are delayed until their number exceeds the maximum burst size in which case the request is terminated with an [error](#limit_req_status). By default, the maximum burst size is equal to zero. For example, the directives\\n```\\nlimit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;\\n\\nserver {\\n    location /search/ {\\n        limit_req zone=one burst=5;\\n    }\\n\\n```\\nallow not more than 1 request per second at an average, with bursts not exceeding 5 requests.\\nIf delaying of excessive requests while requests are being limited is not desired, the parameter `nodelay` should be used:\\n```\\nlimit_req zone=one burst=5 nodelay;\\n\\n```\\n"},{"m":"ngx_http_limit_req_module","n":"limit_req_delay","d":"The `delay` parameter (1.15.7) specifies a limit at which excessive requests become delayed. Default value is zero, i.e. all excessive requests are delayed.\\nThere could be several `limit_req` directives. For example, the following configuration will limit the processing rate of requests coming from a single IP address and, at the same time, the request processing rate by the virtual server:\\n```\\nlimit_req_zone $binary_remote_addr zone=perip:10m rate=1r/s;\\nlimit_req_zone $server_name zone=perserver:10m rate=10r/s;\\n\\nserver {\\n    ...\\n    limit_req zone=perip burst=5 nodelay;\\n    limit_req zone=perserver burst=10;\\n}\\n\\n```\\n\\nThese directives are inherited from the previous configuration level if and only if there are no `limit_req` directives defined on the current level."},{"m":"ngx_http_limit_req_module","n":"limit_req_dry_run","d":"Enables the dry run mode. In this mode, requests processing rate is not limited, however, in the shared memory zone, the number of excessive requests is accounted as usual."},{"m":"ngx_http_limit_req_module","n":"limit_req_log_level","d":"Sets the desired logging level for cases when the server refuses to process requests due to rate exceeding, or delays request processing. Logging level for delays is one point less than for refusals; for example, if \u201c`limit_req_log_level notice`\u201d is specified, delays are logged with the `info` level."},{"m":"ngx_http_limit_req_module","n":"limit_req_status","d":"Sets the status code to return in response to rejected requests."},{"m":"ngx_http_limit_req_module","n":"limit_req_zone","d":"Sets parameters for a shared memory zone that will keep states for various keys. In particular, the state stores the current number of excessive requests. The `_key_` can contain text, variables, and their combination. Requests with an empty key value are not accounted.\\nPrior to version 1.7.6, a `_key_` could contain exactly one variable.\\nUsage example:\\n```\\nlimit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;\\n\\n```\\n\\nHere, the states are kept in a 10 megabyte zone \u201cone\u201d, and an average request processing rate for this zone cannot exceed 1 request per second.\\nA client IP address serves as a key. Note that instead of `$remote_addr`, the `$binary_remote_addr` variable is used here. The `$binary_remote_addr` variable\u2019s size is always 4 bytes for IPv4 addresses or 16 bytes for IPv6 addresses. The stored state always occupies 64 bytes on 32-bit platforms and 128 bytes on 64-bit platforms. One megabyte zone can keep about 16 thousand 64-byte states or about 8 thousand 128-byte states.\\nIf the zone storage is exhausted, the least recently used state is removed. If even after that a new state cannot be created, the request is terminated with an [error](#limit_req_status).\\nThe rate is specified in requests per second (r/s). If a rate of less than one request per second is desired, it is specified in request per minute (r/m). For example, half-request per second is 30r/m."},{"m":"ngx_http_limit_req_module","n":"limit_req_zone_sync","d":"The `sync` parameter (1.15.3) enables [synchronization](../stream/ngx_stream_zone_sync_module.html#zone_sync) of the shared memory zone.\\nThe `sync` parameter is available as part of our [commercial subscription](http://nginx.com/products/).\\n\\n\\nAdditionally, as part of our [commercial subscription](http://nginx.com/products/), the [status information](ngx_http_api_module.html#http_limit_reqs_) for each such shared memory zone can be [obtained](ngx_http_api_module.html#getHttpLimitReqZone) or [reset](ngx_http_api_module.html#deleteHttpLimitReqZoneStat) with the [API](ngx_http_api_module.html) since 1.17.7.\\n"},{"m":"ngx_http_limit_req_module","n":"$limit_req_status","d":"keeps the result of limiting the request processing rate (1.17.6): `PASSED`, `DELAYED`, `REJECTED`, `DELAYED_DRY_RUN`, or `REJECTED_DRY_RUN`"},{"m":"ngx_http_log_module","n":"summary","d":"The `ngx_http_log_module` module writes request logs in the specified format.\\nRequests are logged in the context of a location where processing ends. It may be different from the original location, if an [internal redirect](ngx_http_core_module.html#internal) happens during request processing."},{"m":"ngx_http_log_module","n":"access_log","d":"Sets the path, format, and configuration for a buffered log write. Several logs can be specified on the same configuration level. Logging to [syslog](../syslog.html) can be configured by specifying the \u201c`syslog:`\u201d prefix in the first parameter. The special value `off` cancels all `access_log` directives on the current level. If the format is not specified then the predefined \u201c`combined`\u201d format is used.\\nIf either the `buffer` or `gzip` (1.3.10, 1.2.7) parameter is used, writes to log will be buffered.\\nThe buffer size must not exceed the size of an atomic write to a disk file. For FreeBSD this size is unlimited.\\n\\nWhen buffering is enabled, the data will be written to the file:\\n*   if the next log line does not fit into the buffer;\\n*   if the buffered data is older than specified by the `flush` parameter (1.3.10, 1.2.7);\\n*   when a worker process is [re-opening](../control.html) log files or is shutting down.\\n\\nIf the `gzip` parameter is used, then the buffered data will be compressed before writing to the file. The compression level can be set between 1 (fastest, less compression) and 9 (slowest, best compression). By default, the buffer size is equal to 64K bytes, and the compression level is set to 1. Since the data is compressed in atomic blocks, the log file can be decompressed or read by \u201c`zcat`\u201d at any time.\\nExample:\\n```\\naccess_log /path/to/log.gz combined gzip flush=5m;\\n\\n```\\n\\n\\nFor gzip compression to work, nginx must be built with the zlib library.\\n\\nThe file path can contain variables (0.7.6+), but such logs have some constraints:\\n*   the [user](../ngx_core_module.html#user) whose credentials are used by worker processes should have permissions to create files in a directory with such logs;\\n*   buffered writes do not work;\\n*   the file is opened and closed for each log write. However, since the descriptors of frequently used files can be stored in a [cache](#open_log_file_cache), writing to the old file can continue during the time specified by the [open\\\\_log\\\\_file\\\\_cache](#open_log_file_cache) directive\u2019s `valid` parameter\\n*   during each log write the existence of the request\u2019s [root directory](ngx_http_core_module.html#root) is checked, and if it does not exist the log is not created. It is thus a good idea to specify both [root](ngx_http_core_module.html#root) and `access_log` on the same configuration level:\\n    \\n    > server {\\n    >     root       /spool/vhost/data/$host;\\n    >     access\\\\_log /spool/vhost/logs/$host;\\n    >     ...\\n\\nThe `if` parameter (1.7.0) enables conditional logging. A request will not be logged if the `_condition_` evaluates to \u201c0\u201d or an empty string. In the following example, the requests with response codes 2xx and 3xx will not be logged:\\n```\\nmap $status $loggable {\\n    ~^[23]  0;\\n    default 1;\\n}\\n\\naccess_log /path/to/access.log combined if=$loggable;\\n\\n```\\n"},{"m":"ngx_http_log_module","n":"log_format","d":"Specifies log format."},{"m":"ngx_http_log_module","n":"log_format_escape","d":"The `escape` parameter (1.11.8) allows setting `json` or `default` characters escaping in variables, by default, `default` escaping is used. The `none` value (1.13.10) disables escaping."},{"m":"ngx_http_log_module","n":"log_format_escape_default","d":"For `default` escaping, characters \u201c`\\"`\u201d, \u201c`\\\\`\u201d, and other characters with values less than 32 (0.7.0) or above 126 (1.1.6) are escaped as \u201c`\\\\xXX`\u201d. If the variable value is not found, a hyphen (\u201c`-`\u201d) will be logged."},{"m":"ngx_http_log_module","n":"log_format_escape_json","d":"For `json` escaping, all characters not allowed in JSON [strings](https://tools.ietf.org/html/rfc8259#section-7) will be escaped: characters \u201c`\\"`\u201d and \u201c`\\\\`\u201d are escaped as \u201c`\\\\\\"`\u201d and \u201c`\\\\\\\\`\u201d, characters with values less than 32 are escaped as \u201c`\\\\n`\u201d, \u201c`\\\\r`\u201d, \u201c`\\\\t`\u201d, \u201c`\\\\b`\u201d, \u201c`\\\\f`\u201d, or \u201c`\\\\u00XX`\u201d.\\nThe log format can contain common variables, and variables that exist only at the time of a log write:\\n`$bytes_sent`\\n\\nthe number of bytes sent to a client\\n\\n`$connection`\\n\\nconnection serial number\\n\\n`$connection_requests`\\n\\nthe current number of requests made through a connection (1.1.18)\\n\\n`$msec`\\n\\ntime in seconds with a milliseconds resolution at the time of the log write\\n\\n`$pipe`\\n\\n\u201c`p`\u201d if request was pipelined, \u201c`.`\u201d otherwise\\n\\n`$request_length`\\n\\nrequest length (including request line, header, and request body)\\n\\n`$request_time`\\n\\nrequest processing time in seconds with a milliseconds resolution; time elapsed between the first bytes were read from the client and the log write after the last bytes were sent to the client\\n\\n`$status`\\n\\nresponse status\\n\\n`$time_iso8601`\\n\\nlocal time in the ISO 8601 standard format\\n\\n`$time_local`\\n\\nlocal time in the Common Log Format\\n\\nIn the modern nginx versions variables [$status](ngx_http_core_module.html#var_status) (1.3.2, 1.2.2), [$bytes\\\\_sent](ngx_http_core_module.html#var_bytes_sent) (1.3.8, 1.2.5), [$connection](ngx_http_core_module.html#var_connection) (1.3.8, 1.2.5), [$connection\\\\_requests](ngx_http_core_module.html#var_connection_requests) (1.3.8, 1.2.5), [$msec](ngx_http_core_module.html#var_msec) (1.3.9, 1.2.6), [$request\\\\_time](ngx_http_core_module.html#var_request_time) (1.3.9, 1.2.6), [$pipe](ngx_http_core_module.html#var_pipe) (1.3.12, 1.2.7), [$request\\\\_length](ngx_http_core_module.html#var_request_length) (1.3.12, 1.2.7), [$time\\\\_iso8601](ngx_http_core_module.html#var_time_iso8601) (1.3.12, 1.2.7), and [$time\\\\_local](ngx_http_core_module.html#var_time_local) (1.3.12, 1.2.7) are also available as common variables.\\n\\nHeader lines sent to a client have the prefix \u201c`sent_http_`\u201d, for example, `$sent_http_content_range`.\\nThe configuration always includes the predefined \u201c`combined`\u201d format:\\n```\\nlog_format combined \'$remote_addr - $remote_user [$time_local] \'\\n                    \'\\"$request\\" $status $body_bytes_sent \'\\n                    \'\\"$http_referer\\" \\"$http_user_agent\\"\';\\n\\n```\\n"},{"m":"ngx_http_map_module","n":"summary","d":"The `ngx_http_map_module` module creates variables whose values depend on values of other variables."},{"m":"ngx_http_map_module","n":"map","d":"Creates a new variable whose value depends on values of one or more of the source variables specified in the first parameter.\\nBefore version 0.9.0 only a single variable could be specified in the first parameter.\\n\\n\\nSince variables are evaluated only when they are used, the mere declaration even of a large number of \u201c`map`\u201d variables does not add any extra costs to request processing.\\n\\nParameters inside the `map` block specify a mapping between source and resulting values.\\nSource values are specified as strings or regular expressions (0.9.6).\\nStrings are matched ignoring the case.\\nA regular expression should either start from the \u201c`~`\u201d symbol for a case-sensitive matching, or from the \u201c`~*`\u201d symbols (1.0.4) for case-insensitive matching. A regular expression can contain named and positional captures that can later be used in other directives along with the resulting variable.\\nIf a source value matches one of the names of special parameters described below, it should be prefixed with the \u201c`\\\\`\u201d symbol.\\nThe resulting value can contain text, variable (0.9.0), and their combination (1.11.0).\\nThe following special parameters are also supported:\\n`default` `_value_`\\n\\nsets the resulting value if the source value matches none of the specified variants. When `default` is not specified, the default resulting value will be an empty string.\\n\\n`hostnames`\\n\\nindicates that source values can be hostnames with a prefix or suffix mask:\\n\\n> \\\\*.example.com 1;\\n> example.\\\\*     1;\\n\\nThe following two records\\n\\n> example.com   1;\\n> \\\\*.example.com 1;\\n\\ncan be combined:\\n\\n> .example.com  1;\\n\\nThis parameter should be specified before the list of values.\\n\\n`include` `_file_`\\n\\nincludes a file with values. There can be several inclusions.\\n\\n`volatile`\\n\\nindicates that the variable is not cacheable (1.11.7).\\n\\nIf the source value matches more than one of the specified variants, e.g. both a mask and a regular expression match, the first matching variant will be chosen, in the following order of priority:\\n*   string value without a mask\\n*   longest string value with a prefix mask, e.g. \u201c`*.example.com`\u201d\\n*   longest string value with a suffix mask, e.g. \u201c`mail.*`\u201d\\n*   first matching regular expression (in order of appearance in a configuration file)\\n*   default value\\n"},{"m":"ngx_http_map_module","n":"map_hash_bucket_size","d":"Sets the bucket size for the [map](#map) variables hash tables. Default value depends on the processor\u2019s cache line size. The details of setting up hash tables are provided in a separate [document](../hash.html)."},{"m":"ngx_http_memcached_module","n":"summary","d":"The `ngx_http_memcached_module` module is used to obtain responses from a memcached server. The key is set in the `$memcached_key` variable. A response should be put in memcached in advance by means external to nginx."},{"m":"ngx_http_memcached_module","n":"memcached_bind","d":"Makes outgoing connections to a memcached server originate from the specified local IP address with an optional port (1.11.2). Parameter value can contain variables (1.3.12). The special value `off` (1.3.12) cancels the effect of the `memcached_bind` directive inherited from the previous configuration level, which allows the system to auto-assign the local IP address and port."},{"m":"ngx_http_memcached_module","n":"memcached_bind_transparent","d":"The `transparent` parameter (1.11.0) allows outgoing connections to a memcached server originate from a non-local IP address, for example, from a real IP address of a client:\\n```\\nmemcached_bind $remote_addr transparent;\\n\\n```\\nIn order for this parameter to work, it is usually necessary to run nginx worker processes with the [superuser](../ngx_core_module.html#user) privileges. On Linux it is not required (1.13.8) as if the `transparent` parameter is specified, worker processes inherit the `CAP_NET_RAW` capability from the master process. It is also necessary to configure kernel routing table to intercept network traffic from the memcached server."},{"m":"ngx_http_memcached_module","n":"memcached_buffer_size","d":"Sets the `_size_` of the buffer used for reading the response received from the memcached server. The response is passed to the client synchronously, as soon as it is received."},{"m":"ngx_http_memcached_module","n":"memcached_connect_timeout","d":"Defines a timeout for establishing a connection with a memcached server. It should be noted that this timeout cannot usually exceed 75 seconds."},{"m":"ngx_http_memcached_module","n":"memcached_force_ranges","d":"Enables byte-range support for both cached and uncached responses from the memcached server regardless of the \u201cAccept-Ranges\u201d field in these responses."},{"m":"ngx_http_memcached_module","n":"memcached_gzip_flag","d":"Enables the test for the `_flag_` presence in the memcached server response and sets the \u201c`Content-Encoding`\u201d response header field to \u201c`gzip`\u201d if the flag is set."},{"m":"ngx_http_memcached_module","n":"memcached_next_upstream","d":"Specifies in which cases a request should be passed to the next server:\\n`error`\\n\\nan error occurred while establishing a connection with the server, passing a request to it, or reading the response header;\\n\\n`timeout`\\n\\na timeout has occurred while establishing a connection with the server, passing a request to it, or reading the response header;\\n\\n`invalid_response`\\n\\na server returned an empty or invalid response;\\n\\n`not_found`\\n\\na response was not found on the server;\\n\\n`off`\\n\\ndisables passing a request to the next server.\\n\\nOne should bear in mind that passing a request to the next server is only possible if nothing has been sent to a client yet. That is, if an error or timeout occurs in the middle of the transferring of a response, fixing this is impossible.\\nThe directive also defines what is considered an [unsuccessful attempt](ngx_http_upstream_module.html#max_fails) of communication with a server. The cases of `error`, `timeout` and `invalid_response` are always considered unsuccessful attempts, even if they are not specified in the directive. The case of `not_found` is never considered an unsuccessful attempt.\\nPassing a request to the next server can be limited by [the number of tries](#memcached_next_upstream_tries) and by [time](#memcached_next_upstream_timeout)."},{"m":"ngx_http_memcached_module","n":"memcached_next_upstream_timeout","d":"Limits the time during which a request can be passed to the [next server](#memcached_next_upstream). The `0` value turns off this limitation."},{"m":"ngx_http_memcached_module","n":"memcached_next_upstream_tries","d":"Limits the number of possible tries for passing a request to the [next server](#memcached_next_upstream). The `0` value turns off this limitation."},{"m":"ngx_http_memcached_module","n":"memcached_pass","d":"Sets the memcached server address. The address can be specified as a domain name or IP address, and a port:\\n```\\nmemcached_pass localhost:11211;\\n\\n```\\nor as a UNIX-domain socket path:\\n```\\nmemcached_pass unix:/tmp/memcached.socket;\\n\\n```\\n\\nIf a domain name resolves to several addresses, all of them will be used in a round-robin fashion. In addition, an address can be specified as a [server group](ngx_http_upstream_module.html)."},{"m":"ngx_http_memcached_module","n":"memcached_read_timeout","d":"Defines a timeout for reading a response from the memcached server. The timeout is set only between two successive read operations, not for the transmission of the whole response. If the memcached server does not transmit anything within this time, the connection is closed."},{"m":"ngx_http_memcached_module","n":"memcached_send_timeout","d":"Sets a timeout for transmitting a request to the memcached server. The timeout is set only between two successive write operations, not for the transmission of the whole request. If the memcached server does not receive anything within this time, the connection is closed."},{"m":"ngx_http_memcached_module","n":"memcached_socket_keepalive","d":"Configures the \u201cTCP keepalive\u201d behavior for outgoing connections to a memcached server. By default, the operating system\u2019s settings are in effect for the socket. If the directive is set to the value \u201c`on`\u201d, the `SO_KEEPALIVE` socket option is turned on for the socket."},{"m":"ngx_http_memcached_module","n":"$memcached_key","d":"Defines a key for obtaining response from a memcached server."},{"m":"ngx_http_mirror_module","n":"summary","d":"The `ngx_http_mirror_module` module (1.13.4) implements mirroring of an original request by creating background mirror subrequests. Responses to mirror subrequests are ignored."},{"m":"ngx_http_mirror_module","n":"mirror","d":"Sets the URI to which an original request will be mirrored. Several mirrors can be specified on the same configuration level."},{"m":"ngx_http_mp4_module","n":"summary","d":"The `ngx_http_mp4_module` module provides pseudo-streaming server-side support for MP4 files. Such files typically have the `.mp4`, `.m4v`, or `.m4a` filename extensions.\\nPseudo-streaming works in alliance with a compatible Flash player. The player sends an HTTP request to the server with the start time specified in the query string argument (named simply `start` and specified in seconds), and the server responds with the stream such that its start position corresponds to the requested time, for example:\\n```\\nhttp://example.com/elephants_dream.mp4?start=238.88\\n\\n```\\nThis allows performing a random seeking at any time, or starting playback in the middle of the timeline.\\nTo support seeking, H.264-based formats store metadata in a so-called \u201cmoov atom\u201d. It is a part of the file that holds the index information for the whole file.\\nTo start playback, the player first needs to read metadata. This is done by sending a special request with the `start=0` argument. A lot of encoding software insert the metadata at the end of the file. This is suboptimal for pseudo-streaming, because the player has to download the entire file before starting playback. If the metadata are located at the beginning of the file, it is enough for nginx to simply start sending back the file contents. If the metadata are located at the end of the file, nginx must read the entire file and prepare a new stream so that the metadata come before the media data. This involves some CPU, memory, and disk I/O overhead, so it is a good idea to [prepare an original file for pseudo-streaming](http://flowplayer.org/plugins/streaming/pseudostreaming.html#prepare) in advance, rather than having nginx do this on every such request.\\nThe module also supports the `end` argument of an HTTP request (1.5.13) which sets the end point of playback. The `end` argument can be specified with the `start` argument or separately:\\n```\\nhttp://example.com/elephants_dream.mp4?start=238.88&end=555.55\\n\\n```\\n\\nFor a matching request with a non-zero `start` or `end` argument, nginx will read the metadata from the file, prepare the stream with the requested time range, and send it to the client. This has the same overhead as described above.\\nIf a matching request does not include the `start` and `end` arguments, there is no overhead, and the file is sent simply as a static resource. Some players also support byte-range requests, and thus do not require this module.\\nThis module is not built by default, it should be enabled with the `--with-http_mp4_module` configuration parameter.\\nIf a third-party mp4 module was previously used, it should be disabled.\\n\\nA similar pseudo-streaming support for FLV files is provided by the [ngx\\\\_http\\\\_flv\\\\_module](ngx_http_flv_module.html) module."},{"m":"ngx_http_mp4_module","n":"mp4","d":"Turns on module processing in a surrounding location."},{"m":"ngx_http_mp4_module","n":"mp4_buffer_size","d":"Sets the initial `_size_` of the buffer used for processing MP4 files."},{"m":"ngx_http_mp4_module","n":"mp4_max_buffer_size","d":"During metadata processing, a larger buffer may become necessary. Its size cannot exceed the specified `_size_`, or else nginx will return the 500 (Internal Server Error) server error, and log the following message:\\n```\\n\\"/some/movie/file.mp4\\" mp4 moov atom is too large:\\n12583268, you may want to increase mp4_max_buffer_size\\n\\n```\\n"},{"m":"ngx_http_mp4_module","n":"mp4_limit_rate","d":"Limits the rate of response transmission to a client. The rate is limited based on the average bitrate of the MP4 file served. To calculate the rate, the bitrate is multiplied by the specified `_factor_`. The special value \u201c`on`\u201d corresponds to the factor of 1.1. The special value \u201c`off`\u201d disables rate limiting. The limit is set per a request, and so if a client simultaneously opens two connections, the overall rate will be twice as much as the specified limit.\\n\\nThis directive is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_perl_module","n":"summary","d":"The `ngx_http_perl_module` module is used to implement location and variable handlers in Perl and insert Perl calls into SSI.\\nThis module is not built by default, it should be enabled with the `--with-http_perl_module` configuration parameter.\\nThis module requires [Perl](https://www.perl.org/get.html) version 5.6.1 or higher. The C compiler should be compatible with the one used to build Perl.\\n"},{"m":"ngx_http_perl_module","n":"issues","d":"#### Known Issues\\nThe module is experimental, caveat emptor applies.\\nIn order for Perl to recompile the modified modules during reconfiguration, it should be built with the `-Dusemultiplicity=yes` or `-Dusethreads=yes` parameters. Also, to make Perl leak less memory at run time, it should be built with the `-Dusemymalloc=no` parameter. To check the values of these parameters in an already built Perl (preferred values are specified in the example), run:\\n```\\n$ perl -V:usemultiplicity -V:usemymalloc\\nusemultiplicity=\'define\';\\nusemymalloc=\'n\';\\n\\n```\\n\\nNote that after rebuilding Perl with the new `-Dusemultiplicity=yes` or `-Dusethreads=yes` parameters, all binary Perl modules will have to be rebuilt as well\xa0\u2014 they will just stop working with the new Perl.\\nThere is a possibility that the main process and then worker processes will grow in size after every reconfiguration. If the main process grows to an unacceptable size, the [live upgrade](../control.html#upgrade) procedure can be applied without changing the executable file.\\nWhile the Perl module is performing a long-running operation, such as resolving a domain name, connecting to another server, or querying a database, other requests assigned to the current worker process will not be processed. It is thus recommended to perform only such operations that have predictable and short execution time, such as accessing the local file system."},{"m":"ngx_http_perl_module","n":"perl","d":"Sets a Perl handler for the given location."},{"m":"ngx_http_perl_module","n":"perl_modules","d":"Sets an additional path for Perl modules."},{"m":"ngx_http_perl_module","n":"perl_require","d":"Defines the name of a module that will be loaded during each reconfiguration. Several `perl_require` directives can be present."},{"m":"ngx_http_perl_module","n":"perl_set","d":"Installs a Perl handler for the specified variable."},{"m":"ngx_http_perl_module","n":"ssi","d":"#### Calling Perl from SSI\\nAn SSI command calling Perl has the following format:\\n```\\n\x3c!--# perl sub=\\"module::function\\" arg=\\"parameter1\\" arg=\\"parameter2\\" ...\\n--\x3e\\n\\n```\\n"},{"m":"ngx_http_proxy_module","n":"summary","d":"The `ngx_http_proxy_module` module allows passing requests to another server."},{"m":"ngx_http_proxy_module","n":"proxy_bind","d":"Makes outgoing connections to a proxied server originate from the specified local IP address with an optional port (1.11.2). Parameter value can contain variables (1.3.12). The special value `off` (1.3.12) cancels the effect of the `proxy_bind` directive inherited from the previous configuration level, which allows the system to auto-assign the local IP address and port."},{"m":"ngx_http_proxy_module","n":"proxy_bind_transparent","d":"The `transparent` parameter (1.11.0) allows outgoing connections to a proxied server originate from a non-local IP address, for example, from a real IP address of a client:\\n```\\nproxy_bind $remote_addr transparent;\\n\\n```\\nIn order for this parameter to work, it is usually necessary to run nginx worker processes with the [superuser](../ngx_core_module.html#user) privileges. On Linux it is not required (1.13.8) as if the `transparent` parameter is specified, worker processes inherit the `CAP_NET_RAW` capability from the master process. It is also necessary to configure kernel routing table to intercept network traffic from the proxied server."},{"m":"ngx_http_proxy_module","n":"proxy_buffer_size","d":"Sets the `_size_` of the buffer used for reading the first part of the response received from the proxied server. This part usually contains a small response header. By default, the buffer size is equal to one memory page. This is either 4K or 8K, depending on a platform. It can be made smaller, however."},{"m":"ngx_http_proxy_module","n":"proxy_buffering","d":"Enables or disables buffering of responses from the proxied server.\\nWhen buffering is enabled, nginx receives a response from the proxied server as soon as possible, saving it into the buffers set by the [proxy\\\\_buffer\\\\_size](#proxy_buffer_size) and [proxy\\\\_buffers](#proxy_buffers) directives. If the whole response does not fit into memory, a part of it can be saved to a [temporary file](#proxy_temp_path) on the disk. Writing to temporary files is controlled by the [proxy\\\\_max\\\\_temp\\\\_file\\\\_size](#proxy_max_temp_file_size) and [proxy\\\\_temp\\\\_file\\\\_write\\\\_size](#proxy_temp_file_write_size) directives.\\nWhen buffering is disabled, the response is passed to a client synchronously, immediately as it is received. nginx will not try to read the whole response from the proxied server. The maximum size of the data that nginx can receive from the server at a time is set by the [proxy\\\\_buffer\\\\_size](#proxy_buffer_size) directive.\\nBuffering can also be enabled or disabled by passing \u201c`yes`\u201d or \u201c`no`\u201d in the \u201cX-Accel-Buffering\u201d response header field. This capability can be disabled using the [proxy\\\\_ignore\\\\_headers](#proxy_ignore_headers) directive."},{"m":"ngx_http_proxy_module","n":"proxy_buffers","d":"Sets the `_number_` and `_size_` of the buffers used for reading a response from the proxied server, for a single connection. By default, the buffer size is equal to one memory page. This is either 4K or 8K, depending on a platform."},{"m":"ngx_http_proxy_module","n":"proxy_busy_buffers_size","d":"When [buffering](#proxy_buffering) of responses from the proxied server is enabled, limits the total `_size_` of buffers that can be busy sending a response to the client while the response is not yet fully read. In the meantime, the rest of the buffers can be used for reading the response and, if needed, buffering part of the response to a temporary file. By default, `_size_` is limited by the size of two buffers set by the [proxy\\\\_buffer\\\\_size](#proxy_buffer_size) and [proxy\\\\_buffers](#proxy_buffers) directives."},{"m":"ngx_http_proxy_module","n":"proxy_cache","d":"Defines a shared memory zone used for caching. The same zone can be used in several places. Parameter value can contain variables (1.7.9). The `off` parameter disables caching inherited from the previous configuration level."},{"m":"ngx_http_proxy_module","n":"proxy_cache_background_update","d":"Allows starting a background subrequest to update an expired cache item, while a stale cached response is returned to the client. Note that it is necessary to [allow](#proxy_cache_use_stale_updating) the usage of a stale cached response when it is being updated."},{"m":"ngx_http_proxy_module","n":"proxy_cache_bypass","d":"Defines conditions under which the response will not be taken from a cache. If at least one value of the string parameters is not empty and is not equal to \u201c0\u201d then the response will not be taken from the cache:\\n```\\nproxy_cache_bypass $cookie_nocache $arg_nocache$arg_comment;\\nproxy_cache_bypass $http_pragma    $http_authorization;\\n\\n```\\nCan be used along with the [proxy\\\\_no\\\\_cache](#proxy_no_cache) directive."},{"m":"ngx_http_proxy_module","n":"proxy_cache_convert_head","d":"Enables or disables the conversion of the \u201c`HEAD`\u201d method to \u201c`GET`\u201d for caching. When the conversion is disabled, the [cache key](#proxy_cache_key) should be configured to include the `$request_method`."},{"m":"ngx_http_proxy_module","n":"proxy_cache_key","d":"Defines a key for caching, for example\\n```\\nproxy_cache_key \\"$host$request_uri $cookie_user\\";\\n\\n```\\nBy default, the directive\u2019s value is close to the string\\n```\\nproxy_cache_key $scheme$proxy_host$uri$is_args$args;\\n\\n```\\n"},{"m":"ngx_http_proxy_module","n":"proxy_cache_lock","d":"When enabled, only one request at a time will be allowed to populate a new cache element identified according to the [proxy\\\\_cache\\\\_key](#proxy_cache_key) directive by passing a request to a proxied server. Other requests of the same cache element will either wait for a response to appear in the cache or the cache lock for this element to be released, up to the time set by the [proxy\\\\_cache\\\\_lock\\\\_timeout](#proxy_cache_lock_timeout) directive."},{"m":"ngx_http_proxy_module","n":"proxy_cache_lock_age","d":"If the last request passed to the proxied server for populating a new cache element has not completed for the specified `_time_`, one more request may be passed to the proxied server."},{"m":"ngx_http_proxy_module","n":"proxy_cache_lock_timeout","d":"Sets a timeout for [proxy\\\\_cache\\\\_lock](#proxy_cache_lock). When the `_time_` expires, the request will be passed to the proxied server, however, the response will not be cached.\\nBefore 1.7.8, the response could be cached.\\n"},{"m":"ngx_http_proxy_module","n":"proxy_cache_max_range_offset","d":"Sets an offset in bytes for byte-range requests. If the range is beyond the offset, the range request will be passed to the proxied server and the response will not be cached."},{"m":"ngx_http_proxy_module","n":"proxy_cache_methods","d":"If the client request method is listed in this directive then the response will be cached. \u201c`GET`\u201d and \u201c`HEAD`\u201d methods are always added to the list, though it is recommended to specify them explicitly. See also the [proxy\\\\_no\\\\_cache](#proxy_no_cache) directive."},{"m":"ngx_http_proxy_module","n":"proxy_cache_min_uses","d":"Sets the `_number_` of requests after which the response will be cached."},{"m":"ngx_http_proxy_module","n":"proxy_cache_path","d":"Sets the path and other parameters of a cache. Cache data are stored in files. The file name in a cache is a result of applying the MD5 function to the [cache key](#proxy_cache_key). The `levels` parameter defines hierarchy levels of a cache: from 1 to 3, each level accepts values 1 or 2. For example, in the following configuration\\n```\\nproxy_cache_path /data/nginx/cache levels=1:2 keys_zone=one:10m;\\n\\n```\\nfile names in a cache will look like this:\\n```\\n/data/nginx/cache/c/29/b7f54b2df7773722d382f4809d65029c\\n\\n```\\n\\nA cached response is first written to a temporary file, and then the file is renamed. Starting from version 0.8.9, temporary files and the cache can be put on different file systems. However, be aware that in this case a file is copied across two file systems instead of the cheap renaming operation. It is thus recommended that for any given location both cache and a directory holding temporary files are put on the same file system. The directory for temporary files is set based on the `use_temp_path` parameter (1.7.10). If this parameter is omitted or set to the value `on`, the directory set by the [proxy\\\\_temp\\\\_path](#proxy_temp_path) directive for the given location will be used. If the value is set to `off`, temporary files will be put directly in the cache directory.\\nIn addition, all active keys and information about data are stored in a shared memory zone, whose `_name_` and `_size_` are configured by the `keys_zone` parameter. One megabyte zone can store about 8 thousand keys.\\nAs part of [commercial subscription](http://nginx.com/products/), the shared memory zone also stores extended cache [information](ngx_http_api_module.html#http_caches_), thus, it is required to specify a larger zone size for the same number of keys. For example, one megabyte zone can store about 4 thousand keys.\\n\\nCached data that are not accessed during the time specified by the `inactive` parameter get removed from the cache regardless of their freshness. By default, `inactive` is set to 10 minutes."},{"m":"ngx_http_proxy_module","n":"proxy_cache_path_max_size","d":"The special \u201ccache manager\u201d process monitors the maximum cache size set by the `max_size` parameter, and the minimum amount of free space set by the `min_free` (1.19.1) parameter on the file system with cache. When the size is exceeded or there is not enough free space, it removes the least recently used data. The data is removed in iterations configured by `manager_files`, `manager_threshold`, and `manager_sleep` parameters (1.11.5). During one iteration no more than `manager_files` items are deleted (by default, 100). The duration of one iteration is limited by the `manager_threshold` parameter (by default, 200 milliseconds). Between iterations, a pause configured by the `manager_sleep` parameter (by default, 50 milliseconds) is made.\\nA minute after the start the special \u201ccache loader\u201d process is activated. It loads information about previously cached data stored on file system into a cache zone. The loading is also done in iterations. During one iteration no more than `loader_files` items are loaded (by default, 100). Besides, the duration of one iteration is limited by the `loader_threshold` parameter (by default, 200 milliseconds). Between iterations, a pause configured by the `loader_sleep` parameter (by default, 50 milliseconds) is made.\\nAdditionally, the following parameters are available as part of our [commercial subscription](http://nginx.com/products/):\\n\\n`purger`\\\\=`on`|`off`\\n\\nInstructs whether cache entries that match a [wildcard key](#proxy_cache_purge) will be removed from the disk by the cache purger (1.7.12). Setting the parameter to `on` (default is `off`) will activate the \u201ccache purger\u201d process that permanently iterates through all cache entries and deletes the entries that match the wildcard key.\\n\\n`purger_files`\\\\=`_number_`\\n\\nSets the number of items that will be scanned during one iteration (1.7.12). By default, `purger_files` is set to 10.\\n\\n`purger_threshold`\\\\=`_number_`\\n\\nSets the duration of one iteration (1.7.12). By default, `purger_threshold` is set to 50 milliseconds.\\n\\n`purger_sleep`\\\\=`_number_`\\n\\nSets a pause between iterations (1.7.12). By default, `purger_sleep` is set to 50 milliseconds.\\n\\n\\nIn versions 1.7.3, 1.7.7, and 1.11.10 cache header format has been changed. Previously cached responses will be considered invalid after upgrading to a newer nginx version.\\n"},{"m":"ngx_http_proxy_module","n":"proxy_cache_purge","d":"Defines conditions under which the request will be considered a cache purge request. If at least one value of the string parameters is not empty and is not equal to \u201c0\u201d then the cache entry with a corresponding [cache key](#proxy_cache_key) is removed. The result of successful operation is indicated by returning the 204 (No Content) response.\\nIf the [cache key](#proxy_cache_key) of a purge request ends with an asterisk (\u201c`*`\u201d), all cache entries matching the wildcard key will be removed from the cache. However, these entries will remain on the disk until they are deleted for either [inactivity](#proxy_cache_path), or processed by the [cache purger](#purger) (1.7.12), or a client attempts to access them.\\nExample configuration:\\n```\\nproxy_cache_path /data/nginx/cache keys_zone=cache_zone:10m;\\n\\nmap $request_method $purge_method {\\n    PURGE   1;\\n    default 0;\\n}\\n\\nserver {\\n    ...\\n    location / {\\n        proxy_pass http://backend;\\n        proxy_cache cache_zone;\\n        proxy_cache_key $uri;\\n        proxy_cache_purge $purge_method;\\n    }\\n}\\n\\n```\\n\\nThis functionality is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_proxy_module","n":"proxy_cache_revalidate","d":"Enables revalidation of expired cache items using conditional requests with the \u201cIf-Modified-Since\u201d and \u201cIf-None-Match\u201d header fields."},{"m":"ngx_http_proxy_module","n":"proxy_cache_use_stale","d":"Determines in which cases a stale cached response can be used during communication with the proxied server. The directive\u2019s parameters match the parameters of the [proxy\\\\_next\\\\_upstream](#proxy_next_upstream) directive.\\nThe `error` parameter also permits using a stale cached response if a proxied server to process a request cannot be selected."},{"m":"ngx_http_proxy_module","n":"proxy_cache_use_stale_updating","d":"Additionally, the `updating` parameter permits using a stale cached response if it is currently being updated. This allows minimizing the number of accesses to proxied servers when updating cached data.\\nUsing a stale cached response can also be enabled directly in the response header for a specified number of seconds after the response became stale (1.11.10). This has lower priority than using the directive parameters.\\n*   The \u201c[stale-while-revalidate](https://tools.ietf.org/html/rfc5861#section-3)\u201d extension of the \u201cCache-Control\u201d header field permits using a stale cached response if it is currently being updated.\\n*   The \u201c[stale-if-error](https://tools.ietf.org/html/rfc5861#section-4)\u201d extension of the \u201cCache-Control\u201d header field permits using a stale cached response in case of an error.\\n\\nTo minimize the number of accesses to proxied servers when populating a new cache element, the [proxy\\\\_cache\\\\_lock](#proxy_cache_lock) directive can be used."},{"m":"ngx_http_proxy_module","n":"proxy_cache_valid","d":"Sets caching time for different response codes. For example, the following directives\\n```\\nproxy_cache_valid 200 302 10m;\\nproxy_cache_valid 404      1m;\\n\\n```\\nset 10 minutes of caching for responses with codes 200 and 302 and 1 minute for responses with code 404.\\nIf only caching `_time_` is specified\\n```\\nproxy_cache_valid 5m;\\n\\n```\\nthen only 200, 301, and 302 responses are cached.\\nIn addition, the `any` parameter can be specified to cache any responses:\\n```\\nproxy_cache_valid 200 302 10m;\\nproxy_cache_valid 301      1h;\\nproxy_cache_valid any      1m;\\n\\n```\\n\\nParameters of caching can also be set directly in the response header. This has higher priority than setting of caching time using the directive.\\n*   The \u201cX-Accel-Expires\u201d header field sets caching time of a response in seconds. The zero value disables caching for a response. If the value starts with the `@` prefix, it sets an absolute time in seconds since Epoch, up to which the response may be cached.\\n*   If the header does not include the \u201cX-Accel-Expires\u201d field, parameters of caching may be set in the header fields \u201cExpires\u201d or \u201cCache-Control\u201d.\\n*   If the header includes the \u201cSet-Cookie\u201d field, such a response will not be cached.\\n*   If the header includes the \u201cVary\u201d field with the special value \u201c`*`\u201d, such a response will not be cached (1.7.7). If the header includes the \u201cVary\u201d field with another value, such a response will be cached taking into account the corresponding request header fields (1.7.7).\\nProcessing of one or more of these response header fields can be disabled using the [proxy\\\\_ignore\\\\_headers](#proxy_ignore_headers) directive."},{"m":"ngx_http_proxy_module","n":"proxy_connect_timeout","d":"Defines a timeout for establishing a connection with a proxied server. It should be noted that this timeout cannot usually exceed 75 seconds."},{"m":"ngx_http_proxy_module","n":"proxy_cookie_domain","d":"Sets a text that should be changed in the `domain` attribute of the \u201cSet-Cookie\u201d header fields of a proxied server response. Suppose a proxied server returned the \u201cSet-Cookie\u201d header field with the attribute \u201c`domain=localhost`\u201d. The directive\\n```\\nproxy_cookie_domain localhost example.org;\\n\\n```\\nwill rewrite this attribute to \u201c`domain=example.org`\u201d.\\nA dot at the beginning of the `_domain_` and `_replacement_` strings and the `domain` attribute is ignored. Matching is case-insensitive.\\nThe `_domain_` and `_replacement_` strings can contain variables:\\n```\\nproxy_cookie_domain www.$host $host;\\n\\n```\\n\\nThe directive can also be specified using regular expressions. In this case, `_domain_` should start from the \u201c`~`\u201d symbol. A regular expression can contain named and positional captures, and `_replacement_` can reference them:\\n```\\nproxy_cookie_domain ~\\\\.(?P<sl_domain>[-0-9a-z]+\\\\.[a-z]+)$ $sl_domain;\\n\\n```\\n\\nSeveral `proxy_cookie_domain` directives can be specified on the same level:\\n```\\nproxy_cookie_domain localhost example.org;\\nproxy_cookie_domain ~\\\\.([a-z]+\\\\.[a-z]+)$ $1;\\n\\n```\\nIf several directives can be applied to the cookie, the first matching directive will be chosen.\\nThe `off` parameter cancels the effect of the `proxy_cookie_domain` directives inherited from the previous configuration level."},{"m":"ngx_http_proxy_module","n":"proxy_cookie_flags","d":"Sets one or more flags for the cookie. The `_cookie_` can contain text, variables, and their combinations. The `secure`, `httponly`, `samesite=strict`, `samesite=lax`, `samesite=none` parameters add the corresponding flags. The `nosecure`, `nohttponly`, `nosamesite` parameters remove the corresponding flags.\\nThe cookie can also be specified using regular expressions. In this case, `_cookie_` should start from the \u201c`~`\u201d symbol.\\nSeveral `proxy_cookie_flags` directives can be specified on the same configuration level:\\n```\\nproxy_cookie_flags one httponly;\\nproxy_cookie_flags ~ nosecure samesite=strict;\\n\\n```\\nIf several directives can be applied to the cookie, the first matching directive will be chosen. In the example, the `httponly` flag is added to the cookie `one`, for all other cookies the `samesite=strict` flag is added and the `secure` flag is deleted.\\nThe `off` parameter cancels the effect of the `proxy_cookie_flags` directives inherited from the previous configuration level."},{"m":"ngx_http_proxy_module","n":"proxy_cookie_path","d":"Sets a text that should be changed in the `path` attribute of the \u201cSet-Cookie\u201d header fields of a proxied server response. Suppose a proxied server returned the \u201cSet-Cookie\u201d header field with the attribute \u201c`path=/two/some/uri/`\u201d. The directive\\n```\\nproxy_cookie_path /two/ /;\\n\\n```\\nwill rewrite this attribute to \u201c`path=/some/uri/`\u201d.\\nThe `_path_` and `_replacement_` strings can contain variables:\\n```\\nproxy_cookie_path $uri /some$uri;\\n\\n```\\n\\nThe directive can also be specified using regular expressions. In this case, `_path_` should either start from the \u201c`~`\u201d symbol for a case-sensitive matching, or from the \u201c`~*`\u201d symbols for case-insensitive matching. The regular expression can contain named and positional captures, and `_replacement_` can reference them:\\n```\\nproxy_cookie_path ~*^/user/([^/]+) /u/$1;\\n\\n```\\n\\nSeveral `proxy_cookie_path` directives can be specified on the same level:\\n```\\nproxy_cookie_path /one/ /;\\nproxy_cookie_path / /two/;\\n\\n```\\nIf several directives can be applied to the cookie, the first matching directive will be chosen.\\nThe `off` parameter cancels the effect of the `proxy_cookie_path` directives inherited from the previous configuration level."},{"m":"ngx_http_proxy_module","n":"proxy_force_ranges","d":"Enables byte-range support for both cached and uncached responses from the proxied server regardless of the \u201cAccept-Ranges\u201d field in these responses."},{"m":"ngx_http_proxy_module","n":"proxy_headers_hash_bucket_size","d":"Sets the bucket `_size_` for hash tables used by the [proxy\\\\_hide\\\\_header](#proxy_hide_header) and [proxy\\\\_set\\\\_header](#proxy_set_header) directives. The details of setting up hash tables are provided in a separate [document](../hash.html)."},{"m":"ngx_http_proxy_module","n":"proxy_headers_hash_max_size","d":"Sets the maximum `_size_` of hash tables used by the [proxy\\\\_hide\\\\_header](#proxy_hide_header) and [proxy\\\\_set\\\\_header](#proxy_set_header) directives. The details of setting up hash tables are provided in a separate [document](../hash.html)."},{"m":"ngx_http_proxy_module","n":"proxy_hide_header","d":"By default, nginx does not pass the header fields \u201cDate\u201d, \u201cServer\u201d, \u201cX-Pad\u201d, and \u201cX-Accel-...\u201d from the response of a proxied server to a client. The `proxy_hide_header` directive sets additional fields that will not be passed. If, on the contrary, the passing of fields needs to be permitted, the [proxy\\\\_pass\\\\_header](#proxy_pass_header) directive can be used."},{"m":"ngx_http_proxy_module","n":"proxy_http_version","d":"Sets the HTTP protocol version for proxying. By default, version 1.0 is used. Version 1.1 is recommended for use with [keepalive](ngx_http_upstream_module.html#keepalive) connections and [NTLM authentication](ngx_http_upstream_module.html#ntlm)."},{"m":"ngx_http_proxy_module","n":"proxy_ignore_client_abort","d":"Determines whether the connection with a proxied server should be closed when a client closes the connection without waiting for a response."},{"m":"ngx_http_proxy_module","n":"proxy_ignore_headers","d":"Disables processing of certain response header fields from the proxied server. The following fields can be ignored: \u201cX-Accel-Redirect\u201d, \u201cX-Accel-Expires\u201d, \u201cX-Accel-Limit-Rate\u201d (1.1.6), \u201cX-Accel-Buffering\u201d (1.1.6), \u201cX-Accel-Charset\u201d (1.1.6), \u201cExpires\u201d, \u201cCache-Control\u201d, \u201cSet-Cookie\u201d (0.8.44), and \u201cVary\u201d (1.7.7).\\nIf not disabled, processing of these header fields has the following effect:\\n*   \u201cX-Accel-Expires\u201d, \u201cExpires\u201d, \u201cCache-Control\u201d, \u201cSet-Cookie\u201d, and \u201cVary\u201d set the parameters of response [caching](#proxy_cache_valid);\\n*   \u201cX-Accel-Redirect\u201d performs an [internal redirect](ngx_http_core_module.html#internal) to the specified URI;\\n*   \u201cX-Accel-Limit-Rate\u201d sets the [rate limit](ngx_http_core_module.html#limit_rate) for transmission of a response to a client;\\n*   \u201cX-Accel-Buffering\u201d enables or disables [buffering](#proxy_buffering) of a response;\\n*   \u201cX-Accel-Charset\u201d sets the desired [charset](ngx_http_charset_module.html#charset) of a response.\\n"},{"m":"ngx_http_proxy_module","n":"proxy_intercept_errors","d":"Determines whether proxied responses with codes greater than or equal to 300 should be passed to a client or be intercepted and redirected to nginx for processing with the [error\\\\_page](ngx_http_core_module.html#error_page) directive."},{"m":"ngx_http_proxy_module","n":"proxy_limit_rate","d":"Limits the speed of reading the response from the proxied server. The `_rate_` is specified in bytes per second. The zero value disables rate limiting. The limit is set per a request, and so if nginx simultaneously opens two connections to the proxied server, the overall rate will be twice as much as the specified limit. The limitation works only if [buffering](#proxy_buffering) of responses from the proxied server is enabled."},{"m":"ngx_http_proxy_module","n":"proxy_max_temp_file_size","d":"When [buffering](#proxy_buffering) of responses from the proxied server is enabled, and the whole response does not fit into the buffers set by the [proxy\\\\_buffer\\\\_size](#proxy_buffer_size) and [proxy\\\\_buffers](#proxy_buffers) directives, a part of the response can be saved to a temporary file. This directive sets the maximum `_size_` of the temporary file. The size of data written to the temporary file at a time is set by the [proxy\\\\_temp\\\\_file\\\\_write\\\\_size](#proxy_temp_file_write_size) directive.\\nThe zero value disables buffering of responses to temporary files.\\n\\nThis restriction does not apply to responses that will be [cached](#proxy_cache) or [stored](#proxy_store) on disk.\\n"},{"m":"ngx_http_proxy_module","n":"proxy_method","d":"Specifies the HTTP `_method_` to use in requests forwarded to the proxied server instead of the method from the client request. Parameter value can contain variables (1.11.6)."},{"m":"ngx_http_proxy_module","n":"proxy_next_upstream","d":"Specifies in which cases a request should be passed to the next server:\\n`error`\\n\\nan error occurred while establishing a connection with the server, passing a request to it, or reading the response header;\\n\\n`timeout`\\n\\na timeout has occurred while establishing a connection with the server, passing a request to it, or reading the response header;\\n\\n`invalid_header`\\n\\na server returned an empty or invalid response;\\n\\n`http_500`\\n\\na server returned a response with the code 500;\\n\\n`http_502`\\n\\na server returned a response with the code 502;\\n\\n`http_503`\\n\\na server returned a response with the code 503;\\n\\n`http_504`\\n\\na server returned a response with the code 504;\\n\\n`http_403`\\n\\na server returned a response with the code 403;\\n\\n`http_404`\\n\\na server returned a response with the code 404;\\n\\n`http_429`\\n\\na server returned a response with the code 429 (1.11.13);\\n\\n`non_idempotent`\\n\\nnormally, requests with a [non-idempotent](https://tools.ietf.org/html/rfc7231#section-4.2.2) method (`POST`, `LOCK`, `PATCH`) are not passed to the next server if a request has been sent to an upstream server (1.9.13); enabling this option explicitly allows retrying such requests;\\n\\n`off`\\n\\ndisables passing a request to the next server.\\n\\nOne should bear in mind that passing a request to the next server is only possible if nothing has been sent to a client yet. That is, if an error or timeout occurs in the middle of the transferring of a response, fixing this is impossible.\\nThe directive also defines what is considered an [unsuccessful attempt](ngx_http_upstream_module.html#max_fails) of communication with a server. The cases of `error`, `timeout` and `invalid_header` are always considered unsuccessful attempts, even if they are not specified in the directive. The cases of `http_500`, `http_502`, `http_503`, `http_504`, and `http_429` are considered unsuccessful attempts only if they are specified in the directive. The cases of `http_403` and `http_404` are never considered unsuccessful attempts.\\nPassing a request to the next server can be limited by [the number of tries](#proxy_next_upstream_tries) and by [time](#proxy_next_upstream_timeout)."},{"m":"ngx_http_proxy_module","n":"proxy_next_upstream_timeout","d":"Limits the time during which a request can be passed to the [next server](#proxy_next_upstream). The `0` value turns off this limitation."},{"m":"ngx_http_proxy_module","n":"proxy_next_upstream_tries","d":"Limits the number of possible tries for passing a request to the [next server](#proxy_next_upstream). The `0` value turns off this limitation."},{"m":"ngx_http_proxy_module","n":"proxy_no_cache","d":"Defines conditions under which the response will not be saved to a cache. If at least one value of the string parameters is not empty and is not equal to \u201c0\u201d then the response will not be saved:\\n```\\nproxy_no_cache $cookie_nocache $arg_nocache$arg_comment;\\nproxy_no_cache $http_pragma    $http_authorization;\\n\\n```\\nCan be used along with the [proxy\\\\_cache\\\\_bypass](#proxy_cache_bypass) directive."},{"m":"ngx_http_proxy_module","n":"proxy_pass","d":"Sets the protocol and address of a proxied server and an optional URI to which a location should be mapped. As a protocol, \u201c`http`\u201d or \u201c`https`\u201d can be specified. The address can be specified as a domain name or IP address, and an optional port:\\n```\\nproxy_pass http://localhost:8000/uri/;\\n\\n```\\nor as a UNIX-domain socket path specified after the word \u201c`unix`\u201d and enclosed in colons:\\n```\\nproxy_pass http://unix:/tmp/backend.socket:/uri/;\\n\\n```\\n\\nIf a domain name resolves to several addresses, all of them will be used in a round-robin fashion. In addition, an address can be specified as a [server group](ngx_http_upstream_module.html).\\nParameter value can contain variables. In this case, if an address is specified as a domain name, the name is searched among the described server groups, and, if not found, is determined using a [resolver](ngx_http_core_module.html#resolver).\\nA request URI is passed to the server as follows:\\n*   If the `proxy_pass` directive is specified with a URI, then when a request is passed to the server, the part of a [normalized](ngx_http_core_module.html#location) request URI matching the location is replaced by a URI specified in the directive:\\n    \\n    > location /name/ {\\n    >     proxy\\\\_pass http://127.0.0.1/remote/;\\n    > }\\n    \\n*   If `proxy_pass` is specified without a URI, the request URI is passed to the server in the same form as sent by a client when the original request is processed, or the full normalized request URI is passed when processing the changed URI:\\n    \\n    > location /some/path/ {\\n    >     proxy\\\\_pass http://127.0.0.1;\\n    > }\\n    \\n    > Before version 1.1.12, if `proxy_pass` is specified without a URI, the original request URI might be passed instead of the changed URI in some cases.\\n\\nIn some cases, the part of a request URI to be replaced cannot be determined:\\n*   When location is specified using a regular expression, and also inside named locations.\\n    \\n    In these cases, `proxy_pass` should be specified without a URI.\\n    \\n*   When the URI is changed inside a proxied location using the [rewrite](ngx_http_rewrite_module.html#rewrite) directive, and this same configuration will be used to process a request (`break`):\\n    \\n    > location /name/ {\\n    >     rewrite    /name/(\\\\[^/\\\\]+) /users?name=$1 break;\\n    >     proxy\\\\_pass http://127.0.0.1;\\n    > }\\n    \\n    In this case, the URI specified in the directive is ignored and the full changed request URI is passed to the server.\\n    \\n*   When variables are used in `proxy_pass`:\\n    \\n    > location /name/ {\\n    >     proxy\\\\_pass http://127.0.0.1$request\\\\_uri;\\n    > }\\n    \\n    In this case, if URI is specified in the directive, it is passed to the server as is, replacing the original request URI.\\n\\n[WebSocket](websocket.html) proxying requires special configuration and is supported since version 1.3.13."},{"m":"ngx_http_proxy_module","n":"proxy_pass_header","d":"Permits passing [otherwise disabled](#proxy_hide_header) header fields from a proxied server to a client."},{"m":"ngx_http_proxy_module","n":"proxy_pass_request_body","d":"Indicates whether the original request body is passed to the proxied server.\\n```\\nlocation /x-accel-redirect-here/ {\\n    proxy_method GET;\\n    proxy_pass_request_body off;\\n    proxy_set_header Content-Length \\"\\";\\n\\n    proxy_pass ...\\n}\\n\\n```\\nSee also the [proxy\\\\_set\\\\_header](#proxy_set_header) and [proxy\\\\_pass\\\\_request\\\\_headers](#proxy_pass_request_headers) directives."},{"m":"ngx_http_proxy_module","n":"proxy_pass_request_headers","d":"Indicates whether the header fields of the original request are passed to the proxied server.\\n```\\nlocation /x-accel-redirect-here/ {\\n    proxy_method GET;\\n    proxy_pass_request_headers off;\\n    proxy_pass_request_body off;\\n\\n    proxy_pass ...\\n}\\n\\n```\\nSee also the [proxy\\\\_set\\\\_header](#proxy_set_header) and [proxy\\\\_pass\\\\_request\\\\_body](#proxy_pass_request_body) directives."},{"m":"ngx_http_proxy_module","n":"proxy_read_timeout","d":"Defines a timeout for reading a response from the proxied server. The timeout is set only between two successive read operations, not for the transmission of the whole response. If the proxied server does not transmit anything within this time, the connection is closed."},{"m":"ngx_http_proxy_module","n":"proxy_redirect","d":"Sets the text that should be changed in the \u201cLocation\u201d and \u201cRefresh\u201d header fields of a proxied server response. Suppose a proxied server returned the header field \u201c`Location: http://localhost:8000/two/some/uri/`\u201d. The directive\\n```\\nproxy_redirect http://localhost:8000/two/ http://frontend/one/;\\n\\n```\\nwill rewrite this string to \u201c`Location: http://frontend/one/some/uri/`\u201d.\\nA server name may be omitted in the `_replacement_` string:\\n```\\nproxy_redirect http://localhost:8000/two/ /;\\n\\n```\\nthen the primary server\u2019s name and port, if different from 80, will be inserted.\\nThe default replacement specified by the `default` parameter uses the parameters of the [location](ngx_http_core_module.html#location) and [proxy\\\\_pass](#proxy_pass) directives. Hence, the two configurations below are equivalent:\\n```\\nlocation /one/ {\\n    proxy_pass     http://upstream:port/two/;\\n    proxy_redirect default;\\n\\n```\\n\\n```\\nlocation /one/ {\\n    proxy_pass     http://upstream:port/two/;\\n    proxy_redirect http://upstream:port/two/ /one/;\\n\\n```\\nThe `default` parameter is not permitted if [proxy\\\\_pass](#proxy_pass) is specified using variables.\\nA `_replacement_` string can contain variables:\\n```\\nproxy_redirect http://localhost:8000/ http://$host:$server_port/;\\n\\n```\\n\\nA `_redirect_` can also contain (1.1.11) variables:\\n```\\nproxy_redirect http://$proxy_host:8000/ /;\\n\\n```\\n\\nThe directive can be specified (1.1.11) using regular expressions. In this case, `_redirect_` should either start with the \u201c`~`\u201d symbol for a case-sensitive matching, or with the \u201c`~*`\u201d symbols for case-insensitive matching. The regular expression can contain named and positional captures, and `_replacement_` can reference them:\\n```\\nproxy_redirect ~^(http://[^:]+):\\\\d+(/.+)$ $1$2;\\nproxy_redirect ~*/user/([^/]+)/(.+)$      http://$1.example.com/$2;\\n\\n```\\n\\nSeveral `proxy_redirect` directives can be specified on the same level:\\n```\\nproxy_redirect default;\\nproxy_redirect http://localhost:8000/  /;\\nproxy_redirect http://www.example.com/ /;\\n\\n```\\nIf several directives can be applied to the header fields of a proxied server response, the first matching directive will be chosen.\\nThe `off` parameter cancels the effect of the `proxy_redirect` directives inherited from the previous configuration level.\\nUsing this directive, it is also possible to add host names to relative redirects issued by a proxied server:\\n```\\nproxy_redirect / /;\\n\\n```\\n"},{"m":"ngx_http_proxy_module","n":"proxy_request_buffering","d":"Enables or disables buffering of a client request body.\\nWhen buffering is enabled, the entire request body is [read](ngx_http_core_module.html#client_body_buffer_size) from the client before sending the request to a proxied server.\\nWhen buffering is disabled, the request body is sent to the proxied server immediately as it is received. In this case, the request cannot be passed to the [next server](#proxy_next_upstream) if nginx already started sending the request body.\\nWhen HTTP/1.1 chunked transfer encoding is used to send the original request body, the request body will be buffered regardless of the directive value unless HTTP/1.1 is [enabled](#proxy_http_version) for proxying."},{"m":"ngx_http_proxy_module","n":"proxy_send_lowat","d":"If the directive is set to a non-zero value, nginx will try to minimize the number of send operations on outgoing connections to a proxied server by using either `NOTE_LOWAT` flag of the [kqueue](../events.html#kqueue) method, or the `SO_SNDLOWAT` socket option, with the specified `_size_`.\\nThis directive is ignored on Linux, Solaris, and Windows."},{"m":"ngx_http_proxy_module","n":"proxy_send_timeout","d":"Sets a timeout for transmitting a request to the proxied server. The timeout is set only between two successive write operations, not for the transmission of the whole request. If the proxied server does not receive anything within this time, the connection is closed."},{"m":"ngx_http_proxy_module","n":"proxy_set_body","d":"Allows redefining the request body passed to the proxied server. The `_value_` can contain text, variables, and their combination."},{"m":"ngx_http_proxy_module","n":"proxy_set_header","d":"Allows redefining or appending fields to the request header [passed](#proxy_pass_request_headers) to the proxied server. The `_value_` can contain text, variables, and their combinations. These directives are inherited from the previous configuration level if and only if there are no `proxy_set_header` directives defined on the current level. By default, only two fields are redefined:\\n```\\nproxy_set_header Host       $proxy_host;\\nproxy_set_header Connection close;\\n\\n```\\nIf caching is enabled, the header fields \u201cIf-Modified-Since\u201d, \u201cIf-Unmodified-Since\u201d, \u201cIf-None-Match\u201d, \u201cIf-Match\u201d, \u201cRange\u201d, and \u201cIf-Range\u201d from the original request are not passed to the proxied server.\\nAn unchanged \u201cHost\u201d request header field can be passed like this:\\n```\\nproxy_set_header Host       $http_host;\\n\\n```\\n\\nHowever, if this field is not present in a client request header then nothing will be passed. In such a case it is better to use the `$host` variable\xa0- its value equals the server name in the \u201cHost\u201d request header field or the primary server name if this field is not present:\\n```\\nproxy_set_header Host       $host;\\n\\n```\\n\\nIn addition, the server name can be passed together with the port of the proxied server:\\n```\\nproxy_set_header Host       $host:$proxy_port;\\n\\n```\\n\\nIf the value of a header field is an empty string then this field will not be passed to a proxied server:\\n```\\nproxy_set_header Accept-Encoding \\"\\";\\n\\n```\\n"},{"m":"ngx_http_proxy_module","n":"proxy_socket_keepalive","d":"Configures the \u201cTCP keepalive\u201d behavior for outgoing connections to a proxied server. By default, the operating system\u2019s settings are in effect for the socket. If the directive is set to the value \u201c`on`\u201d, the `SO_KEEPALIVE` socket option is turned on for the socket."},{"m":"ngx_http_proxy_module","n":"proxy_ssl_certificate","d":"Specifies a `_file_` with the certificate in the PEM format used for authentication to a proxied HTTPS server."},{"m":"ngx_http_proxy_module","n":"proxy_ssl_certificate_key","d":"Specifies a `_file_` with the secret key in the PEM format used for authentication to a proxied HTTPS server.\\nThe value `engine`:`_name_`:`_id_` can be specified instead of the `_file_` (1.7.9), which loads a secret key with a specified `_id_` from the OpenSSL engine `_name_`."},{"m":"ngx_http_proxy_module","n":"proxy_ssl_ciphers","d":"Specifies the enabled ciphers for requests to a proxied HTTPS server. The ciphers are specified in the format understood by the OpenSSL library.\\nThe full list can be viewed using the \u201c`openssl ciphers`\u201d command."},{"m":"ngx_http_proxy_module","n":"proxy_ssl_conf_command","d":"Sets arbitrary OpenSSL configuration [commands](https://www.openssl.org/docs/man1.1.1/man3/SSL_CONF_cmd.html) when establishing a connection with the proxied HTTPS server.\\nThe directive is supported when using OpenSSL 1.0.2 or higher.\\n\\nSeveral `proxy_ssl_conf_command` directives can be specified on the same level. These directives are inherited from the previous configuration level if and only if there are no `proxy_ssl_conf_command` directives defined on the current level.\\n\\nNote that configuring OpenSSL directly might result in unexpected behavior.\\n"},{"m":"ngx_http_proxy_module","n":"proxy_ssl_crl","d":"Specifies a `_file_` with revoked certificates (CRL) in the PEM format used to [verify](#proxy_ssl_verify) the certificate of the proxied HTTPS server."},{"m":"ngx_http_proxy_module","n":"proxy_ssl_name","d":"Allows overriding the server name used to [verify](#proxy_ssl_verify) the certificate of the proxied HTTPS server and to be [passed through SNI](#proxy_ssl_server_name) when establishing a connection with the proxied HTTPS server.\\nBy default, the host part of the [proxy\\\\_pass](#proxy_pass) URL is used."},{"m":"ngx_http_proxy_module","n":"proxy_ssl_password_file","d":"Specifies a `_file_` with passphrases for [secret keys](#proxy_ssl_certificate_key) where each passphrase is specified on a separate line. Passphrases are tried in turn when loading the key."},{"m":"ngx_http_proxy_module","n":"proxy_ssl_protocols","d":"Enables the specified protocols for requests to a proxied HTTPS server."},{"m":"ngx_http_proxy_module","n":"proxy_ssl_server_name","d":"Enables or disables passing of the server name through [TLS Server Name Indication extension](http://en.wikipedia.org/wiki/Server_Name_Indication) (SNI, RFC 6066) when establishing a connection with the proxied HTTPS server."},{"m":"ngx_http_proxy_module","n":"proxy_ssl_session_reuse","d":"Determines whether SSL sessions can be reused when working with the proxied server. If the errors \u201c`SSL3_GET_FINISHED:digest check failed`\u201d appear in the logs, try disabling session reuse."},{"m":"ngx_http_proxy_module","n":"proxy_ssl_trusted_certificate","d":"Specifies a `_file_` with trusted CA certificates in the PEM format used to [verify](#proxy_ssl_verify) the certificate of the proxied HTTPS server."},{"m":"ngx_http_proxy_module","n":"proxy_ssl_verify","d":"Enables or disables verification of the proxied HTTPS server certificate."},{"m":"ngx_http_proxy_module","n":"proxy_ssl_verify_depth","d":"Sets the verification depth in the proxied HTTPS server certificates chain."},{"m":"ngx_http_proxy_module","n":"proxy_store","d":"Enables saving of files to a disk. The `on` parameter saves files with paths corresponding to the directives [alias](ngx_http_core_module.html#alias) or [root](ngx_http_core_module.html#root). The `off` parameter disables saving of files. In addition, the file name can be set explicitly using the `_string_` with variables:\\n```\\nproxy_store /data/www$original_uri;\\n\\n```\\n\\nThe modification time of files is set according to the received \u201cLast-Modified\u201d response header field. The response is first written to a temporary file, and then the file is renamed. Starting from version 0.8.9, temporary files and the persistent store can be put on different file systems. However, be aware that in this case a file is copied across two file systems instead of the cheap renaming operation. It is thus recommended that for any given location both saved files and a directory holding temporary files, set by the [proxy\\\\_temp\\\\_path](#proxy_temp_path) directive, are put on the same file system.\\nThis directive can be used to create local copies of static unchangeable files, e.g.:\\n```\\nlocation /images/ {\\n    root               /data/www;\\n    error_page         404 = /fetch$uri;\\n}\\n\\nlocation /fetch/ {\\n    internal;\\n\\n    proxy_pass         http://backend/;\\n    proxy_store        on;\\n    proxy_store_access user:rw group:rw all:r;\\n    proxy_temp_path    /data/temp;\\n\\n    alias              /data/www/;\\n}\\n\\n```\\n\\nor like this:\\n```\\nlocation /images/ {\\n    root               /data/www;\\n    error_page         404 = @fetch;\\n}\\n\\nlocation @fetch {\\n    internal;\\n\\n    proxy_pass         http://backend;\\n    proxy_store        on;\\n    proxy_store_access user:rw group:rw all:r;\\n    proxy_temp_path    /data/temp;\\n\\n    root               /data/www;\\n}\\n\\n```\\n"},{"m":"ngx_http_proxy_module","n":"proxy_store_access","d":"Sets access permissions for newly created files and directories, e.g.:\\n```\\nproxy_store_access user:rw group:rw all:r;\\n\\n```\\n\\nIf any `group` or `all` access permissions are specified then `user` permissions may be omitted:\\n```\\nproxy_store_access group:rw all:r;\\n\\n```\\n"},{"m":"ngx_http_proxy_module","n":"proxy_temp_file_write_size","d":"Limits the `_size_` of data written to a temporary file at a time, when buffering of responses from the proxied server to temporary files is enabled. By default, `_size_` is limited by two buffers set by the [proxy\\\\_buffer\\\\_size](#proxy_buffer_size) and [proxy\\\\_buffers](#proxy_buffers) directives. The maximum size of a temporary file is set by the [proxy\\\\_max\\\\_temp\\\\_file\\\\_size](#proxy_max_temp_file_size) directive."},{"m":"ngx_http_proxy_module","n":"proxy_temp_path","d":"Defines a directory for storing temporary files with data received from proxied servers. Up to three-level subdirectory hierarchy can be used underneath the specified directory. For example, in the following configuration\\n```\\nproxy_temp_path /spool/nginx/proxy_temp 1 2;\\n\\n```\\na temporary file might look like this:\\n```\\n/spool/nginx/proxy_temp/7/45/00000123457\\n\\n```\\n\\nSee also the `use_temp_path` parameter of the [proxy\\\\_cache\\\\_path](#proxy_cache_path) directive."},{"m":"ngx_http_proxy_module","n":"$proxy_host","d":"the \u201cX-Forwarded-For\u201d client request header field with the `$remote_addr` variable appended to it, separated by a comma. If the \u201cX-Forwarded-For\u201d field is not present in the client request header, the `$proxy_add_x_forwarded_for` variable is equal to the `$remote_addr` variable."},{"m":"ngx_http_proxy_module","n":"$proxy_port","d":"the \u201cX-Forwarded-For\u201d client request header field with the `$remote_addr` variable appended to it, separated by a comma. If the \u201cX-Forwarded-For\u201d field is not present in the client request header, the `$proxy_add_x_forwarded_for` variable is equal to the `$remote_addr` variable."},{"m":"ngx_http_proxy_module","n":"\\n$proxy_add_x_forwarded_for","d":"the \u201cX-Forwarded-For\u201d client request header field with the `$remote_addr` variable appended to it, separated by a comma. If the \u201cX-Forwarded-For\u201d field is not present in the client request header, the `$proxy_add_x_forwarded_for` variable is equal to the `$remote_addr` variable."},{"m":"ngx_http_random_index_module","n":"summary","d":"The `ngx_http_random_index_module` module processes requests ending with the slash character (\u2018`/`\u2019) and picks a random file in a directory to serve as an index file. The module is processed before the [ngx\\\\_http\\\\_index\\\\_module](ngx_http_index_module.html) module.\\nThis module is not built by default, it should be enabled with the `--with-http_random_index_module` configuration parameter."},{"m":"ngx_http_realip_module","n":"summary","d":"The `ngx_http_realip_module` module is used to change the client address and optional port to those sent in the specified header field.\\nThis module is not built by default, it should be enabled with the `--with-http_realip_module` configuration parameter."},{"m":"ngx_http_realip_module","n":"set_real_ip_from","d":"Defines trusted addresses that are known to send correct replacement addresses. If the special value `unix:` is specified, all UNIX-domain sockets will be trusted. Trusted addresses may also be specified using a hostname (1.13.1).\\nIPv6 addresses are supported starting from versions 1.3.0 and 1.2.1.\\n"},{"m":"ngx_http_realip_module","n":"real_ip_header","d":"Defines the request header field whose value will be used to replace the client address.\\nThe request header field value that contains an optional port is also used to replace the client port (1.11.0). The address and port should be specified according to [RFC 3986](https://tools.ietf.org/html/rfc3986).\\nThe `proxy_protocol` parameter (1.5.12) changes the client address to the one from the PROXY protocol header. The PROXY protocol must be previously enabled by setting the `proxy_protocol` parameter in the [listen](ngx_http_core_module.html#listen) directive."},{"m":"ngx_http_realip_module","n":"real_ip_recursive","d":"If recursive search is disabled, the original client address that matches one of the trusted addresses is replaced by the last address sent in the request header field defined by the [real\\\\_ip\\\\_header](#real_ip_header) directive. If recursive search is enabled, the original client address that matches one of the trusted addresses is replaced by the last non-trusted address sent in the request header field."},{"m":"ngx_http_realip_module","n":"$realip_remote_addr","d":"keeps the original client port (1.11.0)"},{"m":"ngx_http_realip_module","n":"$realip_remote_port","d":"keeps the original client port (1.11.0)"},{"m":"ngx_http_referer_module","n":"summary","d":"The `ngx_http_referer_module` module is used to block access to a site for requests with invalid values in the \u201cReferer\u201d header field. It should be kept in mind that fabricating a request with an appropriate \u201cReferer\u201d field value is quite easy, and so the intended purpose of this module is not to block such requests thoroughly but to block the mass flow of requests sent by regular browsers. It should also be taken into consideration that regular browsers may not send the \u201cReferer\u201d field even for valid requests."},{"m":"ngx_http_referer_module","n":"referer_hash_bucket_size","d":"Sets the bucket size for the valid referers hash tables. The details of setting up hash tables are provided in a separate [document](../hash.html)."},{"m":"ngx_http_referer_module","n":"referer_hash_max_size","d":"Sets the maximum `_size_` of the valid referers hash tables. The details of setting up hash tables are provided in a separate [document](../hash.html)."},{"m":"ngx_http_referer_module","n":"valid_referers","d":"Specifies the \u201cReferer\u201d request header field values that will cause the embedded `$invalid_referer` variable to be set to an empty string. Otherwise, the variable will be set to \u201c`1`\u201d. Search for a match is case-insensitive.\\nParameters can be as follows:\\n`none`\\n\\nthe \u201cReferer\u201d field is missing in the request header;\\n\\n`blocked`\\n\\nthe \u201cReferer\u201d field is present in the request header, but its value has been deleted by a firewall or proxy server; such values are strings that do not start with \u201c`http://`\u201d or \u201c`https://`\u201d;\\n\\n`server_names`\\n\\nthe \u201cReferer\u201d request header field contains one of the server names;\\n\\narbitrary string\\n\\ndefines a server name and an optional URI prefix. A server name can have an \u201c`*`\u201d at the beginning or end. During the checking, the server\u2019s port in the \u201cReferer\u201d field is ignored;\\n\\nregular expression\\n\\nthe first symbol should be a \u201c`~`\u201d. It should be noted that an expression will be matched against the text starting after the \u201c`http://`\u201d or \u201c`https://`\u201d.\\n\\nExample:\\n```\\nvalid_referers none blocked server_names\\n               *.example.com example.* www.example.org/galleries/\\n               ~\\\\.google\\\\.;\\n\\n```\\n"},{"m":"ngx_http_referer_module","n":"$invalid_referer","d":"Empty string, if the \u201cReferer\u201d request header field value is considered [valid](#valid_referers), otherwise \u201c`1`\u201d."},{"m":"ngx_http_rewrite_module","n":"summary","d":"The `ngx_http_rewrite_module` module is used to change request URI using PCRE regular expressions, return redirects, and conditionally select configurations.\\nThe [break](#break), [if](#if), [return](#return), [rewrite](#rewrite), and [set](#set) directives are processed in the following order:\\n*   the directives of this module specified on the [server](ngx_http_core_module.html#server) level are executed sequentially;\\n*   repeatedly:\\n    *   a [location](ngx_http_core_module.html#location) is searched based on a request URI;\\n    *   the directives of this module specified inside the found location are executed sequentially;\\n    *   the loop is repeated if a request URI was [rewritten](#rewrite), but not more than [10 times](ngx_http_core_module.html#internal).\\n"},{"m":"ngx_http_rewrite_module","n":"break","d":"Stops processing the current set of `ngx_http_rewrite_module` directives.\\nIf a directive is specified inside the [location](ngx_http_core_module.html#location), further processing of the request continues in this location.\\nExample:\\n```\\nif ($slow) {\\n    limit_rate 10k;\\n    break;\\n}\\n\\n```\\n"},{"m":"ngx_http_rewrite_module","n":"if","d":"The specified `_condition_` is evaluated. If true, this module directives specified inside the braces are executed, and the request is assigned the configuration inside the `if` directive. Configurations inside the `if` directives are inherited from the previous configuration level.\\nA condition may be any of the following:\\n*   a variable name; false if the value of a variable is an empty string or \u201c`0`\u201d;\\n    \\n    > Before version 1.0.1, any string starting with \u201c`0`\u201d was considered a false value.\\n    \\n*   comparison of a variable with a string using the \u201c`=`\u201d and \u201c`!=`\u201d operators;\\n*   matching of a variable against a regular expression using the \u201c`~`\u201d (for case-sensitive matching) and \u201c`~*`\u201d (for case-insensitive matching) operators. Regular expressions can contain captures that are made available for later reuse in the `$1`..`$9` variables. Negative operators \u201c`!~`\u201d and \u201c`!~*`\u201d are also available. If a regular expression includes the \u201c`}`\u201d or \u201c`;`\u201d characters, the whole expressions should be enclosed in single or double quotes.\\n*   checking of a file existence with the \u201c`-f`\u201d and \u201c`!-f`\u201d operators;\\n*   checking of a directory existence with the \u201c`-d`\u201d and \u201c`!-d`\u201d operators;\\n*   checking of a file, directory, or symbolic link existence with the \u201c`-e`\u201d and \u201c`!-e`\u201d operators;\\n*   checking for an executable file with the \u201c`-x`\u201d and \u201c`!-x`\u201d operators.\\n\\nExamples:\\n```\\nif ($http_user_agent ~ MSIE) {\\n    rewrite ^(.*)$ /msie/$1 break;\\n}\\n\\nif ($http_cookie ~* \\"id=([^;]+)(?:;|$)\\") {\\n    set $id $1;\\n}\\n\\nif ($request_method = POST) {\\n    return 405;\\n}\\n\\nif ($slow) {\\n    limit_rate 10k;\\n}\\n\\nif ($invalid_referer) {\\n    return 403;\\n}\\n\\n```\\n\\nA value of the `$invalid_referer` embedded variable is set by the [valid\\\\_referers](ngx_http_referer_module.html#valid_referers) directive.\\n"},{"m":"ngx_http_rewrite_module","n":"return","d":"Stops processing and returns the specified `_code_` to a client. The non-standard code 444 closes a connection without sending a response header.\\nStarting from version 0.8.42, it is possible to specify either a redirect URL (for codes 301, 302, 303, 307, and 308) or the response body `_text_` (for other codes). A response body text and redirect URL can contain variables. As a special case, a redirect URL can be specified as a URI local to this server, in which case the full redirect URL is formed according to the request scheme (`$scheme`) and the [server\\\\_name\\\\_in\\\\_redirect](ngx_http_core_module.html#server_name_in_redirect) and [port\\\\_in\\\\_redirect](ngx_http_core_module.html#port_in_redirect) directives.\\nIn addition, a `_URL_` for temporary redirect with the code 302 can be specified as the sole parameter. Such a parameter should start with the \u201c`http://`\u201d, \u201c`https://`\u201d, or \u201c`$scheme`\u201d string. A `_URL_` can contain variables.\\n\\nOnly the following codes could be returned before version 0.7.51: 204, 400, 402\xa0\u2014 406, 408, 410, 411, 413, 416, and 500\xa0\u2014 504.\\n\\nThe code 307 was not treated as a redirect until versions 1.1.16 and 1.0.13.\\n\\nThe code 308 was not treated as a redirect until version 1.13.0.\\n\\nSee also the [error\\\\_page](ngx_http_core_module.html#error_page) directive."},{"m":"ngx_http_rewrite_module","n":"rewrite","d":"If the specified regular expression matches a request URI, URI is changed as specified in the `_replacement_` string. The `rewrite` directives are executed sequentially in order of their appearance in the configuration file. It is possible to terminate further processing of the directives using flags. If a replacement string starts with \u201c`http://`\u201d, \u201c`https://`\u201d, or \u201c`$scheme`\u201d, the processing stops and the redirect is returned to a client.\\nAn optional `_flag_` parameter can be one of:\\n`last`\\n\\nstops processing the current set of `ngx_http_rewrite_module` directives and starts a search for a new location matching the changed URI;\\n\\n`break`\\n\\nstops processing the current set of `ngx_http_rewrite_module` directives as with the [break](#break) directive;\\n\\n`redirect`\\n\\nreturns a temporary redirect with the 302 code; used if a replacement string does not start with \u201c`http://`\u201d, \u201c`https://`\u201d, or \u201c`$scheme`\u201d;\\n\\n`permanent`\\n\\nreturns a permanent redirect with the 301 code.\\nThe full redirect URL is formed according to the request scheme (`$scheme`) and the [server\\\\_name\\\\_in\\\\_redirect](ngx_http_core_module.html#server_name_in_redirect) and [port\\\\_in\\\\_redirect](ngx_http_core_module.html#port_in_redirect) directives.\\nExample:\\n```\\nserver {\\n    ...\\n    rewrite ^(/download/.*)/media/(.*)\\\\..*$ $1/mp3/$2.mp3 last;\\n    rewrite ^(/download/.*)/audio/(.*)\\\\..*$ $1/mp3/$2.ra  last;\\n    return  403;\\n    ...\\n}\\n\\n```\\n\\nBut if these directives are put inside the \u201c`/download/`\u201d location, the `last` flag should be replaced by `break`, or otherwise nginx will make 10 cycles and return the 500 error:\\n```\\nlocation /download/ {\\n    rewrite ^(/download/.*)/media/(.*)\\\\..*$ $1/mp3/$2.mp3 break;\\n    rewrite ^(/download/.*)/audio/(.*)\\\\..*$ $1/mp3/$2.ra  break;\\n    return  403;\\n}\\n\\n```\\n\\nIf a `_replacement_` string includes the new request arguments, the previous request arguments are appended after them. If this is undesired, putting a question mark at the end of a replacement string avoids having them appended, for example:\\n```\\nrewrite ^/users/(.*)$ /show?user=$1? last;\\n\\n```\\n\\nIf a regular expression includes the \u201c`}`\u201d or \u201c`;`\u201d characters, the whole expressions should be enclosed in single or double quotes."},{"m":"ngx_http_rewrite_module","n":"rewrite_log","d":"Enables or disables logging of `ngx_http_rewrite_module` module directives processing results into the [error\\\\_log](../ngx_core_module.html#error_log) at the `notice` level."},{"m":"ngx_http_rewrite_module","n":"set","d":"Sets a `_value_` for the specified `_variable_`. The `_value_` can contain text, variables, and their combination."},{"m":"ngx_http_rewrite_module","n":"uninitialized_variable_warn","d":"Controls whether warnings about uninitialized variables are logged."},{"m":"ngx_http_scgi_module","n":"summary","d":"The `ngx_http_scgi_module` module allows passing requests to an SCGI server."},{"m":"ngx_http_scgi_module","n":"scgi_bind","d":"Makes outgoing connections to an SCGI server originate from the specified local IP address with an optional port (1.11.2). Parameter value can contain variables (1.3.12). The special value `off` (1.3.12) cancels the effect of the `scgi_bind` directive inherited from the previous configuration level, which allows the system to auto-assign the local IP address and port."},{"m":"ngx_http_scgi_module","n":"scgi_bind_transparent","d":"The `transparent` parameter (1.11.0) allows outgoing connections to an SCGI server originate from a non-local IP address, for example, from a real IP address of a client:\\n```\\nscgi_bind $remote_addr transparent;\\n\\n```\\nIn order for this parameter to work, it is usually necessary to run nginx worker processes with the [superuser](../ngx_core_module.html#user) privileges. On Linux it is not required (1.13.8) as if the `transparent` parameter is specified, worker processes inherit the `CAP_NET_RAW` capability from the master process. It is also necessary to configure kernel routing table to intercept network traffic from the SCGI server."},{"m":"ngx_http_scgi_module","n":"scgi_buffer_size","d":"Sets the `_size_` of the buffer used for reading the first part of the response received from the SCGI server. This part usually contains a small response header. By default, the buffer size is equal to one memory page. This is either 4K or 8K, depending on a platform. It can be made smaller, however."},{"m":"ngx_http_scgi_module","n":"scgi_buffering","d":"Enables or disables buffering of responses from the SCGI server.\\nWhen buffering is enabled, nginx receives a response from the SCGI server as soon as possible, saving it into the buffers set by the [scgi\\\\_buffer\\\\_size](#scgi_buffer_size) and [scgi\\\\_buffers](#scgi_buffers) directives. If the whole response does not fit into memory, a part of it can be saved to a [temporary file](#scgi_temp_path) on the disk. Writing to temporary files is controlled by the [scgi\\\\_max\\\\_temp\\\\_file\\\\_size](#scgi_max_temp_file_size) and [scgi\\\\_temp\\\\_file\\\\_write\\\\_size](#scgi_temp_file_write_size) directives.\\nWhen buffering is disabled, the response is passed to a client synchronously, immediately as it is received. nginx will not try to read the whole response from the SCGI server. The maximum size of the data that nginx can receive from the server at a time is set by the [scgi\\\\_buffer\\\\_size](#scgi_buffer_size) directive.\\nBuffering can also be enabled or disabled by passing \u201c`yes`\u201d or \u201c`no`\u201d in the \u201cX-Accel-Buffering\u201d response header field. This capability can be disabled using the [scgi\\\\_ignore\\\\_headers](#scgi_ignore_headers) directive."},{"m":"ngx_http_scgi_module","n":"scgi_buffers","d":"Sets the `_number_` and `_size_` of the buffers used for reading a response from the SCGI server, for a single connection. By default, the buffer size is equal to one memory page. This is either 4K or 8K, depending on a platform."},{"m":"ngx_http_scgi_module","n":"scgi_busy_buffers_size","d":"When [buffering](#scgi_buffering) of responses from the SCGI server is enabled, limits the total `_size_` of buffers that can be busy sending a response to the client while the response is not yet fully read. In the meantime, the rest of the buffers can be used for reading the response and, if needed, buffering part of the response to a temporary file. By default, `_size_` is limited by the size of two buffers set by the [scgi\\\\_buffer\\\\_size](#scgi_buffer_size) and [scgi\\\\_buffers](#scgi_buffers) directives."},{"m":"ngx_http_scgi_module","n":"scgi_cache","d":"Defines a shared memory zone used for caching. The same zone can be used in several places. Parameter value can contain variables (1.7.9). The `off` parameter disables caching inherited from the previous configuration level."},{"m":"ngx_http_scgi_module","n":"scgi_cache_background_update","d":"Allows starting a background subrequest to update an expired cache item, while a stale cached response is returned to the client. Note that it is necessary to [allow](#scgi_cache_use_stale_updating) the usage of a stale cached response when it is being updated."},{"m":"ngx_http_scgi_module","n":"scgi_cache_bypass","d":"Defines conditions under which the response will not be taken from a cache. If at least one value of the string parameters is not empty and is not equal to \u201c0\u201d then the response will not be taken from the cache:\\n```\\nscgi_cache_bypass $cookie_nocache $arg_nocache$arg_comment;\\nscgi_cache_bypass $http_pragma    $http_authorization;\\n\\n```\\nCan be used along with the [scgi\\\\_no\\\\_cache](#scgi_no_cache) directive."},{"m":"ngx_http_scgi_module","n":"scgi_cache_key","d":"Defines a key for caching, for example\\n```\\nscgi_cache_key localhost:9000$request_uri;\\n\\n```\\n"},{"m":"ngx_http_scgi_module","n":"scgi_cache_lock","d":"When enabled, only one request at a time will be allowed to populate a new cache element identified according to the [scgi\\\\_cache\\\\_key](#scgi_cache_key) directive by passing a request to an SCGI server. Other requests of the same cache element will either wait for a response to appear in the cache or the cache lock for this element to be released, up to the time set by the [scgi\\\\_cache\\\\_lock\\\\_timeout](#scgi_cache_lock_timeout) directive."},{"m":"ngx_http_scgi_module","n":"scgi_cache_lock_age","d":"If the last request passed to the SCGI server for populating a new cache element has not completed for the specified `_time_`, one more request may be passed to the SCGI server."},{"m":"ngx_http_scgi_module","n":"scgi_cache_lock_timeout","d":"Sets a timeout for [scgi\\\\_cache\\\\_lock](#scgi_cache_lock). When the `_time_` expires, the request will be passed to the SCGI server, however, the response will not be cached.\\nBefore 1.7.8, the response could be cached.\\n"},{"m":"ngx_http_scgi_module","n":"scgi_cache_max_range_offset","d":"Sets an offset in bytes for byte-range requests. If the range is beyond the offset, the range request will be passed to the SCGI server and the response will not be cached."},{"m":"ngx_http_scgi_module","n":"scgi_cache_methods","d":"If the client request method is listed in this directive then the response will be cached. \u201c`GET`\u201d and \u201c`HEAD`\u201d methods are always added to the list, though it is recommended to specify them explicitly. See also the [scgi\\\\_no\\\\_cache](#scgi_no_cache) directive."},{"m":"ngx_http_scgi_module","n":"scgi_cache_min_uses","d":"Sets the `_number_` of requests after which the response will be cached."},{"m":"ngx_http_scgi_module","n":"scgi_cache_path","d":"Sets the path and other parameters of a cache. Cache data are stored in files. The file name in a cache is a result of applying the MD5 function to the [cache key](#scgi_cache_key). The `levels` parameter defines hierarchy levels of a cache: from 1 to 3, each level accepts values 1 or 2. For example, in the following configuration\\n```\\nscgi_cache_path /data/nginx/cache levels=1:2 keys_zone=one:10m;\\n\\n```\\nfile names in a cache will look like this:\\n```\\n/data/nginx/cache/c/29/b7f54b2df7773722d382f4809d65029c\\n\\n```\\n\\nA cached response is first written to a temporary file, and then the file is renamed. Starting from version 0.8.9, temporary files and the cache can be put on different file systems. However, be aware that in this case a file is copied across two file systems instead of the cheap renaming operation. It is thus recommended that for any given location both cache and a directory holding temporary files are put on the same file system. A directory for temporary files is set based on the `use_temp_path` parameter (1.7.10). If this parameter is omitted or set to the value `on`, the directory set by the [scgi\\\\_temp\\\\_path](#scgi_temp_path) directive for the given location will be used. If the value is set to `off`, temporary files will be put directly in the cache directory.\\nIn addition, all active keys and information about data are stored in a shared memory zone, whose `_name_` and `_size_` are configured by the `keys_zone` parameter. One megabyte zone can store about 8 thousand keys.\\nAs part of [commercial subscription](http://nginx.com/products/), the shared memory zone also stores extended cache [information](ngx_http_api_module.html#http_caches_), thus, it is required to specify a larger zone size for the same number of keys. For example, one megabyte zone can store about 4 thousand keys.\\n\\nCached data that are not accessed during the time specified by the `inactive` parameter get removed from the cache regardless of their freshness. By default, `inactive` is set to 10 minutes."},{"m":"ngx_http_scgi_module","n":"scgi_cache_path_max_size","d":"The special \u201ccache manager\u201d process monitors the maximum cache size set by the `max_size` parameter, and the minimum amount of free space set by the `min_free` (1.19.1) parameter on the file system with cache. When the size is exceeded or there is not enough free space, it removes the least recently used data. The data is removed in iterations configured by `manager_files`, `manager_threshold`, and `manager_sleep` parameters (1.11.5). During one iteration no more than `manager_files` items are deleted (by default, 100). The duration of one iteration is limited by the `manager_threshold` parameter (by default, 200 milliseconds). Between iterations, a pause configured by the `manager_sleep` parameter (by default, 50 milliseconds) is made.\\nA minute after the start the special \u201ccache loader\u201d process is activated. It loads information about previously cached data stored on file system into a cache zone. The loading is also done in iterations. During one iteration no more than `loader_files` items are loaded (by default, 100). Besides, the duration of one iteration is limited by the `loader_threshold` parameter (by default, 200 milliseconds). Between iterations, a pause configured by the `loader_sleep` parameter (by default, 50 milliseconds) is made.\\nAdditionally, the following parameters are available as part of our [commercial subscription](http://nginx.com/products/):\\n\\n`purger`\\\\=`on`|`off`\\n\\nInstructs whether cache entries that match a [wildcard key](#scgi_cache_purge) will be removed from the disk by the cache purger (1.7.12). Setting the parameter to `on` (default is `off`) will activate the \u201ccache purger\u201d process that permanently iterates through all cache entries and deletes the entries that match the wildcard key.\\n\\n`purger_files`\\\\=`_number_`\\n\\nSets the number of items that will be scanned during one iteration (1.7.12). By default, `purger_files` is set to 10.\\n\\n`purger_threshold`\\\\=`_number_`\\n\\nSets the duration of one iteration (1.7.12). By default, `purger_threshold` is set to 50 milliseconds.\\n\\n`purger_sleep`\\\\=`_number_`\\n\\nSets a pause between iterations (1.7.12). By default, `purger_sleep` is set to 50 milliseconds.\\n\\n\\nIn versions 1.7.3, 1.7.7, and 1.11.10 cache header format has been changed. Previously cached responses will be considered invalid after upgrading to a newer nginx version.\\n"},{"m":"ngx_http_scgi_module","n":"scgi_cache_purge","d":"Defines conditions under which the request will be considered a cache purge request. If at least one value of the string parameters is not empty and is not equal to \u201c0\u201d then the cache entry with a corresponding [cache key](#scgi_cache_key) is removed. The result of successful operation is indicated by returning the 204 (No Content) response.\\nIf the [cache key](#scgi_cache_key) of a purge request ends with an asterisk (\u201c`*`\u201d), all cache entries matching the wildcard key will be removed from the cache. However, these entries will remain on the disk until they are deleted for either [inactivity](#scgi_cache_path), or processed by the [cache purger](#purger) (1.7.12), or a client attempts to access them.\\nExample configuration:\\n```\\nscgi_cache_path /data/nginx/cache keys_zone=cache_zone:10m;\\n\\nmap $request_method $purge_method {\\n    PURGE   1;\\n    default 0;\\n}\\n\\nserver {\\n    ...\\n    location / {\\n        scgi_pass        backend;\\n        scgi_cache       cache_zone;\\n        scgi_cache_key   $uri;\\n        scgi_cache_purge $purge_method;\\n    }\\n}\\n\\n```\\n\\nThis functionality is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_scgi_module","n":"scgi_cache_revalidate","d":"Enables revalidation of expired cache items using conditional requests with the \u201cIf-Modified-Since\u201d and \u201cIf-None-Match\u201d header fields."},{"m":"ngx_http_scgi_module","n":"scgi_cache_use_stale","d":"Determines in which cases a stale cached response can be used when an error occurs during communication with the SCGI server. The directive\u2019s parameters match the parameters of the [scgi\\\\_next\\\\_upstream](#scgi_next_upstream) directive.\\nThe `error` parameter also permits using a stale cached response if an SCGI server to process a request cannot be selected."},{"m":"ngx_http_scgi_module","n":"scgi_cache_use_stale_updating","d":"Additionally, the `updating` parameter permits using a stale cached response if it is currently being updated. This allows minimizing the number of accesses to SCGI servers when updating cached data.\\nUsing a stale cached response can also be enabled directly in the response header for a specified number of seconds after the response became stale (1.11.10). This has lower priority than using the directive parameters.\\n*   The \u201c[stale-while-revalidate](https://tools.ietf.org/html/rfc5861#section-3)\u201d extension of the \u201cCache-Control\u201d header field permits using a stale cached response if it is currently being updated.\\n*   The \u201c[stale-if-error](https://tools.ietf.org/html/rfc5861#section-4)\u201d extension of the \u201cCache-Control\u201d header field permits using a stale cached response in case of an error.\\n\\nTo minimize the number of accesses to SCGI servers when populating a new cache element, the [scgi\\\\_cache\\\\_lock](#scgi_cache_lock) directive can be used."},{"m":"ngx_http_scgi_module","n":"scgi_cache_valid","d":"Sets caching time for different response codes. For example, the following directives\\n```\\nscgi_cache_valid 200 302 10m;\\nscgi_cache_valid 404      1m;\\n\\n```\\nset 10 minutes of caching for responses with codes 200 and 302 and 1 minute for responses with code 404.\\nIf only caching `_time_` is specified\\n```\\nscgi_cache_valid 5m;\\n\\n```\\nthen only 200, 301, and 302 responses are cached.\\nIn addition, the `any` parameter can be specified to cache any responses:\\n```\\nscgi_cache_valid 200 302 10m;\\nscgi_cache_valid 301      1h;\\nscgi_cache_valid any      1m;\\n\\n```\\n\\nParameters of caching can also be set directly in the response header. This has higher priority than setting of caching time using the directive.\\n*   The \u201cX-Accel-Expires\u201d header field sets caching time of a response in seconds. The zero value disables caching for a response. If the value starts with the `@` prefix, it sets an absolute time in seconds since Epoch, up to which the response may be cached.\\n*   If the header does not include the \u201cX-Accel-Expires\u201d field, parameters of caching may be set in the header fields \u201cExpires\u201d or \u201cCache-Control\u201d.\\n*   If the header includes the \u201cSet-Cookie\u201d field, such a response will not be cached.\\n*   If the header includes the \u201cVary\u201d field with the special value \u201c`*`\u201d, such a response will not be cached (1.7.7). If the header includes the \u201cVary\u201d field with another value, such a response will be cached taking into account the corresponding request header fields (1.7.7).\\nProcessing of one or more of these response header fields can be disabled using the [scgi\\\\_ignore\\\\_headers](#scgi_ignore_headers) directive."},{"m":"ngx_http_scgi_module","n":"scgi_connect_timeout","d":"Defines a timeout for establishing a connection with an SCGI server. It should be noted that this timeout cannot usually exceed 75 seconds."},{"m":"ngx_http_scgi_module","n":"scgi_force_ranges","d":"Enables byte-range support for both cached and uncached responses from the SCGI server regardless of the \u201cAccept-Ranges\u201d field in these responses."},{"m":"ngx_http_scgi_module","n":"scgi_hide_header","d":"By default, nginx does not pass the header fields \u201cStatus\u201d and \u201cX-Accel-...\u201d from the response of an SCGI server to a client. The `scgi_hide_header` directive sets additional fields that will not be passed. If, on the contrary, the passing of fields needs to be permitted, the [scgi\\\\_pass\\\\_header](#scgi_pass_header) directive can be used."},{"m":"ngx_http_scgi_module","n":"scgi_ignore_client_abort","d":"Determines whether the connection with an SCGI server should be closed when a client closes the connection without waiting for a response."},{"m":"ngx_http_scgi_module","n":"scgi_ignore_headers","d":"Disables processing of certain response header fields from the SCGI server. The following fields can be ignored: \u201cX-Accel-Redirect\u201d, \u201cX-Accel-Expires\u201d, \u201cX-Accel-Limit-Rate\u201d (1.1.6), \u201cX-Accel-Buffering\u201d (1.1.6), \u201cX-Accel-Charset\u201d (1.1.6), \u201cExpires\u201d, \u201cCache-Control\u201d, \u201cSet-Cookie\u201d (0.8.44), and \u201cVary\u201d (1.7.7).\\nIf not disabled, processing of these header fields has the following effect:\\n*   \u201cX-Accel-Expires\u201d, \u201cExpires\u201d, \u201cCache-Control\u201d, \u201cSet-Cookie\u201d, and \u201cVary\u201d set the parameters of response [caching](#scgi_cache_valid);\\n*   \u201cX-Accel-Redirect\u201d performs an [internal redirect](ngx_http_core_module.html#internal) to the specified URI;\\n*   \u201cX-Accel-Limit-Rate\u201d sets the [rate limit](ngx_http_core_module.html#limit_rate) for transmission of a response to a client;\\n*   \u201cX-Accel-Buffering\u201d enables or disables [buffering](#scgi_buffering) of a response;\\n*   \u201cX-Accel-Charset\u201d sets the desired [charset](ngx_http_charset_module.html#charset) of a response.\\n"},{"m":"ngx_http_scgi_module","n":"scgi_intercept_errors","d":"Determines whether an SCGI server responses with codes greater than or equal to 300 should be passed to a client or be intercepted and redirected to nginx for processing with the [error\\\\_page](ngx_http_core_module.html#error_page) directive."},{"m":"ngx_http_scgi_module","n":"scgi_limit_rate","d":"Limits the speed of reading the response from the SCGI server. The `_rate_` is specified in bytes per second. The zero value disables rate limiting. The limit is set per a request, and so if nginx simultaneously opens two connections to the SCGI server, the overall rate will be twice as much as the specified limit. The limitation works only if [buffering](#scgi_buffering) of responses from the SCGI server is enabled."},{"m":"ngx_http_scgi_module","n":"scgi_max_temp_file_size","d":"When [buffering](#scgi_buffering) of responses from the SCGI server is enabled, and the whole response does not fit into the buffers set by the [scgi\\\\_buffer\\\\_size](#scgi_buffer_size) and [scgi\\\\_buffers](#scgi_buffers) directives, a part of the response can be saved to a temporary file. This directive sets the maximum `_size_` of the temporary file. The size of data written to the temporary file at a time is set by the [scgi\\\\_temp\\\\_file\\\\_write\\\\_size](#scgi_temp_file_write_size) directive.\\nThe zero value disables buffering of responses to temporary files.\\n\\nThis restriction does not apply to responses that will be [cached](#scgi_cache) or [stored](#scgi_store) on disk.\\n"},{"m":"ngx_http_scgi_module","n":"scgi_next_upstream","d":"Specifies in which cases a request should be passed to the next server:\\n`error`\\n\\nan error occurred while establishing a connection with the server, passing a request to it, or reading the response header;\\n\\n`timeout`\\n\\na timeout has occurred while establishing a connection with the server, passing a request to it, or reading the response header;\\n\\n`invalid_header`\\n\\na server returned an empty or invalid response;\\n\\n`http_500`\\n\\na server returned a response with the code 500;\\n\\n`http_503`\\n\\na server returned a response with the code 503;\\n\\n`http_403`\\n\\na server returned a response with the code 403;\\n\\n`http_404`\\n\\na server returned a response with the code 404;\\n\\n`http_429`\\n\\na server returned a response with the code 429 (1.11.13);\\n\\n`non_idempotent`\\n\\nnormally, requests with a [non-idempotent](https://tools.ietf.org/html/rfc7231#section-4.2.2) method (`POST`, `LOCK`, `PATCH`) are not passed to the next server if a request has been sent to an upstream server (1.9.13); enabling this option explicitly allows retrying such requests;\\n\\n`off`\\n\\ndisables passing a request to the next server.\\n\\nOne should bear in mind that passing a request to the next server is only possible if nothing has been sent to a client yet. That is, if an error or timeout occurs in the middle of the transferring of a response, fixing this is impossible.\\nThe directive also defines what is considered an [unsuccessful attempt](ngx_http_upstream_module.html#max_fails) of communication with a server. The cases of `error`, `timeout` and `invalid_header` are always considered unsuccessful attempts, even if they are not specified in the directive. The cases of `http_500`, `http_503`, and `http_429` are considered unsuccessful attempts only if they are specified in the directive. The cases of `http_403` and `http_404` are never considered unsuccessful attempts.\\nPassing a request to the next server can be limited by [the number of tries](#scgi_next_upstream_tries) and by [time](#scgi_next_upstream_timeout)."},{"m":"ngx_http_scgi_module","n":"scgi_next_upstream_timeout","d":"Limits the time during which a request can be passed to the [next server](#scgi_next_upstream). The `0` value turns off this limitation."},{"m":"ngx_http_scgi_module","n":"scgi_next_upstream_tries","d":"Limits the number of possible tries for passing a request to the [next server](#scgi_next_upstream). The `0` value turns off this limitation."},{"m":"ngx_http_scgi_module","n":"scgi_no_cache","d":"Defines conditions under which the response will not be saved to a cache. If at least one value of the string parameters is not empty and is not equal to \u201c0\u201d then the response will not be saved:\\n```\\nscgi_no_cache $cookie_nocache $arg_nocache$arg_comment;\\nscgi_no_cache $http_pragma    $http_authorization;\\n\\n```\\nCan be used along with the [scgi\\\\_cache\\\\_bypass](#scgi_cache_bypass) directive."},{"m":"ngx_http_scgi_module","n":"scgi_param","d":"Sets a `_parameter_` that should be passed to the SCGI server. The `_value_` can contain text, variables, and their combination. These directives are inherited from the previous configuration level if and only if there are no `scgi_param` directives defined on the current level.\\nStandard [CGI environment variables](https://tools.ietf.org/html/rfc3875#section-4.1) should be provided as SCGI headers, see the `scgi_params` file provided in the distribution:\\n```\\nlocation / {\\n    include scgi_params;\\n    ...\\n}\\n\\n```\\n\\nIf the directive is specified with `if_not_empty` (1.1.11) then such a parameter will be passed to the server only if its value is not empty:\\n```\\nscgi_param HTTPS $https if_not_empty;\\n\\n```\\n"},{"m":"ngx_http_scgi_module","n":"scgi_pass","d":"Sets the address of an SCGI server. The address can be specified as a domain name or IP address, and a port:\\n```\\nscgi_pass localhost:9000;\\n\\n```\\nor as a UNIX-domain socket path:\\n```\\nscgi_pass unix:/tmp/scgi.socket;\\n\\n```\\n\\nIf a domain name resolves to several addresses, all of them will be used in a round-robin fashion. In addition, an address can be specified as a [server group](ngx_http_upstream_module.html).\\nParameter value can contain variables. In this case, if an address is specified as a domain name, the name is searched among the described [server groups](ngx_http_upstream_module.html), and, if not found, is determined using a [resolver](ngx_http_core_module.html#resolver)."},{"m":"ngx_http_scgi_module","n":"scgi_pass_header","d":"Permits passing [otherwise disabled](#scgi_hide_header) header fields from an SCGI server to a client."},{"m":"ngx_http_scgi_module","n":"scgi_pass_request_body","d":"Indicates whether the original request body is passed to the SCGI server. See also the [scgi\\\\_pass\\\\_request\\\\_headers](#scgi_pass_request_headers) directive."},{"m":"ngx_http_scgi_module","n":"scgi_pass_request_headers","d":"Indicates whether the header fields of the original request are passed to the SCGI server. See also the [scgi\\\\_pass\\\\_request\\\\_body](#scgi_pass_request_body) directive."},{"m":"ngx_http_scgi_module","n":"scgi_read_timeout","d":"Defines a timeout for reading a response from the SCGI server. The timeout is set only between two successive read operations, not for the transmission of the whole response. If the SCGI server does not transmit anything within this time, the connection is closed."},{"m":"ngx_http_scgi_module","n":"scgi_request_buffering","d":"Enables or disables buffering of a client request body.\\nWhen buffering is enabled, the entire request body is [read](ngx_http_core_module.html#client_body_buffer_size) from the client before sending the request to an SCGI server.\\nWhen buffering is disabled, the request body is sent to the SCGI server immediately as it is received. In this case, the request cannot be passed to the [next server](#scgi_next_upstream) if nginx already started sending the request body.\\nWhen HTTP/1.1 chunked transfer encoding is used to send the original request body, the request body will be buffered regardless of the directive value."},{"m":"ngx_http_scgi_module","n":"scgi_send_timeout","d":"Sets a timeout for transmitting a request to the SCGI server. The timeout is set only between two successive write operations, not for the transmission of the whole request. If the SCGI server does not receive anything within this time, the connection is closed."},{"m":"ngx_http_scgi_module","n":"scgi_socket_keepalive","d":"Configures the \u201cTCP keepalive\u201d behavior for outgoing connections to an SCGI server. By default, the operating system\u2019s settings are in effect for the socket. If the directive is set to the value \u201c`on`\u201d, the `SO_KEEPALIVE` socket option is turned on for the socket."},{"m":"ngx_http_scgi_module","n":"scgi_store","d":"Enables saving of files to a disk. The `on` parameter saves files with paths corresponding to the directives [alias](ngx_http_core_module.html#alias) or [root](ngx_http_core_module.html#root). The `off` parameter disables saving of files. In addition, the file name can be set explicitly using the `_string_` with variables:\\n```\\nscgi_store /data/www$original_uri;\\n\\n```\\n\\nThe modification time of files is set according to the received \u201cLast-Modified\u201d response header field. The response is first written to a temporary file, and then the file is renamed. Starting from version 0.8.9, temporary files and the persistent store can be put on different file systems. However, be aware that in this case a file is copied across two file systems instead of the cheap renaming operation. It is thus recommended that for any given location both saved files and a directory holding temporary files, set by the [scgi\\\\_temp\\\\_path](#scgi_temp_path) directive, are put on the same file system.\\nThis directive can be used to create local copies of static unchangeable files, e.g.:\\n```\\nlocation /images/ {\\n    root              /data/www;\\n    error_page        404 = /fetch$uri;\\n}\\n\\nlocation /fetch/ {\\n    internal;\\n\\n    scgi_pass         backend:9000;\\n    ...\\n\\n    scgi_store        on;\\n    scgi_store_access user:rw group:rw all:r;\\n    scgi_temp_path    /data/temp;\\n\\n    alias             /data/www/;\\n}\\n\\n```\\n"},{"m":"ngx_http_scgi_module","n":"scgi_store_access","d":"Sets access permissions for newly created files and directories, e.g.:\\n```\\nscgi_store_access user:rw group:rw all:r;\\n\\n```\\n\\nIf any `group` or `all` access permissions are specified then `user` permissions may be omitted:\\n```\\nscgi_store_access group:rw all:r;\\n\\n```\\n"},{"m":"ngx_http_scgi_module","n":"scgi_temp_file_write_size","d":"Limits the `_size_` of data written to a temporary file at a time, when buffering of responses from the SCGI server to temporary files is enabled. By default, `_size_` is limited by two buffers set by the [scgi\\\\_buffer\\\\_size](#scgi_buffer_size) and [scgi\\\\_buffers](#scgi_buffers) directives. The maximum size of a temporary file is set by the [scgi\\\\_max\\\\_temp\\\\_file\\\\_size](#scgi_max_temp_file_size) directive."},{"m":"ngx_http_secure_link_module","n":"summary","d":"The `ngx_http_secure_link_module` module (0.7.18) is used to check authenticity of requested links, protect resources from unauthorized access, and limit link lifetime.\\nThe authenticity of a requested link is verified by comparing the checksum value passed in a request with the value computed for the request. If a link has a limited lifetime and the time has expired, the link is considered outdated. The status of these checks is made available in the `$secure_link` variable.\\nThe module provides two alternative operation modes. The first mode is enabled by the [secure\\\\_link\\\\_secret](#secure_link_secret) directive and is used to check authenticity of requested links as well as protect resources from unauthorized access. The second mode (0.8.50) is enabled by the [secure\\\\_link](#secure_link) and [secure\\\\_link\\\\_md5](#secure_link_md5) directives and is also used to limit lifetime of links.\\nThis module is not built by default, it should be enabled with the `--with-http_secure_link_module` configuration parameter."},{"m":"ngx_http_secure_link_module","n":"secure_link","d":"Defines a string with variables from which the checksum value and lifetime of a link will be extracted.\\nVariables used in an `_expression_` are usually associated with a request; see [example](#secure_link_md5) below.\\nThe checksum value extracted from the string is compared with the MD5 hash value of the expression defined by the [secure\\\\_link\\\\_md5](#secure_link_md5) directive. If the checksums are different, the `$secure_link` variable is set to an empty string. If the checksums are the same, the link lifetime is checked. If the link has a limited lifetime and the time has expired, the `$secure_link` variable is set to \u201c`0`\u201d. Otherwise, it is set to \u201c`1`\u201d. The MD5 hash value passed in a request is encoded in [base64url](https://tools.ietf.org/html/rfc4648#section-5).\\nIf a link has a limited lifetime, the expiration time is set in seconds since Epoch (Thu, 01 Jan 1970 00:00:00 GMT). The value is specified in the expression after the MD5 hash, and is separated by a comma. The expiration time passed in a request is available through the `$secure_link_expires` variable for a use in the [secure\\\\_link\\\\_md5](#secure_link_md5) directive. If the expiration time is not specified, a link has the unlimited lifetime."},{"m":"ngx_http_secure_link_module","n":"secure_link_md5","d":"Defines an expression for which the MD5 hash value will be computed and compared with the value passed in a request.\\nThe expression should contain the secured part of a link (resource) and a secret ingredient. If the link has a limited lifetime, the expression should also contain `$secure_link_expires`.\\nTo prevent unauthorized access, the expression may contain some information about the client, such as its address and browser version.\\nExample:\\n```\\nlocation /s/ {\\n    secure_link $arg_md5,$arg_expires;\\n    secure_link_md5 \\"$secure_link_expires$uri$remote_addr secret\\";\\n\\n    if ($secure_link = \\"\\") {\\n        return 403;\\n    }\\n\\n    if ($secure_link = \\"0\\") {\\n        return 410;\\n    }\\n\\n    ...\\n}\\n\\n```\\nThe \u201c`/s/link?md5=_e4Nc3iduzkWRm01TBBNYw&expires=2147483647`\u201d link restricts access to \u201c`/s/link`\u201d for the client with the IP address 127.0.0.1. The link also has the limited lifetime until January 19, 2038 (GMT).\\nOn UNIX, the `_md5_` request argument value can be obtained as:\\n```\\necho -n \'2147483647/s/link127.0.0.1 secret\' | \\\\\\n    openssl md5 -binary | openssl base64 | tr +/ -_ | tr -d =\\n\\n```\\n"},{"m":"ngx_http_secure_link_module","n":"secure_link_secret","d":"Defines a secret `_word_` used to check authenticity of requested links.\\nThe full URI of a requested link looks as follows:\\n```\\n/prefix/hash/link\\n\\n```\\nwhere `_hash_` is a hexadecimal representation of the MD5 hash computed for the concatenation of the link and secret word, and `_prefix_` is an arbitrary string without slashes.\\nIf the requested link passes the authenticity check, the `$secure_link` variable is set to the link extracted from the request URI. Otherwise, the `$secure_link` variable is set to an empty string.\\nExample:\\n```\\nlocation /p/ {\\n    secure_link_secret secret;\\n\\n    if ($secure_link = \\"\\") {\\n        return 403;\\n    }\\n\\n    rewrite ^ /secure/$secure_link;\\n}\\n\\nlocation /secure/ {\\n    internal;\\n}\\n\\n```\\nA request of \u201c`/p/5e814704a28d9bc1914ff19fa0c4a00a/link`\u201d will be internally redirected to \u201c`/secure/link`\u201d.\\nOn UNIX, the hash value for this example can be obtained as:\\n```\\necho -n \'linksecret\' | openssl md5 -hex\\n\\n```\\n"},{"m":"ngx_http_session_log_module","n":"summary","d":"The `ngx_http_session_log_module` module enables logging sessions (that is, aggregates of multiple HTTP requests) instead of individual HTTP requests.\\n\\nThis module is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_session_log_module","n":"session_log","d":"Enables the use of the specified session log. The special value `off` cancels the effect of the `session_log` directives inherited from the previous configuration level."},{"m":"ngx_http_session_log_module","n":"session_log_format","d":"Specifies the output format of a log. The value of the `$body_bytes_sent` variable is aggregated across all requests in a session. The values of all other variables available for logging correspond to the first request in a session."},{"m":"ngx_http_session_log_module","n":"session_log_zone","d":"Sets the path to a log file and configures the shared memory zone that is used to store currently active sessions.\\nA session is considered active for as long as the time elapsed since the last request in the session does not exceed the specified `timeout` (by default, 30 seconds). Once a session is no longer active, it is written to the log.\\nThe `id` parameter identifies the session to which a request is mapped. The `id` parameter is set to the hexadecimal representation of an MD5 hash (for example, obtained from a cookie using variables). If this parameter is not specified or does not represent the valid MD5 hash, nginx computes the MD5 hash from the value of the `md5` parameter and creates a new session using this hash. Both the `id` and `md5` parameters can contain variables.\\nThe `format` parameter sets the custom session log format configured by the [session\\\\_log\\\\_format](#session_log_format) directive. If `format` is not specified, the predefined \u201c`combined`\u201d format is used."},{"m":"ngx_http_session_log_module","n":"$session_log_id","d":"current session ID in binary form (16 bytes)."},{"m":"ngx_http_session_log_module","n":"$session_log_binary_id\\n","d":"current session ID in binary form (16 bytes)."},{"m":"ngx_http_slice_module","n":"summary","d":"The `ngx_http_slice_module` module (1.9.8) is a filter that splits a request into subrequests, each returning a certain range of response. The filter provides more effective caching of big responses.\\nThis module is not built by default, it should be enabled with the `--with-http_slice_module` configuration parameter."},{"m":"ngx_http_slice_module","n":"slice","d":"Sets the `_size_` of the slice. The zero value disables splitting responses into slices. Note that a too low value may result in excessive memory usage and opening a large number of files.\\nIn order for a subrequest to return the required range, the `$slice_range` variable should be [passed](ngx_http_proxy_module.html#proxy_set_header) to the proxied server as the `Range` request header field. If [caching](ngx_http_proxy_module.html#proxy_cache) is enabled, `$slice_range` should be added to the [cache key](ngx_http_proxy_module.html#proxy_cache_key) and caching of responses with 206 status code should be [enabled](ngx_http_proxy_module.html#proxy_cache_valid)."},{"m":"ngx_http_slice_module","n":"$slice_range","d":"the current slice range in [HTTP byte range](https://tools.ietf.org/html/rfc7233#section-2.1) format, for example, `bytes=0-1048575`."},{"m":"ngx_http_spdy_module","n":"summary","d":"The `ngx_http_spdy_module` module provides experimental support for [SPDY](http://www.chromium.org/spdy/spdy-protocol). Currently, [draft 3.1](http://www.chromium.org/spdy/spdy-protocol/spdy-protocol-draft3-1) of SPDY protocol is implemented.\\nBefore version 1.5.10, [draft 2](http://www.chromium.org/spdy/spdy-protocol/spdy-protocol-draft2) of SPDY protocol was implemented.\\n\\nThis module is not built by default, it should be enabled with the `--with-http_spdy_module` configuration parameter.\\n\\nThis module was superseded by the [ngx\\\\_http\\\\_v2\\\\_module](ngx_http_v2_module.html) module in 1.9.5.\\n"},{"m":"ngx_http_spdy_module","n":"issues","d":"#### Known Issues\\nThe module is experimental, caveat emptor applies.\\nCurrent implementation of SPDY protocol does not support \u201cserver push\u201d.\\nIn versions prior to 1.5.9, responses in SPDY connections could not be [rate limited](ngx_http_core_module.html#limit_rate).\\nBuffering of a client request body cannot be disabled regardless of [proxy\\\\_request\\\\_buffering](ngx_http_proxy_module.html#proxy_request_buffering), [fastcgi\\\\_request\\\\_buffering](ngx_http_fastcgi_module.html#fastcgi_request_buffering), [uwsgi\\\\_request\\\\_buffering](ngx_http_uwsgi_module.html#uwsgi_request_buffering), and [scgi\\\\_request\\\\_buffering](ngx_http_scgi_module.html#scgi_request_buffering) directive values."},{"m":"ngx_http_spdy_module","n":"spdy_chunk_size","d":"Sets the maximum size of chunks into which the response body is [sliced](http://www.chromium.org/spdy/spdy-protocol/spdy-protocol-draft2#TOC-Data-frames). A too low value results in higher overhead. A too high value impairs prioritization due to [HOL blocking](http://en.wikipedia.org/wiki/Head-of-line_blocking)."},{"m":"ngx_http_spdy_module","n":"spdy_headers_comp","d":"Sets the header compression `_level_` of a response in a range from 1 (fastest, less compression) to 9 (slowest, best compression). The special value 0 turns off the header compression."},{"m":"ngx_http_split_clients_module","n":"summary","d":"The `ngx_http_split_clients_module` module creates variables suitable for A/B testing, also known as split testing."},{"m":"ngx_http_ssi_module","n":"summary","d":"The `ngx_http_ssi_module` module is a filter that processes SSI (Server Side Includes) commands in responses passing through it. Currently, the list of supported SSI commands is incomplete."},{"m":"ngx_http_ssi_module","n":"ssi","d":"Enables or disables processing of SSI commands in responses."},{"m":"ngx_http_ssi_module","n":"ssi_last_modified","d":"Allows preserving the \u201cLast-Modified\u201d header field from the original response during SSI processing to facilitate response caching.\\nBy default, the header field is removed as contents of the response are modified during processing and may contain dynamically generated elements or parts that are changed independently of the original response."},{"m":"ngx_http_ssi_module","n":"ssi_min_file_chunk","d":"Sets the minimum `_size_` for parts of a response stored on disk, starting from which it makes sense to send them using [sendfile](ngx_http_core_module.html#sendfile)."},{"m":"ngx_http_ssi_module","n":"ssi_silent_errors","d":"If enabled, suppresses the output of the \u201c`[an error occurred while processing the directive]`\u201d string if an error occurred during SSI processing."},{"m":"ngx_http_ssi_module","n":"ssi_types","d":"Enables processing of SSI commands in responses with the specified MIME types in addition to \u201c`text/html`\u201d. The special value \u201c`*`\u201d matches any MIME type (0.8.29)."},{"m":"ngx_http_ssi_module","n":"ssi_value_length","d":"Sets the maximum length of parameter values in SSI commands."},{"m":"ngx_http_ssi_module","n":"commands","d":"#### SSI Commands\\nSSI commands have the following generic format:\\n```\\n\x3c!--# command parameter1=value1 parameter2=value2 ... --\x3e\\n\\n```\\n\\nThe following commands are supported:\\n`block`\\n\\nDefines a block that can be used as a stub in the `include` command. The block can contain other SSI commands. The command has the following parameter:\\n\\n`name`\\n\\nblock name.\\n\\nExample:\\n\\n> \x3c!--# block name=\\"one\\" --\x3e\\n> stub\\n> \x3c!--# endblock --\x3e\\n\\n`config`\\n\\nSets some parameters used during SSI processing, namely:\\n\\n`errmsg`\\n\\na string that is output if an error occurs during SSI processing. By default, the following string is output:\\n\\n> \\\\[an error occurred while processing the directive\\\\]\\n\\n`timefmt`\\n\\na format string passed to the `strftime()` function used to output date and time. By default, the following format is used:\\n\\n> \\"%A, %d-%b-%Y %H:%M:%S %Z\\"\\n\\nThe \u201c`%s`\u201d format is suitable to output time in seconds.\\n\\n`echo`\\n\\nOutputs the value of a variable. The command has the following parameters:\\n\\n`var`\\n\\nthe variable name.\\n\\n`encoding`\\n\\nthe encoding method. Possible values include `none`, `url`, and `entity`. By default, `entity` is used.\\n\\n`default`\\n\\na non-standard parameter that sets a string to be output if a variable is undefined. By default, \u201c`(none)`\u201d is output. The command\\n\\n> \x3c!--# echo var=\\"name\\" default=\\"**no**\\" --\x3e\\n\\nreplaces the following sequence of commands:\\n\\n> \x3c!--# if expr=\\"$name\\" --\x3e\x3c!--# echo var=\\"name\\" --\x3e\x3c!--#\\n>        else --\x3e**no**\x3c!--# endif --\x3e\\n\\n`if`\\n\\nPerforms a conditional inclusion. The following commands are supported:\\n\\n> \x3c!--# if expr=\\"...\\" --\x3e\\n> ...\\n> \x3c!--# elif expr=\\"...\\" --\x3e\\n> ...\\n> \x3c!--# else --\x3e\\n> ...\\n> \x3c!--# endif --\x3e\\n\\nOnly one level of nesting is currently supported. The command has the following parameter:\\n\\n`expr`\\n\\nexpression. An expression can be:\\n\\n*   variable existence check:\\n    \\n    > \x3c!--# if expr=\\"$name\\" --\x3e\\n    \\n*   comparison of a variable with a text:\\n    \\n    > \x3c!--# if expr=\\"$name = `_text_`\\" --\x3e\\n    > \x3c!--# if expr=\\"$name != `_text_`\\" --\x3e\\n    \\n*   comparison of a variable with a regular expression:\\n    \\n    > \x3c!--# if expr=\\"$name = /`_text_`/\\" --\x3e\\n    > \x3c!--# if expr=\\"$name != /`_text_`/\\" --\x3e\\n    \\n\\nIf a `_text_` contains variables, their values are substituted. A regular expression can contain positional and named captures that can later be used through variables, for example:\\n\\n> \x3c!--# if expr=\\"$name = /(.+)@(?P<domain>.+)/\\" --\x3e\\n>     \x3c!--# echo var=\\"1\\" --\x3e\\n>     \x3c!--# echo var=\\"domain\\" --\x3e\\n> \x3c!--# endif --\x3e\\n\\n`include`\\n\\nIncludes the result of another request into a response. The command has the following parameters:\\n\\n`file`\\n\\nspecifies an included file, for example:\\n\\n> \x3c!--# include file=\\"footer.html\\" --\x3e\\n\\n`virtual`\\n\\nspecifies an included request, for example:\\n\\n> \x3c!--# include virtual=\\"/remote/body.php?argument=value\\" --\x3e\\n\\nSeveral requests specified on one page and processed by proxied or FastCGI/uwsgi/SCGI/gRPC servers run in parallel. If sequential processing is desired, the `wait` parameter should be used.\\n\\n`stub`\\n\\na non-standard parameter that names the block whose content will be output if the included request results in an empty body or if an error occurs during the request processing, for example:\\n\\n> \x3c!--# block name=\\"one\\" --\x3e&nbsp;\x3c!--# endblock --\x3e\\n> \x3c!--# include virtual=\\"/remote/body.php?argument=value\\" stub=\\"one\\" --\x3e\\n\\nThe replacement block content is processed in the included request context.\\n\\n`wait`\\n\\na non-standard parameter that instructs to wait for a request to fully complete before continuing with SSI processing, for example:\\n\\n> \x3c!--# include virtual=\\"/remote/body.php?argument=value\\" wait=\\"yes\\" --\x3e\\n\\n`set`\\n\\na non-standard parameter that instructs to write a successful result of request processing to the specified variable, for example:\\n\\n> \x3c!--# include virtual=\\"/remote/body.php?argument=value\\" set=\\"one\\" --\x3e\\n\\nThe maximum size of the response is set by the [subrequest\\\\_output\\\\_buffer\\\\_size](ngx_http_core_module.html#subrequest_output_buffer_size) directive (1.13.10):\\n\\n> location /remote/ {\\n>     subrequest\\\\_output\\\\_buffer\\\\_size 64k;\\n>     ...\\n> }\\n\\nPrior to version 1.13.10, only the results of responses obtained using the [ngx\\\\_http\\\\_proxy\\\\_module](ngx_http_proxy_module.html), [ngx\\\\_http\\\\_memcached\\\\_module](ngx_http_memcached_module.html), [ngx\\\\_http\\\\_fastcgi\\\\_module](ngx_http_fastcgi_module.html) (1.5.6), [ngx\\\\_http\\\\_uwsgi\\\\_module](ngx_http_uwsgi_module.html) (1.5.6), and [ngx\\\\_http\\\\_scgi\\\\_module](ngx_http_scgi_module.html) (1.5.6) modules could be written into variables. The maximum size of the response was set with the [proxy\\\\_buffer\\\\_size](ngx_http_proxy_module.html#proxy_buffer_size), [memcached\\\\_buffer\\\\_size](ngx_http_memcached_module.html#memcached_buffer_size), [fastcgi\\\\_buffer\\\\_size](ngx_http_fastcgi_module.html#fastcgi_buffer_size), [uwsgi\\\\_buffer\\\\_size](ngx_http_uwsgi_module.html#uwsgi_buffer_size), and [scgi\\\\_buffer\\\\_size](ngx_http_scgi_module.html#scgi_buffer_size) directives.\\n\\n`set`\\n\\nSets a value of a variable. The command has the following parameters:\\n\\n`var`\\n\\nthe variable name.\\n\\n`value`\\n\\nthe variable value. If an assigned value contains variables, their values are substituted.\\n"},{"m":"ngx_http_ssi_module","n":"$date_local","d":"current time in GMT. The format is set by the `config` command with the `timefmt` parameter."},{"m":"ngx_http_ssi_module","n":"$date_gmt","d":"current time in GMT. The format is set by the `config` command with the `timefmt` parameter."},{"m":"ngx_http_ssl_module","n":"summary","d":"The `ngx_http_ssl_module` module provides the necessary support for HTTPS.\\nThis module is not built by default, it should be enabled with the `--with-http_ssl_module` configuration parameter.\\nThis module requires the [OpenSSL](http://www.openssl.org) library.\\n"},{"m":"ngx_http_ssl_module","n":"ssl","d":"This directive was made obsolete in version 1.15.0. The `ssl` parameter of the [listen](ngx_http_core_module.html#listen) directive should be used instead."},{"m":"ngx_http_ssl_module","n":"ssl_buffer_size","d":"Sets the size of the buffer used for sending data.\\nBy default, the buffer size is 16k, which corresponds to minimal overhead when sending big responses. To minimize Time To First Byte it may be beneficial to use smaller values, for example:\\n```\\nssl_buffer_size 4k;\\n\\n```\\n"},{"m":"ngx_http_ssl_module","n":"ssl_certificate","d":"Specifies a `_file_` with the certificate in the PEM format for the given virtual server. If intermediate certificates should be specified in addition to a primary certificate, they should be specified in the same file in the following order: the primary certificate comes first, then the intermediate certificates. A secret key in the PEM format may be placed in the same file.\\nSince version 1.11.0, this directive can be specified multiple times to load certificates of different types, for example, RSA and ECDSA:\\n```\\nserver {\\n    listen              443 ssl;\\n    server_name         example.com;\\n\\n    ssl_certificate     example.com.rsa.crt;\\n    ssl_certificate_key example.com.rsa.key;\\n\\n    ssl_certificate     example.com.ecdsa.crt;\\n    ssl_certificate_key example.com.ecdsa.key;\\n\\n    ...\\n}\\n\\n```\\n\\nOnly OpenSSL 1.0.2 or higher supports separate [certificate chains](configuring_https_servers.html#chains) for different certificates. With older versions, only one certificate chain can be used.\\n\\nSince version 1.15.9, variables can be used in the `_file_` name when using OpenSSL 1.0.2 or higher:\\n```\\nssl_certificate     $ssl_server_name.crt;\\nssl_certificate_key $ssl_server_name.key;\\n\\n```\\nNote that using variables implies that a certificate will be loaded for each SSL handshake, and this may have a negative impact on performance."},{"m":"ngx_http_ssl_module","n":"ssl_certificate_data","d":"The value `data`:`_$variable_` can be specified instead of the `_file_` (1.15.10), which loads a certificate from a variable without using intermediate files. Note that inappropriate use of this syntax may have its security implications, such as writing secret key data to [error log](../ngx_core_module.html#error_log).\\nIt should be kept in mind that due to the HTTPS protocol limitations for maximum interoperability virtual servers should listen on [different IP addresses](configuring_https_servers.html#name_based_https_servers)."},{"m":"ngx_http_ssl_module","n":"ssl_certificate_key","d":"Specifies a `_file_` with the secret key in the PEM format for the given virtual server.\\nThe value `engine`:`_name_`:`_id_` can be specified instead of the `_file_` (1.7.9), which loads a secret key with a specified `_id_` from the OpenSSL engine `_name_`."},{"m":"ngx_http_ssl_module","n":"ssl_certificate_key_data","d":"The value `data`:`_$variable_` can be specified instead of the `_file_` (1.15.10), which loads a secret key from a variable without using intermediate files. Note that inappropriate use of this syntax may have its security implications, such as writing secret key data to [error log](../ngx_core_module.html#error_log).\\nSince version 1.15.9, variables can be used in the `_file_` name when using OpenSSL 1.0.2 or higher."},{"m":"ngx_http_ssl_module","n":"ssl_ciphers","d":"Specifies the enabled ciphers. The ciphers are specified in the format understood by the OpenSSL library, for example:\\n```\\nssl_ciphers ALL:!aNULL:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP;\\n\\n```\\n\\nThe full list can be viewed using the \u201c`openssl ciphers`\u201d command.\\n\\nThe previous versions of nginx used [different](configuring_https_servers.html#compatibility) ciphers by default.\\n"},{"m":"ngx_http_ssl_module","n":"ssl_client_certificate","d":"Specifies a `_file_` with trusted CA certificates in the PEM format used to [verify](#ssl_verify_client) client certificates and OCSP responses if [ssl\\\\_stapling](#ssl_stapling) is enabled.\\nThe list of certificates will be sent to clients. If this is not desired, the [ssl\\\\_trusted\\\\_certificate](#ssl_trusted_certificate) directive can be used."},{"m":"ngx_http_ssl_module","n":"ssl_conf_command","d":"Sets arbitrary OpenSSL configuration [commands](https://www.openssl.org/docs/man1.1.1/man3/SSL_CONF_cmd.html).\\nThe directive is supported when using OpenSSL 1.0.2 or higher.\\n\\nSeveral `ssl_conf_command` directives can be specified on the same level:\\n```\\nssl_conf_command Options PrioritizeChaCha;\\nssl_conf_command Ciphersuites TLS_CHACHA20_POLY1305_SHA256;\\n\\n```\\nThese directives are inherited from the previous configuration level if and only if there are no `ssl_conf_command` directives defined on the current level.\\n\\nNote that configuring OpenSSL directly might result in unexpected behavior.\\n"},{"m":"ngx_http_ssl_module","n":"ssl_crl","d":"Specifies a `_file_` with revoked certificates (CRL) in the PEM format used to [verify](#ssl_verify_client) client certificates."},{"m":"ngx_http_ssl_module","n":"ssl_dhparam","d":"Specifies a `_file_` with DH parameters for DHE ciphers.\\nBy default no parameters are set, and therefore DHE ciphers will not be used.\\nPrior to version 1.11.0, builtin parameters were used by default.\\n"},{"m":"ngx_http_ssl_module","n":"ssl_early_data","d":"Enables or disables TLS 1.3 [early data](https://tools.ietf.org/html/rfc8446#section-2.3).\\nRequests sent within early data are subject to [replay attacks](https://tools.ietf.org/html/rfc8470). To protect against such attacks at the application layer, the [$ssl\\\\_early\\\\_data](#var_ssl_early_data) variable should be used.\\n\\n```\\nproxy_set_header Early-Data $ssl_early_data;\\n\\n```\\n\\nThe directive is supported when using OpenSSL 1.1.1 or higher (1.15.4) and [BoringSSL](https://boringssl.googlesource.com/boringssl/).\\n"},{"m":"ngx_http_ssl_module","n":"ssl_ecdh_curve","d":"Specifies a `_curve_` for ECDHE ciphers.\\nWhen using OpenSSL 1.0.2 or higher, it is possible to specify multiple curves (1.11.0), for example:\\n```\\nssl_ecdh_curve prime256v1:secp384r1;\\n\\n```\\n\\nThe special value `auto` (1.11.0) instructs nginx to use a list built into the OpenSSL library when using OpenSSL 1.0.2 or higher, or `prime256v1` with older versions.\\n\\nPrior to version 1.11.0, the `prime256v1` curve was used by default.\\n\\n\\nWhen using OpenSSL 1.0.2 or higher, this directive sets the list of curves supported by the server. Thus, in order for ECDSA certificates to work, it is important to include the curves used in the certificates.\\n"},{"m":"ngx_http_ssl_module","n":"ssl_ocsp","d":"Enables OCSP validation of the client certificate chain. The `leaf` parameter enables validation of the client certificate only.\\nFor the OCSP validation to work, the [ssl\\\\_verify\\\\_client](#ssl_verify_client) directive should be set to `on` or `optional`.\\nTo resolve the OCSP responder hostname, the [resolver](ngx_http_core_module.html#resolver) directive should also be specified.\\nExample:\\n```\\nssl_verify_client on;\\nssl_ocsp          on;\\nresolver          192.0.2.1;\\n\\n```\\n"},{"m":"ngx_http_ssl_module","n":"ssl_ocsp_cache","d":"Sets `name` and `size` of the cache that stores client certificates status for OCSP validation. The cache is shared between all worker processes. A cache with the same name can be used in several virtual servers.\\nThe `off` parameter prohibits the use of the cache."},{"m":"ngx_http_ssl_module","n":"ssl_ocsp_responder","d":"Overrides the URL of the OCSP responder specified in the \u201c[Authority Information Access](https://tools.ietf.org/html/rfc5280#section-4.2.2.1)\u201d certificate extension for [validation](#ssl_ocsp) of client certificates.\\nOnly \u201c`http://`\u201d OCSP responders are supported:\\n```\\nssl_ocsp_responder http://ocsp.example.com/;\\n\\n```\\n"},{"m":"ngx_http_ssl_module","n":"ssl_password_file","d":"Specifies a `_file_` with passphrases for [secret keys](#ssl_certificate_key) where each passphrase is specified on a separate line. Passphrases are tried in turn when loading the key.\\nExample:\\n```\\nhttp {\\n    ssl_password_file /etc/keys/global.pass;\\n    ...\\n\\n    server {\\n        server_name www1.example.com;\\n        ssl_certificate_key /etc/keys/first.key;\\n    }\\n\\n    server {\\n        server_name www2.example.com;\\n\\n        # named pipe can also be used instead of a file\\n        ssl_password_file /etc/keys/fifo;\\n        ssl_certificate_key /etc/keys/second.key;\\n    }\\n}\\n\\n```\\n"},{"m":"ngx_http_ssl_module","n":"ssl_prefer_server_ciphers","d":"Specifies that server ciphers should be preferred over client ciphers when using the SSLv3 and TLS protocols."},{"m":"ngx_http_ssl_module","n":"ssl_protocols","d":"Enables the specified protocols.\\nThe `TLSv1.1` and `TLSv1.2` parameters (1.1.13, 1.0.12) work only when OpenSSL 1.0.1 or higher is used.\\n\\nThe `TLSv1.3` parameter (1.13.0) works only when OpenSSL 1.1.1 built with TLSv1.3 support is used.\\n"},{"m":"ngx_http_ssl_module","n":"ssl_reject_handshake","d":"If enabled, SSL handshakes in the [server](ngx_http_core_module.html#server) block will be rejected.\\nFor example, in the following configuration, SSL handshakes with server names other than `example.com` are rejected:\\n```\\nserver {\\n    listen               443 ssl;\\n    ssl_reject_handshake on;\\n}\\n\\nserver {\\n    listen              443 ssl;\\n    server_name         example.com;\\n    ssl_certificate     example.com.crt;\\n    ssl_certificate_key example.com.key;\\n}\\n\\n```\\n"},{"m":"ngx_http_ssl_module","n":"ssl_session_cache","d":"Sets the types and sizes of caches that store session parameters. A cache can be of any of the following types:\\n`off`\\n\\nthe use of a session cache is strictly prohibited: nginx explicitly tells a client that sessions may not be reused.\\n\\n`none`\\n\\nthe use of a session cache is gently disallowed: nginx tells a client that sessions may be reused, but does not actually store session parameters in the cache.\\n\\n`builtin`\\n\\na cache built in OpenSSL; used by one worker process only. The cache size is specified in sessions. If size is not given, it is equal to 20480 sessions. Use of the built-in cache can cause memory fragmentation.\\n\\n`shared`\\n\\na cache shared between all worker processes. The cache size is specified in bytes; one megabyte can store about 4000 sessions. Each shared cache should have an arbitrary name. A cache with the same name can be used in several virtual servers.\\n\\nBoth cache types can be used simultaneously, for example:\\n```\\nssl_session_cache builtin:1000 shared:SSL:10m;\\n\\n```\\nbut using only shared cache without the built-in cache should be more efficient."},{"m":"ngx_http_ssl_module","n":"ssl_session_ticket_key","d":"Sets a `_file_` with the secret key used to encrypt and decrypt TLS session tickets. The directive is necessary if the same key has to be shared between multiple servers. By default, a randomly generated key is used.\\nIf several keys are specified, only the first key is used to encrypt TLS session tickets. This allows configuring key rotation, for example:\\n```\\nssl_session_ticket_key current.key;\\nssl_session_ticket_key previous.key;\\n\\n```\\n\\nThe `_file_` must contain 80 or 48 bytes of random data and can be created using the following command:\\n```\\nopenssl rand 80 > ticket.key\\n\\n```\\nDepending on the file size either AES256 (for 80-byte keys, 1.11.8) or AES128 (for 48-byte keys) is used for encryption."},{"m":"ngx_http_ssl_module","n":"ssl_session_tickets","d":"Enables or disables session resumption through [TLS session tickets](https://tools.ietf.org/html/rfc5077)."},{"m":"ngx_http_ssl_module","n":"ssl_session_timeout","d":"Specifies a time during which a client may reuse the session parameters."},{"m":"ngx_http_ssl_module","n":"ssl_stapling","d":"Enables or disables [stapling of OCSP responses](https://tools.ietf.org/html/rfc6066#section-8) by the server. Example:\\n```\\nssl_stapling on;\\nresolver 192.0.2.1;\\n\\n```\\n\\nFor the OCSP stapling to work, the certificate of the server certificate issuer should be known. If the [ssl\\\\_certificate](#ssl_certificate) file does not contain intermediate certificates, the certificate of the server certificate issuer should be present in the [ssl\\\\_trusted\\\\_certificate](#ssl_trusted_certificate) file.\\nFor a resolution of the OCSP responder hostname, the [resolver](ngx_http_core_module.html#resolver) directive should also be specified."},{"m":"ngx_http_ssl_module","n":"ssl_stapling_file","d":"When set, the stapled OCSP response will be taken from the specified `_file_` instead of querying the OCSP responder specified in the server certificate.\\nThe file should be in the DER format as produced by the \u201c`openssl ocsp`\u201d command."},{"m":"ngx_http_ssl_module","n":"ssl_stapling_responder","d":"Overrides the URL of the OCSP responder specified in the \u201c[Authority Information Access](https://tools.ietf.org/html/rfc5280#section-4.2.2.1)\u201d certificate extension.\\nOnly \u201c`http://`\u201d OCSP responders are supported:\\n```\\nssl_stapling_responder http://ocsp.example.com/;\\n\\n```\\n"},{"m":"ngx_http_ssl_module","n":"ssl_stapling_verify","d":"Enables or disables verification of OCSP responses by the server.\\nFor verification to work, the certificate of the server certificate issuer, the root certificate, and all intermediate certificates should be configured as trusted using the [ssl\\\\_trusted\\\\_certificate](#ssl_trusted_certificate) directive."},{"m":"ngx_http_ssl_module","n":"ssl_trusted_certificate","d":"Specifies a `_file_` with trusted CA certificates in the PEM format used to [verify](#ssl_verify_client) client certificates and OCSP responses if [ssl\\\\_stapling](#ssl_stapling) is enabled.\\nIn contrast to the certificate set by [ssl\\\\_client\\\\_certificate](#ssl_client_certificate), the list of these certificates will not be sent to clients."},{"m":"ngx_http_ssl_module","n":"ssl_verify_client","d":"Enables verification of client certificates. The verification result is stored in the [$ssl\\\\_client\\\\_verify](#var_ssl_client_verify) variable.\\nThe `optional` parameter (0.8.7+) requests the client certificate and verifies it if the certificate is present.\\nThe `optional_no_ca` parameter (1.3.8, 1.2.5) requests the client certificate but does not require it to be signed by a trusted CA certificate. This is intended for the use in cases when a service that is external to nginx performs the actual certificate verification. The contents of the certificate is accessible through the [$ssl\\\\_client\\\\_cert](#var_ssl_client_cert) variable."},{"m":"ngx_http_ssl_module","n":"ssl_verify_depth","d":"Sets the verification depth in the client certificates chain."},{"m":"ngx_http_ssl_module","n":"errors","d":"#### Error Processing\\nThe `ngx_http_ssl_module` module supports several non-standard error codes that can be used for redirects using the [error\\\\_page](ngx_http_core_module.html#error_page) directive:\\n495\\n\\nan error has occurred during the client certificate verification;\\n\\n496\\n\\na client has not presented the required certificate;\\n\\n497\\n\\na regular request has been sent to the HTTPS port.\\n\\nThe redirection happens after the request is fully parsed and the variables, such as `$request_uri`, `$uri`, `$args` and others, are available."},{"m":"ngx_http_ssl_module","n":"$ssl_cipher","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_ciphers","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_client_escaped_cert","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_client_cert","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_client_fingerprint","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_client_i_dn","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_client_i_dn_legacy","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_client_raw_cert\\n","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_client_s_dn","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_client_s_dn_legacy","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_client_serial","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_client_v_end","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_client_v_remain","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_client_v_start","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_client_verify","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_curves","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_early_data","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_protocol","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_server_name","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_session_id","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_ssl_module","n":"$ssl_session_reused","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise (1.5.11)."},{"m":"ngx_http_status_module","n":"summary","d":"The `ngx_http_status_module` module provides access to various status information.\\nThis module was available as part of our [commercial subscription](http://nginx.com/products/) until 1.13.10. It was superseded by the [ngx\\\\_http\\\\_api\\\\_module](ngx_http_api_module.html) module in 1.13.3.\\n"},{"m":"ngx_http_status_module","n":"status","d":"The status information will be accessible from the surrounding location. Access to this location should be [limited](ngx_http_core_module.html#satisfy)."},{"m":"ngx_http_status_module","n":"status_format","d":"By default, status information is output in the JSON format.\\nAlternatively, data may be output as JSONP. The `_callback_` parameter specifies the name of a callback function. Parameter value can contain variables. If parameter is omitted, or the computed value is an empty string, then \u201c`ngx_status_jsonp_callback`\u201d is used."},{"m":"ngx_http_status_module","n":"status_zone","d":"Enables collection of virtual [http](ngx_http_core_module.html#server) or [stream](../stream/ngx_stream_core_module.html#server) (1.7.11) server status information in the specified `_zone_`. Several servers may share the same zone."},{"m":"ngx_http_status_module","n":"data","d":"#### Data\\nThe following status information is provided:\\n`version`\\n\\nVersion of the provided data set. The current version is 8.\\n\\n`nginx_version`\\n\\nVersion of nginx.\\n\\n`nginx_build`\\n\\nName of nginx build.\\n\\n`address`\\n\\nThe address of the server that accepted status request.\\n\\n`generation`\\n\\nThe total number of configuration [reloads](../control.html#reconfiguration).\\n\\n`load_timestamp`\\n\\nTime of the last reload of configuration, in milliseconds since Epoch.\\n\\n`timestamp`\\n\\nCurrent time in milliseconds since Epoch.\\n\\n`pid`\\n\\nThe ID of the worker process that handled status request.\\n\\n`ppid`\\n\\nThe ID of the master process that started the [worker process](#pid).\\n\\n`processes`\\n\\n`respawned`\\n\\nThe total number of abnormally terminated and respawned child processes.\\n\\n`connections`\\n\\n`accepted`\\n\\nThe total number of accepted client connections.\\n\\n`dropped`\\n\\nThe total number of dropped client connections.\\n\\n`active`\\n\\nThe current number of active client connections.\\n\\n`idle`\\n\\nThe current number of idle client connections.\\n\\n`ssl`\\n\\n`handshakes`\\n\\nThe total number of successful SSL handshakes.\\n\\n`handshakes_failed`\\n\\nThe total number of failed SSL handshakes.\\n\\n`session_reuses`\\n\\nThe total number of session reuses during SSL handshake.\\n\\n`requests`\\n\\n`total`\\n\\nThe total number of client requests.\\n\\n`current`\\n\\nThe current number of client requests.\\n\\n`server_zones`\\n\\nFor each [status\\\\_zone](#status_zone):\\n\\n`processing`\\n\\nThe number of client requests that are currently being processed.\\n\\n`requests`\\n\\nThe total number of client requests received from clients.\\n\\n`responses`\\n\\n`total`\\n\\nThe total number of responses sent to clients.\\n\\n`1xx`, `2xx`, `3xx`, `4xx`, `5xx`\\n\\nThe number of responses with status codes 1xx, 2xx, 3xx, 4xx, and 5xx.\\n\\n`discarded`\\n\\nThe total number of requests completed without sending a response.\\n\\n`received`\\n\\nThe total number of bytes received from clients.\\n\\n`sent`\\n\\nThe total number of bytes sent to clients.\\n\\n`slabs`\\n\\nFor each shared memory zone that uses slab allocator:\\n\\n`pages`\\n\\n`used`\\n\\nThe current number of used memory pages.\\n\\n`free`\\n\\nThe current number of free memory pages.\\n\\n`slots`\\n\\nFor each memory slot size (8, 16, 32, 64, 128, etc.) the following data are provided:\\n\\n`used`\\n\\nThe current number of used memory slots.\\n\\n`free`\\n\\nThe current number of free memory slots.\\n\\n`reqs`\\n\\nThe total number of attempts to allocate memory of specified size.\\n\\n`fails`\\n\\nThe number of unsuccessful attempts to allocate memory of specified size.\\n\\n`upstreams`\\n\\nFor each [dynamically configurable](ngx_http_upstream_module.html#zone) [group](ngx_http_upstream_module.html#upstream), the following data are provided:\\n\\n`peers`\\n\\nFor each [server](ngx_http_upstream_module.html#server), the following data are provided:\\n\\n`id`\\n\\nThe ID of the server.\\n\\n`server`\\n\\nAn [address](ngx_http_upstream_module.html#server) of the server.\\n\\n`name`\\n\\nThe name of the server specified in the [server](ngx_http_upstream_module.html#server) directive.\\n\\n`service`\\n\\nThe [service](ngx_http_upstream_module.html#service) parameter value of the [server](ngx_http_upstream_module.html#server) directive.\\n\\n`backup`\\n\\nA boolean value indicating whether the server is a [backup](ngx_http_upstream_module.html#backup) server.\\n\\n`weight`\\n\\n[Weight](ngx_http_upstream_module.html#weight) of the server.\\n\\n`state`\\n\\nCurrent state, which may be one of \u201c`up`\u201d, \u201c`draining`\u201d, \u201c`down`\u201d, \u201c`unavail`\u201d, \u201c`checking`\u201d, or \u201c`unhealthy`\u201d.\\n\\n`active`\\n\\nThe current number of active connections.\\n\\n`max_conns`\\n\\nThe [max\\\\_conns](ngx_http_upstream_module.html#max_conns) limit for the server.\\n\\n`requests`\\n\\nThe total number of client requests forwarded to this server.\\n\\n`responses`\\n\\n`total`\\n\\nThe total number of responses obtained from this server.\\n\\n`1xx`, `2xx`, `3xx`, `4xx`, `5xx`\\n\\nThe number of responses with status codes 1xx, 2xx, 3xx, 4xx, and 5xx.\\n\\n`sent`\\n\\nThe total number of bytes sent to this server.\\n\\n`received`\\n\\nThe total number of bytes received from this server.\\n\\n`fails`\\n\\nThe total number of unsuccessful attempts to communicate with the server.\\n\\n`unavail`\\n\\nHow many times the server became unavailable for client requests (state \u201c`unavail`\u201d) due to the number of unsuccessful attempts reaching the [max\\\\_fails](ngx_http_upstream_module.html#max_fails) threshold.\\n\\n`health_checks`\\n\\n`checks`\\n\\nThe total number of [health check](ngx_http_upstream_hc_module.html#health_check) requests made.\\n\\n`fails`\\n\\nThe number of failed health checks.\\n\\n`unhealthy`\\n\\nHow many times the server became unhealthy (state \u201c`unhealthy`\u201d).\\n\\n`last_passed`\\n\\nBoolean indicating if the last health check request was successful and passed [tests](ngx_http_upstream_hc_module.html#match).\\n\\n`downtime`\\n\\nTotal time the server was in the \u201c`unavail`\u201d, \u201c`checking`\u201d, and \u201c`unhealthy`\u201d states.\\n\\n`downstart`\\n\\nThe time (in milliseconds since Epoch) when the server became \u201c`unavail`\u201d, \u201c`checking`\u201d, or \u201c`unhealthy`\u201d.\\n\\n`selected`\\n\\nThe time (in milliseconds since Epoch) when the server was last selected to process a request (1.7.5).\\n\\n`header_time`\\n\\nThe average time to get the [response header](ngx_http_upstream_module.html#var_upstream_header_time) from the server (1.7.10). Prior to version 1.11.6, the field was available only when using the [least\\\\_time](ngx_http_upstream_module.html#least_time) load balancing method.\\n\\n`response_time`\\n\\nThe average time to get the [full response](ngx_http_upstream_module.html#var_upstream_response_time) from the server (1.7.10). Prior to version 1.11.6, the field was available only when using the [least\\\\_time](ngx_http_upstream_module.html#least_time) load balancing method.\\n\\n`keepalive`\\n\\nThe current number of idle [keepalive](ngx_http_upstream_module.html#keepalive) connections.\\n\\n`zombies`\\n\\nThe current number of servers removed from the group but still processing active client requests.\\n\\n`zone`\\n\\nThe name of the shared memory [zone](ngx_http_upstream_module.html#zone) that keeps the group\u2019s configuration and run-time state.\\n\\n`queue`\\n\\nFor the requests [queue](ngx_http_upstream_module.html#queue), the following data are provided:\\n\\n`size`\\n\\nThe current number of requests in the queue.\\n\\n`max_size`\\n\\nThe maximum number of requests that can be in the queue at the same time.\\n\\n`overflows`\\n\\nThe total number of requests rejected due to the queue overflow.\\n\\n`caches`\\n\\nFor each cache (configured by [proxy\\\\_cache\\\\_path](ngx_http_proxy_module.html#proxy_cache_path) and the likes):\\n\\n`size`\\n\\nThe current size of the cache.\\n\\n`max_size`\\n\\nThe limit on the maximum size of the cache specified in the configuration.\\n\\n`cold`\\n\\nA boolean value indicating whether the \u201ccache loader\u201d process is still loading data from disk into the cache.\\n\\n`hit`, `stale`, `updating`, `revalidated`\\n\\n`responses`\\n\\nThe total number of responses read from the cache (hits, or stale responses due to [proxy\\\\_cache\\\\_use\\\\_stale](ngx_http_proxy_module.html#proxy_cache_use_stale) and the likes).\\n\\n`bytes`\\n\\nThe total number of bytes read from the cache.\\n\\n`miss`, `expired`, `bypass`\\n\\n`responses`\\n\\nThe total number of responses not taken from the cache (misses, expires, or bypasses due to [proxy\\\\_cache\\\\_bypass](ngx_http_proxy_module.html#proxy_cache_bypass) and the likes).\\n\\n`bytes`\\n\\nThe total number of bytes read from the proxied server.\\n\\n`responses_written`\\n\\nThe total number of responses written to the cache.\\n\\n`bytes_written`\\n\\nThe total number of bytes written to the cache.\\n\\n`stream`\\n\\n`server_zones`\\n\\nFor each [status\\\\_zone](#status_zone):\\n\\n`processing`\\n\\nThe number of client connections that are currently being processed.\\n\\n`connections`\\n\\nThe total number of connections accepted from clients.\\n\\n`sessions`\\n\\n`total`\\n\\nThe total number of completed client sessions.\\n\\n`2xx`, `4xx`, `5xx`\\n\\nThe number of sessions completed with [status codes](../stream/ngx_stream_core_module.html#var_status) 2xx, 4xx, or 5xx.\\n\\n`discarded`\\n\\nThe total number of connections completed without creating a session.\\n\\n`received`\\n\\nThe total number of bytes received from clients.\\n\\n`sent`\\n\\nThe total number of bytes sent to clients.\\n\\n`upstreams`\\n\\nFor each [dynamically configurable](../stream/ngx_stream_upstream_module.html#zone) [group](../stream/ngx_stream_upstream_module.html#upstream), the following data are provided:\\n\\n`peers`\\n\\nFor each [server](../stream/ngx_stream_upstream_module.html#server) the following data are provided:\\n\\n`id`\\n\\nThe ID of the server.\\n\\n`server`\\n\\nAn [address](../stream/ngx_stream_upstream_module.html#server) of the server.\\n\\n`name`\\n\\nThe name of the server specified in the [server](../stream/ngx_stream_upstream_module.html#server) directive.\\n\\n`service`\\n\\nThe [service](../stream/ngx_stream_upstream_module.html#service) parameter value of the [server](../stream/ngx_stream_upstream_module.html#server) directive.\\n\\n`backup`\\n\\nA boolean value indicating whether the server is a [backup](../stream/ngx_stream_upstream_module.html#backup) server.\\n\\n`weight`\\n\\n[Weight](../stream/ngx_stream_upstream_module.html#weight) of the server.\\n\\n`state`\\n\\nCurrent state, which may be one of \u201c`up`\u201d, \u201c`down`\u201d, \u201c`unavail`\u201d, \u201c`checking`\u201d, or \u201c`unhealthy`\u201d.\\n\\n`active`\\n\\nThe current number of connections.\\n\\n`max_conns`\\n\\nThe [max\\\\_conns](../stream/ngx_stream_upstream_module.html#max_conns) limit for the server.\\n\\n`connections`\\n\\nThe total number of client connections forwarded to this server.\\n\\n`connect_time`\\n\\nThe average time to connect to the upstream server. Prior to version 1.11.6, the field was available only when using the [least\\\\_time](../stream/ngx_stream_upstream_module.html#least_time) load balancing method.\\n\\n`first_byte_time`\\n\\nThe average time to receive the first byte of data. Prior to version 1.11.6, the field was available only when using the [least\\\\_time](../stream/ngx_stream_upstream_module.html#least_time) load balancing method.\\n\\n`response_time`\\n\\nThe average time to receive the last byte of data. Prior to version 1.11.6, the field was available only when using the [least\\\\_time](../stream/ngx_stream_upstream_module.html#least_time) load balancing method.\\n\\n`sent`\\n\\nThe total number of bytes sent to this server.\\n\\n`received`\\n\\nThe total number of bytes received from this server.\\n\\n`fails`\\n\\nThe total number of unsuccessful attempts to communicate with the server.\\n\\n`unavail`\\n\\nHow many times the server became unavailable for client connections (state \u201c`unavail`\u201d) due to the number of unsuccessful attempts reaching the [max\\\\_fails](../stream/ngx_stream_upstream_module.html#max_fails) threshold.\\n\\n`health_checks`\\n\\n`checks`\\n\\nThe total number of [health check](../stream/ngx_stream_upstream_hc_module.html#health_check) requests made.\\n\\n`fails`\\n\\nThe number of failed health checks.\\n\\n`unhealthy`\\n\\nHow many times the server became unhealthy (state \u201c`unhealthy`\u201d).\\n\\n`last_passed`\\n\\nBoolean indicating if the last health check request was successful and passed [tests](../stream/ngx_stream_upstream_hc_module.html#match).\\n\\n`downtime`\\n\\nTotal time the server was in the \u201c`unavail`\u201d, \u201c`checking`\u201d, and \u201c`unhealthy`\u201d states.\\n\\n`downstart`\\n\\nThe time (in milliseconds since Epoch) when the server became \u201c`unavail`\u201d, \u201c`checking`\u201d, or \u201c`unhealthy`\u201d.\\n\\n`selected`\\n\\nThe time (in milliseconds since Epoch) when the server was last selected to process a connection.\\n\\n`zombies`\\n\\nThe current number of servers removed from the group but still processing active client connections.\\n\\n`zone`\\n\\nThe name of the shared memory [zone](../stream/ngx_stream_upstream_module.html#zone) that keeps the group\u2019s configuration and run-time state.\\n"},{"m":"ngx_http_stub_status_module","n":"summary","d":"The `ngx_http_stub_status_module` module provides access to basic status information.\\nThis module is not built by default, it should be enabled with the `--with-http_stub_status_module` configuration parameter."},{"m":"ngx_http_stub_status_module","n":"stub_status","d":"The basic status information will be accessible from the surrounding location.\\n\\nIn versions prior to 1.7.5, the directive syntax required an arbitrary argument, for example, \u201c`stub_status on`\u201d.\\n"},{"m":"ngx_http_stub_status_module","n":"data","d":"#### Data\\nThe following status information is provided:\\n`Active connections`\\n\\nThe current number of active client connections including `Waiting` connections.\\n\\n`accepts`\\n\\nThe total number of accepted client connections.\\n\\n`handled`\\n\\nThe total number of handled connections. Generally, the parameter value is the same as `accepts` unless some resource limits have been reached (for example, the [worker\\\\_connections](../ngx_core_module.html#worker_connections) limit).\\n\\n`requests`\\n\\nThe total number of client requests.\\n\\n`Reading`\\n\\nThe current number of connections where nginx is reading the request header.\\n\\n`Writing`\\n\\nThe current number of connections where nginx is writing the response back to the client.\\n\\n`Waiting`\\n\\nThe current number of idle client connections waiting for a request.\\n"},{"m":"ngx_http_stub_status_module","n":"$connections_active","d":"same as the `Waiting` value."},{"m":"ngx_http_stub_status_module","n":"$connections_reading","d":"same as the `Waiting` value."},{"m":"ngx_http_stub_status_module","n":"$connections_writing","d":"same as the `Waiting` value."},{"m":"ngx_http_stub_status_module","n":"$connections_waiting","d":"same as the `Waiting` value."},{"m":"ngx_http_sub_module","n":"summary","d":"The `ngx_http_sub_module` module is a filter that modifies a response by replacing one specified string by another.\\nThis module is not built by default, it should be enabled with the `--with-http_sub_module` configuration parameter."},{"m":"ngx_http_sub_module","n":"sub_filter","d":"Sets a string to replace and a replacement string. The string to replace is matched ignoring the case. The string to replace (1.9.4) and replacement string can contain variables. Several `sub_filter` directives can be specified on the same configuration level (1.9.4). These directives are inherited from the previous configuration level if and only if there are no `sub_filter` directives defined on the current level."},{"m":"ngx_http_sub_module","n":"sub_filter_last_modified","d":"Allows preserving the \u201cLast-Modified\u201d header field from the original response during replacement to facilitate response caching.\\nBy default, the header field is removed as contents of the response are modified during processing."},{"m":"ngx_http_sub_module","n":"sub_filter_once","d":"Indicates whether to look for each string to replace once or repeatedly."},{"m":"ngx_http_upstream_module","n":"summary","d":"The `ngx_http_upstream_module` module is used to define groups of servers that can be referenced by the [proxy\\\\_pass](ngx_http_proxy_module.html#proxy_pass), [fastcgi\\\\_pass](ngx_http_fastcgi_module.html#fastcgi_pass), [uwsgi\\\\_pass](ngx_http_uwsgi_module.html#uwsgi_pass), [scgi\\\\_pass](ngx_http_scgi_module.html#scgi_pass), [memcached\\\\_pass](ngx_http_memcached_module.html#memcached_pass), and [grpc\\\\_pass](ngx_http_grpc_module.html#grpc_pass) directives."},{"m":"ngx_http_upstream_module","n":"upstream","d":"Defines a group of servers. Servers can listen on different ports. In addition, servers listening on TCP and UNIX-domain sockets can be mixed.\\nExample:\\n```\\nupstream backend {\\n    server backend1.example.com weight=5;\\n    server 127.0.0.1:8080       max_fails=3 fail_timeout=30s;\\n    server unix:/tmp/backend3;\\n\\n    server backup1.example.com  backup;\\n}\\n\\n```\\n\\nBy default, requests are distributed between the servers using a weighted round-robin balancing method. In the above example, each 7 requests will be distributed as follows: 5 requests go to `backend1.example.com` and one request to each of the second and third servers. If an error occurs during communication with a server, the request will be passed to the next server, and so on until all of the functioning servers will be tried. If a successful response could not be obtained from any of the servers, the client will receive the result of the communication with the last server."},{"m":"ngx_http_upstream_module","n":"server","d":"Defines the `_address_` and other `_parameters_` of a server. The address can be specified as a domain name or IP address, with an optional port, or as a UNIX-domain socket path specified after the \u201c`unix:`\u201d prefix. If a port is not specified, the port 80 is used. A domain name that resolves to several IP addresses defines multiple servers at once.\\nThe following parameters can be defined:\\n`weight`\\\\=`_number_`\\n\\nsets the weight of the server, by default, 1.\\n\\n`max_conns`\\\\=`_number_`\\n\\nlimits the maximum `_number_` of simultaneous active connections to the proxied server (1.11.5). Default value is zero, meaning there is no limit. If the server group does not reside in the [shared memory](#zone), the limitation works per each worker process.\\n\\n> If [idle keepalive](#keepalive) connections, multiple [workers](../ngx_core_module.html#worker_processes), and the [shared memory](#zone) are enabled, the total number of active and idle connections to the proxied server may exceed the `max_conns` value.\\n\\n> Since version 1.5.9 and prior to version 1.11.5, this parameter was available as part of our [commercial subscription](http://nginx.com/products/).\\n\\n`max_fails`\\\\=`_number_`\\n\\nsets the number of unsuccessful attempts to communicate with the server that should happen in the duration set by the `fail_timeout` parameter to consider the server unavailable for a duration also set by the `fail_timeout` parameter. By default, the number of unsuccessful attempts is set to 1. The zero value disables the accounting of attempts. What is considered an unsuccessful attempt is defined by the [proxy\\\\_next\\\\_upstream](ngx_http_proxy_module.html#proxy_next_upstream), [fastcgi\\\\_next\\\\_upstream](ngx_http_fastcgi_module.html#fastcgi_next_upstream), [uwsgi\\\\_next\\\\_upstream](ngx_http_uwsgi_module.html#uwsgi_next_upstream), [scgi\\\\_next\\\\_upstream](ngx_http_scgi_module.html#scgi_next_upstream), [memcached\\\\_next\\\\_upstream](ngx_http_memcached_module.html#memcached_next_upstream), and [grpc\\\\_next\\\\_upstream](ngx_http_grpc_module.html#grpc_next_upstream) directives.\\n\\n`fail_timeout`\\\\=`_time_`\\n\\nsets\\n\\n*   the time during which the specified number of unsuccessful attempts to communicate with the server should happen to consider the server unavailable;\\n*   and the period of time the server will be considered unavailable.\\n\\nBy default, the parameter is set to 10 seconds.\\n\\n`backup`\\n\\nmarks the server as a backup server. It will be passed requests when the primary servers are unavailable.\\n\\n> The parameter cannot be used along with the [hash](#hash), [ip\\\\_hash](#ip_hash), and [random](#random) load balancing methods.\\n\\n`down`\\n\\nmarks the server as permanently unavailable.\\n\\nAdditionally, the following parameters are available as part of our [commercial subscription](http://nginx.com/products/):\\n`resolve`\\n\\nmonitors changes of the IP addresses that correspond to a domain name of the server, and automatically modifies the upstream configuration without the need of restarting nginx (1.5.12). The server group must reside in the [shared memory](#zone).\\n\\nIn order for this parameter to work, the `resolver` directive must be specified in the [http](ngx_http_core_module.html#resolver) block or in the corresponding [upstream](#resolver) block.\\n\\n`route`\\\\=`_string_`\\n\\nsets the server route name.\\n\\n`service`\\\\=`_name_`\\n\\nenables resolving of DNS [SRV](https://tools.ietf.org/html/rfc2782) records and sets the service `_name_` (1.9.13). In order for this parameter to work, it is necessary to specify the [resolve](#resolve) parameter for the server and specify a hostname without a port number.\\n\\nIf the service name does not contain a dot (\u201c`.`\u201d), then the [RFC](https://tools.ietf.org/html/rfc2782)\\\\-compliant name is constructed and the TCP protocol is added to the service prefix. For example, to look up the `_http._tcp.backend.example.com` SRV record, it is necessary to specify the directive:\\n\\n> server backend.example.com service=http resolve;\\n\\nIf the service name contains one or more dots, then the name is constructed by joining the service prefix and the server name. For example, to look up the `_http._tcp.backend.example.com` and `server1.backend.example.com` SRV records, it is necessary to specify the directives:\\n\\n> server backend.example.com service=\\\\_http.\\\\_tcp resolve;\\n> server example.com service=server1.backend resolve;\\n\\nHighest-priority SRV records (records with the same lowest-number priority value) are resolved as primary servers, the rest of SRV records are resolved as backup servers. If the [backup](#backup) parameter is specified for the server, high-priority SRV records are resolved as backup servers, the rest of SRV records are ignored.\\n\\n`slow_start`\\\\=`_time_`\\n\\nsets the `_time_` during which the server will recover its weight from zero to a nominal value, when unhealthy server becomes [healthy](ngx_http_upstream_hc_module.html#health_check), or when the server becomes available after a period of time it was considered [unavailable](#fail_timeout). Default value is zero, i.e. slow start is disabled.\\n\\n> The parameter cannot be used along with the [hash](#hash), [ip\\\\_hash](#ip_hash), and [random](#random) load balancing methods.\\n\\n`drain`\\n\\nputs the server into the \u201cdraining\u201d mode (1.13.6). In this mode, only requests [bound](#sticky) to the server will be proxied to it.\\n\\n> Prior to version 1.13.6, the parameter could be changed only with the [API](ngx_http_api_module.html) module.\\n\\n\\nIf there is only a single server in a group, `max_fails`, `fail_timeout` and `slow_start` parameters are ignored, and such a server will never be considered unavailable.\\n"},{"m":"ngx_http_upstream_module","n":"zone","d":"Defines the `_name_` and `_size_` of the shared memory zone that keeps the group\u2019s configuration and run-time state that are shared between worker processes. Several groups may share the same zone. In this case, it is enough to specify the `_size_` only once.\\nAdditionally, as part of our [commercial subscription](http://nginx.com/products/), such groups allow changing the group membership or modifying the settings of a particular server without the need of restarting nginx. The configuration is accessible via the [API](ngx_http_api_module.html) module (1.13.3).\\nPrior to version 1.13.3, the configuration was accessible only via a special location handled by [upstream\\\\_conf](ngx_http_upstream_conf_module.html#upstream_conf).\\n"},{"m":"ngx_http_upstream_module","n":"state","d":"Specifies a `_file_` that keeps the state of the dynamically configurable group.\\nExamples:\\n```\\nstate /var/lib/nginx/state/servers.conf; # path for Linux\\nstate /var/db/nginx/state/servers.conf;  # path for FreeBSD\\n\\n```\\n\\nThe state is currently limited to the list of servers with their parameters. The file is read when parsing the configuration and is updated each time the upstream configuration is [changed](ngx_http_api_module.html#http_upstreams_http_upstream_name_servers_). Changing the file content directly should be avoided. The directive cannot be used along with the [server](#server) directive.\\n\\nChanges made during [configuration reload](../control.html#reconfiguration) or [binary upgrade](../control.html#upgrade) can be lost.\\n\\n\\nThis directive is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_upstream_module","n":"hash","d":"Specifies a load balancing method for a server group where the client-server mapping is based on the hashed `_key_` value. The `_key_` can contain text, variables, and their combinations. Note that adding or removing a server from the group may result in remapping most of the keys to different servers. The method is compatible with the [Cache::Memcached](https://metacpan.org/pod/Cache::Memcached) Perl library.\\nIf the `consistent` parameter is specified, the [ketama](https://www.metabrew.com/article/libketama-consistent-hashing-algo-memcached-clients) consistent hashing method will be used instead. The method ensures that only a few keys will be remapped to different servers when a server is added to or removed from the group. This helps to achieve a higher cache hit ratio for caching servers. The method is compatible with the [Cache::Memcached::Fast](https://metacpan.org/pod/Cache::Memcached::Fast) Perl library with the `_ketama_points_` parameter set to 160."},{"m":"ngx_http_upstream_module","n":"ip_hash","d":"Specifies that a group should use a load balancing method where requests are distributed between servers based on client IP addresses. The first three octets of the client IPv4 address, or the entire IPv6 address, are used as a hashing key. The method ensures that requests from the same client will always be passed to the same server except when this server is unavailable. In the latter case client requests will be passed to another server. Most probably, it will always be the same server as well.\\nIPv6 addresses are supported starting from versions 1.3.2 and 1.2.2.\\n\\nIf one of the servers needs to be temporarily removed, it should be marked with the `down` parameter in order to preserve the current hashing of client IP addresses.\\nExample:\\n```\\nupstream backend {\\n    ip_hash;\\n\\n    server backend1.example.com;\\n    server backend2.example.com;\\n    server backend3.example.com down;\\n    server backend4.example.com;\\n}\\n\\n```\\n\\n\\nUntil versions 1.3.1 and 1.2.2, it was not possible to specify a weight for servers using the `ip_hash` load balancing method.\\n"},{"m":"ngx_http_upstream_module","n":"keepalive","d":"Activates the cache for connections to upstream servers.\\nThe `_connections_` parameter sets the maximum number of idle keepalive connections to upstream servers that are preserved in the cache of each worker process. When this number is exceeded, the least recently used connections are closed.\\nIt should be particularly noted that the `keepalive` directive does not limit the total number of connections to upstream servers that an nginx worker process can open. The `_connections_` parameter should be set to a number small enough to let upstream servers process new incoming connections as well.\\n\\nWhen using load balancing methods other than the default round-robin method, it is necessary to activate them before the `keepalive` directive.\\n\\nExample configuration of memcached upstream with keepalive connections:\\n```\\nupstream memcached_backend {\\n    server 127.0.0.1:11211;\\n    server 10.0.0.2:11211;\\n\\n    keepalive 32;\\n}\\n\\nserver {\\n    ...\\n\\n    location /memcached/ {\\n        set $memcached_key $uri;\\n        memcached_pass memcached_backend;\\n    }\\n\\n}\\n\\n```\\n\\nFor HTTP, the [proxy\\\\_http\\\\_version](ngx_http_proxy_module.html#proxy_http_version) directive should be set to \u201c`1.1`\u201d and the \u201cConnection\u201d header field should be cleared:\\n```\\nupstream http_backend {\\n    server 127.0.0.1:8080;\\n\\n    keepalive 16;\\n}\\n\\nserver {\\n    ...\\n\\n    location /http/ {\\n        proxy_pass http://http_backend;\\n        proxy_http_version 1.1;\\n        proxy_set_header Connection \\"\\";\\n        ...\\n    }\\n}\\n\\n```\\n\\n\\nAlternatively, HTTP/1.0 persistent connections can be used by passing the \u201cConnection: Keep-Alive\u201d header field to an upstream server, though this method is not recommended.\\n\\nFor FastCGI servers, it is required to set [fastcgi\\\\_keep\\\\_conn](ngx_http_fastcgi_module.html#fastcgi_keep_conn) for keepalive connections to work:\\n```\\nupstream fastcgi_backend {\\n    server 127.0.0.1:9000;\\n\\n    keepalive 8;\\n}\\n\\nserver {\\n    ...\\n\\n    location /fastcgi/ {\\n        fastcgi_pass fastcgi_backend;\\n        fastcgi_keep_conn on;\\n        ...\\n    }\\n}\\n\\n```\\n\\n\\nSCGI and uwsgi protocols do not have a notion of keepalive connections.\\n"},{"m":"ngx_http_upstream_module","n":"keepalive_requests","d":"Sets the maximum number of requests that can be served through one keepalive connection. After the maximum number of requests is made, the connection is closed.\\nClosing connections periodically is necessary to free per-connection memory allocations. Therefore, using too high maximum number of requests could result in excessive memory usage and not recommended."},{"m":"ngx_http_upstream_module","n":"keepalive_timeout","d":"Sets a timeout during which an idle keepalive connection to an upstream server will stay open."},{"m":"ngx_http_upstream_module","n":"ntlm","d":"Allows proxying requests with [NTLM Authentication](https://en.wikipedia.org/wiki/Integrated_Windows_Authentication). The upstream connection is bound to the client connection once the client sends a request with the \u201cAuthorization\u201d header field value starting with \u201c`Negotiate`\u201d or \u201c`NTLM`\u201d. Further client requests will be proxied through the same upstream connection, keeping the authentication context.\\nIn order for NTLM authentication to work, it is necessary to enable keepalive connections to upstream servers. The [proxy\\\\_http\\\\_version](ngx_http_proxy_module.html#proxy_http_version) directive should be set to \u201c`1.1`\u201d and the \u201cConnection\u201d header field should be cleared:\\n```\\nupstream http_backend {\\n    server 127.0.0.1:8080;\\n\\n    ntlm;\\n}\\n\\nserver {\\n    ...\\n\\n    location /http/ {\\n        proxy_pass http://http_backend;\\n        proxy_http_version 1.1;\\n        proxy_set_header Connection \\"\\";\\n        ...\\n    }\\n}\\n\\n```\\n\\n\\nWhen using load balancer methods other than the default round-robin method, it is necessary to activate them before the `ntlm` directive.\\n\\n\\nThis directive is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_upstream_module","n":"least_conn","d":"Specifies that a group should use a load balancing method where a request is passed to the server with the least number of active connections, taking into account weights of servers. If there are several such servers, they are tried in turn using a weighted round-robin balancing method."},{"m":"ngx_http_upstream_module","n":"least_time","d":"Specifies that a group should use a load balancing method where a request is passed to the server with the least average response time and least number of active connections, taking into account weights of servers. If there are several such servers, they are tried in turn using a weighted round-robin balancing method.\\nIf the `header` parameter is specified, time to receive the [response header](#var_upstream_header_time) is used. If the `last_byte` parameter is specified, time to receive the [full response](#var_upstream_response_time) is used. If the `inflight` parameter is specified (1.11.6), incomplete requests are also taken into account.\\nPrior to version 1.11.6, incomplete requests were taken into account by default.\\n\\n\\nThis directive is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_upstream_module","n":"queue","d":"If an upstream server cannot be selected immediately while processing a request, the request will be placed into the queue. The directive specifies the maximum `_number_` of requests that can be in the queue at the same time. If the queue is filled up, or the server to pass the request to cannot be selected within the time period specified in the `timeout` parameter, the 502 (Bad Gateway) error will be returned to the client.\\nThe default value of the `timeout` parameter is 60 seconds.\\n\\nWhen using load balancer methods other than the default round-robin method, it is necessary to activate them before the `queue` directive.\\n\\nThis directive is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_upstream_module","n":"random","d":"Specifies that a group should use a load balancing method where a request is passed to a randomly selected server, taking into account weights of servers.\\nThe optional `two` parameter instructs nginx to randomly select [two](https://homes.cs.washington.edu/~karlin/papers/balls.pdf) servers and then choose a server using the specified `method`. The default method is `least_conn` which passes a request to a server with the least number of active connections."},{"m":"ngx_http_upstream_module","n":"random_least_time","d":"The `least_time` method passes a request to a server with the least average response time and least number of active connections. If `least_time=header` is specified, the time to receive the [response header](#var_upstream_header_time) is used. If `least_time=last_byte` is specified, the time to receive the [full response](#var_upstream_response_time) is used.\\nThe `least_time` method is available as a part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_upstream_module","n":"resolver","d":"Configures name servers used to resolve names of upstream servers into addresses, for example:\\n```\\nresolver 127.0.0.1 [::1]:5353;\\n\\n```\\nThe address can be specified as a domain name or IP address, with an optional port. If port is not specified, the port 53 is used. Name servers are queried in a round-robin fashion."},{"m":"ngx_http_upstream_module","n":"resolver_ipv6","d":"By default, nginx will look up both IPv4 and IPv6 addresses while resolving. If looking up of IPv6 addresses is not desired, the `ipv6=off` parameter can be specified."},{"m":"ngx_http_upstream_module","n":"resolver_valid","d":"By default, nginx caches answers using the TTL value of a response. An optional `valid` parameter allows overriding it:\\n```\\nresolver 127.0.0.1 [::1]:5353 valid=30s;\\n\\n```\\n\\nTo prevent DNS spoofing, it is recommended configuring DNS servers in a properly secured trusted local network.\\n"},{"m":"ngx_http_upstream_module","n":"resolver_status_zone","d":"The optional `status_zone` parameter enables [collection](ngx_http_api_module.html#resolvers_) of DNS server statistics of requests and responses in the specified `_zone_`.\\n\\nThis directive is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_upstream_module","n":"resolver_timeout","d":"Sets a timeout for name resolution, for example:\\n```\\nresolver_timeout 5s;\\n\\n```\\n\\n\\nThis directive is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_upstream_module","n":"sticky","d":"Enables session affinity, which causes requests from the same client to be passed to the same server in a group of servers. Three methods are available:\\n`cookie`\\n\\nWhen the `cookie` method is used, information about the designated server is passed in an HTTP cookie generated by nginx:\\n\\n> upstream backend {\\n>     server backend1.example.com;\\n>     server backend2.example.com;\\n> \\n>     sticky cookie srv\\\\_id expires=1h domain=.example.com path=/;\\n> }\\n\\nA request that comes from a client not yet bound to a particular server is passed to the server selected by the configured balancing method. Further requests with this cookie will be passed to the designated server. If the designated server cannot process a request, the new server is selected as if the client has not been bound yet.\\n\\nThe first parameter sets the name of the cookie to be set or inspected. The cookie value is a hexadecimal representation of the MD5 hash of the IP address and port, or of the UNIX-domain socket path. However, if the \u201c`route`\u201d parameter of the [server](#server) directive is specified, the cookie value will be the value of the \u201c`route`\u201d parameter:\\n\\n> upstream backend {\\n>     server backend1.example.com route=**a**;\\n>     server backend2.example.com route=**b**;\\n> \\n>     sticky cookie srv\\\\_id expires=1h domain=.example.com path=/;\\n> }\\n\\nIn this case, the value of the \u201c`srv_id`\u201d cookie will be either `_a_` or `_b_`.\\n\\nAdditional parameters may be as follows:\\n\\n`expires=``_time_`\\n\\nSets the `_time_` for which a browser should keep the cookie. The special value `max` will cause the cookie to expire on \u201c`31 Dec 2037 23:55:55 GMT`\u201d. If the parameter is not specified, it will cause the cookie to expire at the end of a browser session.\\n\\n`domain=``_domain_`\\n\\nDefines the `_domain_` for which the cookie is set. Parameter value can contain variables (1.11.5).\\n\\n`httponly`\\n\\nAdds the `HttpOnly` attribute to the cookie (1.7.11).\\n\\n`samesite=``strict` | `lax` | `none`\\n\\nAdds the `SameSite` attribute to the cookie with one of the following values (1.19.4): `Strict`, `Lax`, or `None`.\\n\\n`secure`\\n\\nAdds the `Secure` attribute to the cookie (1.7.11).\\n\\n`path=``_path_`\\n\\nDefines the `_path_` for which the cookie is set.\\n\\nIf any parameters are omitted, the corresponding cookie fields are not set.\\n\\n`route`\\n\\nWhen the `route` method is used, proxied server assigns client a route on receipt of the first request. All subsequent requests from this client will carry routing information in a cookie or URI. This information is compared with the \u201c`route`\u201d parameter of the [server](#server) directive to identify the server to which the request should be proxied. If the \u201c`route`\u201d parameter is not specified, the route name will be a hexadecimal representation of the MD5 hash of the IP address and port, or of the UNIX-domain socket path. If the designated server cannot process a request, the new server is selected by the configured balancing method as if there is no routing information in the request.\\n\\nThe parameters of the `route` method specify variables that may contain routing information. The first non-empty variable is used to find the matching server.\\n\\nExample:\\n\\n> map $cookie\\\\_jsessionid $route\\\\_cookie {\\n>     ~.+\\\\\\\\.(?P<route>\\\\\\\\w+)$ $route;\\n> }\\n> \\n> map $request\\\\_uri $route\\\\_uri {\\n>     ~jsessionid=.+\\\\\\\\.(?P<route>\\\\\\\\w+)$ $route;\\n> }\\n> \\n> upstream backend {\\n>     server backend1.example.com route=a;\\n>     server backend2.example.com route=b;\\n> \\n>     sticky route $route\\\\_cookie $route\\\\_uri;\\n> }\\n\\nHere, the route is taken from the \u201c`JSESSIONID`\u201d cookie if present in a request. Otherwise, the route from the URI is used.\\n\\n`learn`\\n\\nWhen the `learn` method (1.7.1) is used, nginx analyzes upstream server responses and learns server-initiated sessions usually passed in an HTTP cookie.\\n\\n> upstream backend {\\n>    server backend1.example.com:8080;\\n>    server backend2.example.com:8081;\\n> \\n>    sticky learn\\n>           create=$upstream\\\\_cookie\\\\_examplecookie\\n>           lookup=$cookie\\\\_examplecookie\\n>           zone=client\\\\_sessions:1m;\\n> }\\n\\nIn the example, the upstream server creates a session by setting the cookie \u201c`EXAMPLECOOKIE`\u201d in the response. Further requests with this cookie will be passed to the same server. If the server cannot process the request, the new server is selected as if the client has not been bound yet.\\n\\nThe parameters `create` and `lookup` specify variables that indicate how new sessions are created and existing sessions are searched, respectively. Both parameters may be specified more than once, in which case the first non-empty variable is used.\\n\\nSessions are stored in a shared memory zone, whose `_name_` and `_size_` are configured by the `zone` parameter. One megabyte zone can store about 4000 sessions on the 64-bit platform. The sessions that are not accessed during the time specified by the `timeout` parameter get removed from the zone. By default, `timeout` is set to 10 minutes.\\n\\nThe `header` parameter (1.13.1) allows creating a session right after receiving response headers from the upstream server.\\n\\nThe `sync` parameter (1.13.8) enables [synchronization](../stream/ngx_stream_zone_sync_module.html#zone_sync) of the shared memory zone.\\n\\n\\nThis directive is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_upstream_module","n":"sticky_cookie_insert","d":"This directive is obsolete since version 1.5.7. An equivalent [sticky](#sticky) directive with a new syntax should be used instead:\\n`sticky cookie` `_name_` \\\\[`expires=``_time_`\\\\] \\\\[`domain=``_domain_`\\\\] \\\\[`path=``_path_`\\\\];\\n"},{"m":"ngx_http_upstream_module","n":"$upstream_addr","d":"keeps fields from the end of the response obtained from the upstream server (1.13.10)."},{"m":"ngx_http_upstream_module","n":"$upstream_bytes_received","d":"keeps fields from the end of the response obtained from the upstream server (1.13.10)."},{"m":"ngx_http_upstream_module","n":"$upstream_bytes_sent","d":"keeps fields from the end of the response obtained from the upstream server (1.13.10)."},{"m":"ngx_http_upstream_module","n":"$upstream_cache_status\\n","d":"keeps fields from the end of the response obtained from the upstream server (1.13.10)."},{"m":"ngx_http_upstream_module","n":"$upstream_connect_time\\n","d":"keeps fields from the end of the response obtained from the upstream server (1.13.10)."},{"m":"ngx_http_upstream_module","n":"$upstream_cookie_name\\n","d":"keeps fields from the end of the response obtained from the upstream server (1.13.10)."},{"m":"ngx_http_upstream_module","n":"$upstream_header_time\\n","d":"keeps fields from the end of the response obtained from the upstream server (1.13.10)."},{"m":"ngx_http_upstream_module","n":"$upstream_http_name","d":"keeps fields from the end of the response obtained from the upstream server (1.13.10)."},{"m":"ngx_http_upstream_module","n":"$upstream_queue_time","d":"keeps fields from the end of the response obtained from the upstream server (1.13.10)."},{"m":"ngx_http_upstream_module","n":"$upstream_response_length\\n","d":"keeps fields from the end of the response obtained from the upstream server (1.13.10)."},{"m":"ngx_http_upstream_module","n":"$upstream_response_time\\n","d":"keeps fields from the end of the response obtained from the upstream server (1.13.10)."},{"m":"ngx_http_upstream_module","n":"$upstream_status","d":"keeps fields from the end of the response obtained from the upstream server (1.13.10)."},{"m":"ngx_http_upstream_module","n":"$upstream_trailer_name","d":"keeps fields from the end of the response obtained from the upstream server (1.13.10)."},{"m":"ngx_http_upstream_conf_module","n":"summary","d":"The `ngx_http_upstream_conf_module` module allows configuring upstream server groups on-the-fly via a simple HTTP interface without the need of restarting nginx. The [http](ngx_http_upstream_module.html#zone) or [stream](../stream/ngx_stream_upstream_module.html#zone) server group must reside in the shared memory.\\nThis module was available as part of our [commercial subscription](http://nginx.com/products/) until 1.13.10. It was superseded by the [ngx\\\\_http\\\\_api\\\\_module](ngx_http_api_module.html) module in 1.13.3.\\n"},{"m":"ngx_http_upstream_hc_module","n":"summary","d":"The `ngx_http_upstream_hc_module` module allows enabling periodic health checks of the servers in a [group](ngx_http_upstream_module.html#upstream) referenced in the surrounding location. The server group must reside in the [shared memory](ngx_http_upstream_module.html#zone).\\nIf a health check fails, the server will be considered unhealthy. If several health checks are defined for the same group of servers, a single failure of any check will make the corresponding server be considered unhealthy. Client requests are not passed to unhealthy servers and servers in the \u201cchecking\u201d state.\\n\\nPlease note that most of the variables will have empty values when used with health checks.\\n\\n\\nThis module is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_upstream_hc_module","n":"health_check","d":"Enables periodic health checks of the servers in a [group](ngx_http_upstream_module.html#upstream) referenced in the surrounding location.\\nThe following optional parameters are supported:\\n`interval`\\\\=`_time_`\\n\\nsets the interval between two consecutive health checks, by default, 5 seconds.\\n\\n`jitter`\\\\=`_time_`\\n\\nsets the time within which each health check will be randomly delayed, by default, there is no delay.\\n\\n`fails`\\\\=`_number_`\\n\\nsets the number of consecutive failed health checks of a particular server after which this server will be considered unhealthy, by default, 1.\\n\\n`passes`\\\\=`_number_`\\n\\nsets the number of consecutive passed health checks of a particular server after which the server will be considered healthy, by default, 1.\\n\\n`uri`\\\\=`_uri_`\\n\\ndefines the URI used in health check requests, by default, \u201c`/`\u201d.\\n\\n`mandatory`\\n\\nsets the initial \u201cchecking\u201d state for a server until the first health check is completed (1.11.7). Client requests are not passed to servers in the \u201cchecking\u201d state. If the parameter is not specified, the server will be initially considered healthy.\\n\\n`match`\\\\=`_name_`\\n\\nspecifies the `match` block configuring the tests that a response should pass in order for a health check to pass. By default, the response should have status code 2xx or 3xx.\\n\\n`port`\\\\=`_number_`\\n\\ndefines the port used when connecting to a server to perform a health check (1.9.7). By default, equals the [server](ngx_http_upstream_module.html#server) port.\\n\\n`type`\\\\=`grpc` \\\\[`grpc_service`\\\\=`_name_`\\\\] \\\\[`grpc_status`\\\\=`_code_`\\\\]\\n\\nenables periodic [health checks](https://github.com/grpc/grpc/blob/master/doc/health-checking.md#grpc-health-checking-protocol) of a gRPC server or a particular gRPC service specified with the optional `grpc_service` parameter (1.19.5). If the server does not support the gRPC Health Checking Protocol, the optional `grpc_status` parameter can be used to specify non-zero gRPC [status](https://github.com/grpc/grpc/blob/master/doc/statuscodes.md#status-codes-and-their-use-in-grpc) (for example, status code \u201c`12`\u201d / \u201c`UNIMPLEMENTED`\u201d) that will be treated as healthy:\\n\\n> health\\\\_check mandatory type=grpc grpc\\\\_status=12;\\n\\nThe `type`\\\\=`grpc` parameter must be specified after all other directive parameters, `grpc_service` and `grpc_status` must follow `type`\\\\=`grpc`. The parameter is not compatible with [`uri`](#health_check_uri) or [`match`](#health_check_match) parameters.\\n"},{"m":"ngx_http_userid_module","n":"summary","d":"The `ngx_http_userid_module` module sets cookies suitable for client identification. Received and set cookies can be logged using the embedded variables [$uid\\\\_got](#var_uid_got) and [$uid\\\\_set](#var_uid_set). This module is compatible with the [mod\\\\_uid](http://www.lexa.ru/programs/mod-uid-eng.html) module for Apache."},{"m":"ngx_http_userid_module","n":"userid","d":"Enables or disables setting cookies and logging the received cookies:\\n`on`\\n\\nenables the setting of version 2 cookies and logging of the received cookies;\\n\\n`v1`\\n\\nenables the setting of version 1 cookies and logging of the received cookies;\\n\\n`log`\\n\\ndisables the setting of cookies, but enables logging of the received cookies;\\n\\n`off`\\n\\ndisables the setting of cookies and logging of the received cookies.\\n"},{"m":"ngx_http_userid_module","n":"userid_domain","d":"Defines a domain for which the cookie is set. The `none` parameter disables setting of a domain for the cookie."},{"m":"ngx_http_userid_module","n":"userid_expires","d":"Sets a time during which a browser should keep the cookie. The parameter `max` will cause the cookie to expire on \u201c`31 Dec 2037 23:55:55 GMT`\u201d. The parameter `off` will cause the cookie to expire at the end of a browser session."},{"m":"ngx_http_userid_module","n":"userid_flags","d":"If the parameter is not `off`, defines one or more additional flags for the cookie: `secure`, `httponly`, `samesite=strict`, `samesite=lax`, `samesite=none`."},{"m":"ngx_http_userid_module","n":"userid_mark","d":"If the parameter is not `off`, enables the cookie marking mechanism and sets the character used as a mark. This mechanism is used to add or change [userid\\\\_p3p](#userid_p3p) and/or a cookie expiration time while preserving the client identifier. A mark can be any letter of the English alphabet (case-sensitive), digit, or the \u201c`=`\u201d character.\\nIf the mark is set, it is compared with the first padding symbol in the base64 representation of the client identifier passed in a cookie. If they do not match, the cookie is resent with the specified mark, expiration time, and \u201cP3P\u201d header."},{"m":"ngx_http_userid_module","n":"userid_name","d":"Sets the cookie name."},{"m":"ngx_http_userid_module","n":"userid_p3p","d":"Sets a value for the \u201cP3P\u201d header field that will be sent along with the cookie. If the directive is set to the special value `none`, the \u201cP3P\u201d header will not be sent in a response."},{"m":"ngx_http_userid_module","n":"userid_path","d":"Defines a path for which the cookie is set."},{"m":"ngx_http_userid_module","n":"userid_service","d":"If identifiers are issued by multiple servers (services), each service should be assigned its own `_number_` to ensure that client identifiers are unique. For version 1 cookies, the default value is zero. For version 2 cookies, the default value is the number composed from the last four octets of the server\u2019s IP address."},{"m":"ngx_http_userid_module","n":"$uid_got","d":"The cookie name and sent client identifier."},{"m":"ngx_http_userid_module","n":"$uid_reset","d":"The cookie name and sent client identifier."},{"m":"ngx_http_userid_module","n":"$uid_set","d":"The cookie name and sent client identifier."},{"m":"ngx_http_uwsgi_module","n":"summary","d":"The `ngx_http_uwsgi_module` module allows passing requests to a uwsgi server."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_bind","d":"Makes outgoing connections to a uwsgi server originate from the specified local IP address with an optional port (1.11.2). Parameter value can contain variables (1.3.12). The special value `off` (1.3.12) cancels the effect of the `uwsgi_bind` directive inherited from the previous configuration level, which allows the system to auto-assign the local IP address and port."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_bind_transparent","d":"The `transparent` parameter (1.11.0) allows outgoing connections to a uwsgi server originate from a non-local IP address, for example, from a real IP address of a client:\\n```\\nuwsgi_bind $remote_addr transparent;\\n\\n```\\nIn order for this parameter to work, it is usually necessary to run nginx worker processes with the [superuser](../ngx_core_module.html#user) privileges. On Linux it is not required (1.13.8) as if the `transparent` parameter is specified, worker processes inherit the `CAP_NET_RAW` capability from the master process. It is also necessary to configure kernel routing table to intercept network traffic from the uwsgi server."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_buffer_size","d":"Sets the `_size_` of the buffer used for reading the first part of the response received from the uwsgi server. This part usually contains a small response header. By default, the buffer size is equal to one memory page. This is either 4K or 8K, depending on a platform. It can be made smaller, however."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_buffering","d":"Enables or disables buffering of responses from the uwsgi server.\\nWhen buffering is enabled, nginx receives a response from the uwsgi server as soon as possible, saving it into the buffers set by the [uwsgi\\\\_buffer\\\\_size](#uwsgi_buffer_size) and [uwsgi\\\\_buffers](#uwsgi_buffers) directives. If the whole response does not fit into memory, a part of it can be saved to a [temporary file](#uwsgi_temp_path) on the disk. Writing to temporary files is controlled by the [uwsgi\\\\_max\\\\_temp\\\\_file\\\\_size](#uwsgi_max_temp_file_size) and [uwsgi\\\\_temp\\\\_file\\\\_write\\\\_size](#uwsgi_temp_file_write_size) directives.\\nWhen buffering is disabled, the response is passed to a client synchronously, immediately as it is received. nginx will not try to read the whole response from the uwsgi server. The maximum size of the data that nginx can receive from the server at a time is set by the [uwsgi\\\\_buffer\\\\_size](#uwsgi_buffer_size) directive.\\nBuffering can also be enabled or disabled by passing \u201c`yes`\u201d or \u201c`no`\u201d in the \u201cX-Accel-Buffering\u201d response header field. This capability can be disabled using the [uwsgi\\\\_ignore\\\\_headers](#uwsgi_ignore_headers) directive."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_buffers","d":"Sets the `_number_` and `_size_` of the buffers used for reading a response from the uwsgi server, for a single connection. By default, the buffer size is equal to one memory page. This is either 4K or 8K, depending on a platform."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_busy_buffers_size","d":"When [buffering](#uwsgi_buffering) of responses from the uwsgi server is enabled, limits the total `_size_` of buffers that can be busy sending a response to the client while the response is not yet fully read. In the meantime, the rest of the buffers can be used for reading the response and, if needed, buffering part of the response to a temporary file. By default, `_size_` is limited by the size of two buffers set by the [uwsgi\\\\_buffer\\\\_size](#uwsgi_buffer_size) and [uwsgi\\\\_buffers](#uwsgi_buffers) directives."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_cache","d":"Defines a shared memory zone used for caching. The same zone can be used in several places. Parameter value can contain variables (1.7.9). The `off` parameter disables caching inherited from the previous configuration level."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_cache_background_update","d":"Allows starting a background subrequest to update an expired cache item, while a stale cached response is returned to the client. Note that it is necessary to [allow](#uwsgi_cache_use_stale_updating) the usage of a stale cached response when it is being updated."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_cache_bypass","d":"Defines conditions under which the response will not be taken from a cache. If at least one value of the string parameters is not empty and is not equal to \u201c0\u201d then the response will not be taken from the cache:\\n```\\nuwsgi_cache_bypass $cookie_nocache $arg_nocache$arg_comment;\\nuwsgi_cache_bypass $http_pragma    $http_authorization;\\n\\n```\\nCan be used along with the [uwsgi\\\\_no\\\\_cache](#uwsgi_no_cache) directive."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_cache_key","d":"Defines a key for caching, for example\\n```\\nuwsgi_cache_key localhost:9000$request_uri;\\n\\n```\\n"},{"m":"ngx_http_uwsgi_module","n":"uwsgi_cache_lock","d":"When enabled, only one request at a time will be allowed to populate a new cache element identified according to the [uwsgi\\\\_cache\\\\_key](#uwsgi_cache_key) directive by passing a request to a uwsgi server. Other requests of the same cache element will either wait for a response to appear in the cache or the cache lock for this element to be released, up to the time set by the [uwsgi\\\\_cache\\\\_lock\\\\_timeout](#uwsgi_cache_lock_timeout) directive."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_cache_lock_age","d":"If the last request passed to the uwsgi server for populating a new cache element has not completed for the specified `_time_`, one more request may be passed to the uwsgi server."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_cache_lock_timeout","d":"Sets a timeout for [uwsgi\\\\_cache\\\\_lock](#uwsgi_cache_lock). When the `_time_` expires, the request will be passed to the uwsgi server, however, the response will not be cached.\\nBefore 1.7.8, the response could be cached.\\n"},{"m":"ngx_http_uwsgi_module","n":"uwsgi_cache_max_range_offset","d":"Sets an offset in bytes for byte-range requests. If the range is beyond the offset, the range request will be passed to the uwsgi server and the response will not be cached."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_cache_methods","d":"If the client request method is listed in this directive then the response will be cached. \u201c`GET`\u201d and \u201c`HEAD`\u201d methods are always added to the list, though it is recommended to specify them explicitly. See also the [uwsgi\\\\_no\\\\_cache](#uwsgi_no_cache) directive."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_cache_min_uses","d":"Sets the `_number_` of requests after which the response will be cached."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_cache_path","d":"Sets the path and other parameters of a cache. Cache data are stored in files. The file name in a cache is a result of applying the MD5 function to the [cache key](#uwsgi_cache_key). The `levels` parameter defines hierarchy levels of a cache: from 1 to 3, each level accepts values 1 or 2. For example, in the following configuration\\n```\\nuwsgi_cache_path /data/nginx/cache levels=1:2 keys_zone=one:10m;\\n\\n```\\nfile names in a cache will look like this:\\n```\\n/data/nginx/cache/c/29/b7f54b2df7773722d382f4809d65029c\\n\\n```\\n\\nA cached response is first written to a temporary file, and then the file is renamed. Starting from version 0.8.9, temporary files and the cache can be put on different file systems. However, be aware that in this case a file is copied across two file systems instead of the cheap renaming operation. It is thus recommended that for any given location both cache and a directory holding temporary files are put on the same file system. A directory for temporary files is set based on the `use_temp_path` parameter (1.7.10). If this parameter is omitted or set to the value `on`, the directory set by the [uwsgi\\\\_temp\\\\_path](#uwsgi_temp_path) directive for the given location will be used. If the value is set to `off`, temporary files will be put directly in the cache directory.\\nIn addition, all active keys and information about data are stored in a shared memory zone, whose `_name_` and `_size_` are configured by the `keys_zone` parameter. One megabyte zone can store about 8 thousand keys.\\nAs part of [commercial subscription](http://nginx.com/products/), the shared memory zone also stores extended cache [information](ngx_http_api_module.html#http_caches_), thus, it is required to specify a larger zone size for the same number of keys. For example, one megabyte zone can store about 4 thousand keys.\\n\\nCached data that are not accessed during the time specified by the `inactive` parameter get removed from the cache regardless of their freshness. By default, `inactive` is set to 10 minutes."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_cache_path_max_size","d":"The special \u201ccache manager\u201d process monitors the maximum cache size set by the `max_size` parameter, and the minimum amount of free space set by the `min_free` (1.19.1) parameter on the file system with cache. When the size is exceeded or there is not enough free space, it removes the least recently used data. The data is removed in iterations configured by `manager_files`, `manager_threshold`, and `manager_sleep` parameters (1.11.5). During one iteration no more than `manager_files` items are deleted (by default, 100). The duration of one iteration is limited by the `manager_threshold` parameter (by default, 200 milliseconds). Between iterations, a pause configured by the `manager_sleep` parameter (by default, 50 milliseconds) is made.\\nA minute after the start the special \u201ccache loader\u201d process is activated. It loads information about previously cached data stored on file system into a cache zone. The loading is also done in iterations. During one iteration no more than `loader_files` items are loaded (by default, 100). Besides, the duration of one iteration is limited by the `loader_threshold` parameter (by default, 200 milliseconds). Between iterations, a pause configured by the `loader_sleep` parameter (by default, 50 milliseconds) is made.\\nAdditionally, the following parameters are available as part of our [commercial subscription](http://nginx.com/products/):\\n\\n`purger`\\\\=`on`|`off`\\n\\nInstructs whether cache entries that match a [wildcard key](#uwsgi_cache_purge) will be removed from the disk by the cache purger (1.7.12). Setting the parameter to `on` (default is `off`) will activate the \u201ccache purger\u201d process that permanently iterates through all cache entries and deletes the entries that match the wildcard key.\\n\\n`purger_files`\\\\=`_number_`\\n\\nSets the number of items that will be scanned during one iteration (1.7.12). By default, `purger_files` is set to 10.\\n\\n`purger_threshold`\\\\=`_number_`\\n\\nSets the duration of one iteration (1.7.12). By default, `purger_threshold` is set to 50 milliseconds.\\n\\n`purger_sleep`\\\\=`_number_`\\n\\nSets a pause between iterations (1.7.12). By default, `purger_sleep` is set to 50 milliseconds.\\n\\n\\nIn versions 1.7.3, 1.7.7, and 1.11.10 cache header format has been changed. Previously cached responses will be considered invalid after upgrading to a newer nginx version.\\n"},{"m":"ngx_http_uwsgi_module","n":"uwsgi_cache_purge","d":"Defines conditions under which the request will be considered a cache purge request. If at least one value of the string parameters is not empty and is not equal to \u201c0\u201d then the cache entry with a corresponding [cache key](#uwsgi_cache_key) is removed. The result of successful operation is indicated by returning the 204 (No Content) response.\\nIf the [cache key](#uwsgi_cache_key) of a purge request ends with an asterisk (\u201c`*`\u201d), all cache entries matching the wildcard key will be removed from the cache. However, these entries will remain on the disk until they are deleted for either [inactivity](#uwsgi_cache_path), or processed by the [cache purger](#purger) (1.7.12), or a client attempts to access them.\\nExample configuration:\\n```\\nuwsgi_cache_path /data/nginx/cache keys_zone=cache_zone:10m;\\n\\nmap $request_method $purge_method {\\n    PURGE   1;\\n    default 0;\\n}\\n\\nserver {\\n    ...\\n    location / {\\n        uwsgi_pass        backend;\\n        uwsgi_cache       cache_zone;\\n        uwsgi_cache_key   $uri;\\n        uwsgi_cache_purge $purge_method;\\n    }\\n}\\n\\n```\\n\\nThis functionality is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_http_uwsgi_module","n":"uwsgi_cache_revalidate","d":"Enables revalidation of expired cache items using conditional requests with the \u201cIf-Modified-Since\u201d and \u201cIf-None-Match\u201d header fields."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_cache_use_stale","d":"Determines in which cases a stale cached response can be used when an error occurs during communication with the uwsgi server. The directive\u2019s parameters match the parameters of the [uwsgi\\\\_next\\\\_upstream](#uwsgi_next_upstream) directive.\\nThe `error` parameter also permits using a stale cached response if a uwsgi server to process a request cannot be selected."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_cache_use_stale_updating","d":"Additionally, the `updating` parameter permits using a stale cached response if it is currently being updated. This allows minimizing the number of accesses to uwsgi servers when updating cached data.\\nUsing a stale cached response can also be enabled directly in the response header for a specified number of seconds after the response became stale (1.11.10). This has lower priority than using the directive parameters.\\n*   The \u201c[stale-while-revalidate](https://tools.ietf.org/html/rfc5861#section-3)\u201d extension of the \u201cCache-Control\u201d header field permits using a stale cached response if it is currently being updated.\\n*   The \u201c[stale-if-error](https://tools.ietf.org/html/rfc5861#section-4)\u201d extension of the \u201cCache-Control\u201d header field permits using a stale cached response in case of an error.\\n\\nTo minimize the number of accesses to uwsgi servers when populating a new cache element, the [uwsgi\\\\_cache\\\\_lock](#uwsgi_cache_lock) directive can be used."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_cache_valid","d":"Sets caching time for different response codes. For example, the following directives\\n```\\nuwsgi_cache_valid 200 302 10m;\\nuwsgi_cache_valid 404      1m;\\n\\n```\\nset 10 minutes of caching for responses with codes 200 and 302 and 1 minute for responses with code 404.\\nIf only caching `_time_` is specified\\n```\\nuwsgi_cache_valid 5m;\\n\\n```\\nthen only 200, 301, and 302 responses are cached.\\nIn addition, the `any` parameter can be specified to cache any responses:\\n```\\nuwsgi_cache_valid 200 302 10m;\\nuwsgi_cache_valid 301      1h;\\nuwsgi_cache_valid any      1m;\\n\\n```\\n\\nParameters of caching can also be set directly in the response header. This has higher priority than setting of caching time using the directive.\\n*   The \u201cX-Accel-Expires\u201d header field sets caching time of a response in seconds. The zero value disables caching for a response. If the value starts with the `@` prefix, it sets an absolute time in seconds since Epoch, up to which the response may be cached.\\n*   If the header does not include the \u201cX-Accel-Expires\u201d field, parameters of caching may be set in the header fields \u201cExpires\u201d or \u201cCache-Control\u201d.\\n*   If the header includes the \u201cSet-Cookie\u201d field, such a response will not be cached.\\n*   If the header includes the \u201cVary\u201d field with the special value \u201c`*`\u201d, such a response will not be cached (1.7.7). If the header includes the \u201cVary\u201d field with another value, such a response will be cached taking into account the corresponding request header fields (1.7.7).\\nProcessing of one or more of these response header fields can be disabled using the [uwsgi\\\\_ignore\\\\_headers](#uwsgi_ignore_headers) directive."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_connect_timeout","d":"Defines a timeout for establishing a connection with a uwsgi server. It should be noted that this timeout cannot usually exceed 75 seconds."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_force_ranges","d":"Enables byte-range support for both cached and uncached responses from the uwsgi server regardless of the \u201cAccept-Ranges\u201d field in these responses."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_hide_header","d":"By default, nginx does not pass the header fields \u201cStatus\u201d and \u201cX-Accel-...\u201d from the response of a uwsgi server to a client. The `uwsgi_hide_header` directive sets additional fields that will not be passed. If, on the contrary, the passing of fields needs to be permitted, the [uwsgi\\\\_pass\\\\_header](#uwsgi_pass_header) directive can be used."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_ignore_client_abort","d":"Determines whether the connection with a uwsgi server should be closed when a client closes the connection without waiting for a response."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_ignore_headers","d":"Disables processing of certain response header fields from the uwsgi server. The following fields can be ignored: \u201cX-Accel-Redirect\u201d, \u201cX-Accel-Expires\u201d, \u201cX-Accel-Limit-Rate\u201d (1.1.6), \u201cX-Accel-Buffering\u201d (1.1.6), \u201cX-Accel-Charset\u201d (1.1.6), \u201cExpires\u201d, \u201cCache-Control\u201d, \u201cSet-Cookie\u201d (0.8.44), and \u201cVary\u201d (1.7.7).\\nIf not disabled, processing of these header fields has the following effect:\\n*   \u201cX-Accel-Expires\u201d, \u201cExpires\u201d, \u201cCache-Control\u201d, \u201cSet-Cookie\u201d, and \u201cVary\u201d set the parameters of response [caching](#uwsgi_cache_valid);\\n*   \u201cX-Accel-Redirect\u201d performs an [internal redirect](ngx_http_core_module.html#internal) to the specified URI;\\n*   \u201cX-Accel-Limit-Rate\u201d sets the [rate limit](ngx_http_core_module.html#limit_rate) for transmission of a response to a client;\\n*   \u201cX-Accel-Buffering\u201d enables or disables [buffering](#uwsgi_buffering) of a response;\\n*   \u201cX-Accel-Charset\u201d sets the desired [charset](ngx_http_charset_module.html#charset) of a response.\\n"},{"m":"ngx_http_uwsgi_module","n":"uwsgi_intercept_errors","d":"Determines whether a uwsgi server responses with codes greater than or equal to 300 should be passed to a client or be intercepted and redirected to nginx for processing with the [error\\\\_page](ngx_http_core_module.html#error_page) directive."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_limit_rate","d":"Limits the speed of reading the response from the uwsgi server. The `_rate_` is specified in bytes per second. The zero value disables rate limiting. The limit is set per a request, and so if nginx simultaneously opens two connections to the uwsgi server, the overall rate will be twice as much as the specified limit. The limitation works only if [buffering](#uwsgi_buffering) of responses from the uwsgi server is enabled."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_max_temp_file_size","d":"When [buffering](#uwsgi_buffering) of responses from the uwsgi server is enabled, and the whole response does not fit into the buffers set by the [uwsgi\\\\_buffer\\\\_size](#uwsgi_buffer_size) and [uwsgi\\\\_buffers](#uwsgi_buffers) directives, a part of the response can be saved to a temporary file. This directive sets the maximum `_size_` of the temporary file. The size of data written to the temporary file at a time is set by the [uwsgi\\\\_temp\\\\_file\\\\_write\\\\_size](#uwsgi_temp_file_write_size) directive.\\nThe zero value disables buffering of responses to temporary files.\\n\\nThis restriction does not apply to responses that will be [cached](#uwsgi_cache) or [stored](#uwsgi_store) on disk.\\n"},{"m":"ngx_http_uwsgi_module","n":"uwsgi_modifier1","d":"Sets the value of the `modifier1` field in the [uwsgi packet header](http://uwsgi-docs.readthedocs.org/en/latest/Protocol.html#uwsgi-packet-header)."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_modifier2","d":"Sets the value of the `modifier2` field in the [uwsgi packet header](http://uwsgi-docs.readthedocs.org/en/latest/Protocol.html#uwsgi-packet-header)."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_next_upstream","d":"Specifies in which cases a request should be passed to the next server:\\n`error`\\n\\nan error occurred while establishing a connection with the server, passing a request to it, or reading the response header;\\n\\n`timeout`\\n\\na timeout has occurred while establishing a connection with the server, passing a request to it, or reading the response header;\\n\\n`invalid_header`\\n\\na server returned an empty or invalid response;\\n\\n`http_500`\\n\\na server returned a response with the code 500;\\n\\n`http_503`\\n\\na server returned a response with the code 503;\\n\\n`http_403`\\n\\na server returned a response with the code 403;\\n\\n`http_404`\\n\\na server returned a response with the code 404;\\n\\n`http_429`\\n\\na server returned a response with the code 429 (1.11.13);\\n\\n`non_idempotent`\\n\\nnormally, requests with a [non-idempotent](https://tools.ietf.org/html/rfc7231#section-4.2.2) method (`POST`, `LOCK`, `PATCH`) are not passed to the next server if a request has been sent to an upstream server (1.9.13); enabling this option explicitly allows retrying such requests;\\n\\n`off`\\n\\ndisables passing a request to the next server.\\n\\nOne should bear in mind that passing a request to the next server is only possible if nothing has been sent to a client yet. That is, if an error or timeout occurs in the middle of the transferring of a response, fixing this is impossible.\\nThe directive also defines what is considered an [unsuccessful attempt](ngx_http_upstream_module.html#max_fails) of communication with a server. The cases of `error`, `timeout` and `invalid_header` are always considered unsuccessful attempts, even if they are not specified in the directive. The cases of `http_500`, `http_503`, and `http_429` are considered unsuccessful attempts only if they are specified in the directive. The cases of `http_403` and `http_404` are never considered unsuccessful attempts.\\nPassing a request to the next server can be limited by [the number of tries](#uwsgi_next_upstream_tries) and by [time](#uwsgi_next_upstream_timeout)."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_next_upstream_timeout","d":"Limits the time during which a request can be passed to the [next server](#uwsgi_next_upstream). The `0` value turns off this limitation."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_next_upstream_tries","d":"Limits the number of possible tries for passing a request to the [next server](#uwsgi_next_upstream). The `0` value turns off this limitation."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_no_cache","d":"Defines conditions under which the response will not be saved to a cache. If at least one value of the string parameters is not empty and is not equal to \u201c0\u201d then the response will not be saved:\\n```\\nuwsgi_no_cache $cookie_nocache $arg_nocache$arg_comment;\\nuwsgi_no_cache $http_pragma    $http_authorization;\\n\\n```\\nCan be used along with the [uwsgi\\\\_cache\\\\_bypass](#uwsgi_cache_bypass) directive."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_param","d":"Sets a `_parameter_` that should be passed to the uwsgi server. The `_value_` can contain text, variables, and their combination. These directives are inherited from the previous configuration level if and only if there are no `uwsgi_param` directives defined on the current level.\\nStandard [CGI environment variables](https://tools.ietf.org/html/rfc3875#section-4.1) should be provided as uwsgi headers, see the `uwsgi_params` file provided in the distribution:\\n```\\nlocation / {\\n    include uwsgi_params;\\n    ...\\n}\\n\\n```\\n\\nIf the directive is specified with `if_not_empty` (1.1.11) then such a parameter will be passed to the server only if its value is not empty:\\n```\\nuwsgi_param HTTPS $https if_not_empty;\\n\\n```\\n"},{"m":"ngx_http_uwsgi_module","n":"uwsgi_pass","d":"Sets the protocol and address of a uwsgi server. As a `_protocol_`, \u201c`uwsgi`\u201d or \u201c`suwsgi`\u201d (secured uwsgi, uwsgi over SSL) can be specified. The address can be specified as a domain name or IP address, and a port:\\n```\\nuwsgi_pass localhost:9000;\\nuwsgi_pass uwsgi://localhost:9000;\\nuwsgi_pass suwsgi://[2001:db8::1]:9090;\\n\\n```\\nor as a UNIX-domain socket path:\\n```\\nuwsgi_pass unix:/tmp/uwsgi.socket;\\n\\n```\\n\\nIf a domain name resolves to several addresses, all of them will be used in a round-robin fashion. In addition, an address can be specified as a [server group](ngx_http_upstream_module.html).\\nParameter value can contain variables. In this case, if an address is specified as a domain name, the name is searched among the described [server groups](ngx_http_upstream_module.html), and, if not found, is determined using a [resolver](ngx_http_core_module.html#resolver).\\n\\nSecured uwsgi protocol is supported since version 1.5.8.\\n"},{"m":"ngx_http_uwsgi_module","n":"uwsgi_pass_header","d":"Permits passing [otherwise disabled](#uwsgi_hide_header) header fields from a uwsgi server to a client."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_pass_request_body","d":"Indicates whether the original request body is passed to the uwsgi server. See also the [uwsgi\\\\_pass\\\\_request\\\\_headers](#uwsgi_pass_request_headers) directive."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_pass_request_headers","d":"Indicates whether the header fields of the original request are passed to the uwsgi server. See also the [uwsgi\\\\_pass\\\\_request\\\\_body](#uwsgi_pass_request_body) directive."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_read_timeout","d":"Defines a timeout for reading a response from the uwsgi server. The timeout is set only between two successive read operations, not for the transmission of the whole response. If the uwsgi server does not transmit anything within this time, the connection is closed."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_request_buffering","d":"Enables or disables buffering of a client request body.\\nWhen buffering is enabled, the entire request body is [read](ngx_http_core_module.html#client_body_buffer_size) from the client before sending the request to a uwsgi server.\\nWhen buffering is disabled, the request body is sent to the uwsgi server immediately as it is received. In this case, the request cannot be passed to the [next server](#uwsgi_next_upstream) if nginx already started sending the request body.\\nWhen HTTP/1.1 chunked transfer encoding is used to send the original request body, the request body will be buffered regardless of the directive value."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_send_timeout","d":"Sets a timeout for transmitting a request to the uwsgi server. The timeout is set only between two successive write operations, not for the transmission of the whole request. If the uwsgi server does not receive anything within this time, the connection is closed."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_socket_keepalive","d":"Configures the \u201cTCP keepalive\u201d behavior for outgoing connections to a uwsgi server. By default, the operating system\u2019s settings are in effect for the socket. If the directive is set to the value \u201c`on`\u201d, the `SO_KEEPALIVE` socket option is turned on for the socket."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_ssl_certificate","d":"Specifies a `_file_` with the certificate in the PEM format used for authentication to a secured uwsgi server."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_ssl_certificate_key","d":"Specifies a `_file_` with the secret key in the PEM format used for authentication to a secured uwsgi server.\\nThe value `engine`:`_name_`:`_id_` can be specified instead of the `_file_` (1.7.9), which loads a secret key with a specified `_id_` from the OpenSSL engine `_name_`."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_ssl_ciphers","d":"Specifies the enabled ciphers for requests to a secured uwsgi server. The ciphers are specified in the format understood by the OpenSSL library.\\nThe full list can be viewed using the \u201c`openssl ciphers`\u201d command."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_ssl_conf_command","d":"Sets arbitrary OpenSSL configuration [commands](https://www.openssl.org/docs/man1.1.1/man3/SSL_CONF_cmd.html) when establishing a connection with the secured uwsgi server.\\nThe directive is supported when using OpenSSL 1.0.2 or higher.\\n\\nSeveral `uwsgi_ssl_conf_command` directives can be specified on the same level. These directives are inherited from the previous configuration level if and only if there are no `uwsgi_ssl_conf_command` directives defined on the current level.\\n\\nNote that configuring OpenSSL directly might result in unexpected behavior.\\n"},{"m":"ngx_http_uwsgi_module","n":"uwsgi_ssl_crl","d":"Specifies a `_file_` with revoked certificates (CRL) in the PEM format used to [verify](#uwsgi_ssl_verify) the certificate of the secured uwsgi server."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_ssl_name","d":"Allows overriding the server name used to [verify](#uwsgi_ssl_verify) the certificate of the secured uwsgi server and to be [passed through SNI](#uwsgi_ssl_server_name) when establishing a connection with the secured uwsgi server.\\nBy default, the host part from [uwsgi\\\\_pass](#uwsgi_pass) is used."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_ssl_password_file","d":"Specifies a `_file_` with passphrases for [secret keys](#uwsgi_ssl_certificate_key) where each passphrase is specified on a separate line. Passphrases are tried in turn when loading the key."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_ssl_protocols","d":"Enables the specified protocols for requests to a secured uwsgi server."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_ssl_server_name","d":"Enables or disables passing of the server name through [TLS Server Name Indication extension](http://en.wikipedia.org/wiki/Server_Name_Indication) (SNI, RFC 6066) when establishing a connection with the secured uwsgi server."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_ssl_session_reuse","d":"Determines whether SSL sessions can be reused when working with a secured uwsgi server. If the errors \u201c`SSL3_GET_FINISHED:digest check failed`\u201d appear in the logs, try disabling session reuse."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_ssl_trusted_certificate","d":"Specifies a `_file_` with trusted CA certificates in the PEM format used to [verify](#uwsgi_ssl_verify) the certificate of the secured uwsgi server."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_ssl_verify","d":"Enables or disables verification of the secured uwsgi server certificate."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_ssl_verify_depth","d":"Sets the verification depth in the secured uwsgi server certificates chain."},{"m":"ngx_http_uwsgi_module","n":"uwsgi_store","d":"Enables saving of files to a disk. The `on` parameter saves files with paths corresponding to the directives [alias](ngx_http_core_module.html#alias) or [root](ngx_http_core_module.html#root). The `off` parameter disables saving of files. In addition, the file name can be set explicitly using the `_string_` with variables:\\n```\\nuwsgi_store /data/www$original_uri;\\n\\n```\\n\\nThe modification time of files is set according to the received \u201cLast-Modified\u201d response header field. The response is first written to a temporary file, and then the file is renamed. Starting from version 0.8.9, temporary files and the persistent store can be put on different file systems. However, be aware that in this case a file is copied across two file systems instead of the cheap renaming operation. It is thus recommended that for any given location both saved files and a directory holding temporary files, set by the [uwsgi\\\\_temp\\\\_path](#uwsgi_temp_path) directive, are put on the same file system.\\nThis directive can be used to create local copies of static unchangeable files, e.g.:\\n```\\nlocation /images/ {\\n    root               /data/www;\\n    error_page         404 = /fetch$uri;\\n}\\n\\nlocation /fetch/ {\\n    internal;\\n\\n    uwsgi_pass         backend:9000;\\n    ...\\n\\n    uwsgi_store        on;\\n    uwsgi_store_access user:rw group:rw all:r;\\n    uwsgi_temp_path    /data/temp;\\n\\n    alias              /data/www/;\\n}\\n\\n```\\n"},{"m":"ngx_http_uwsgi_module","n":"uwsgi_store_access","d":"Sets access permissions for newly created files and directories, e.g.:\\n```\\nuwsgi_store_access user:rw group:rw all:r;\\n\\n```\\n\\nIf any `group` or `all` access permissions are specified then `user` permissions may be omitted:\\n```\\nuwsgi_store_access group:rw all:r;\\n\\n```\\n"},{"m":"ngx_http_uwsgi_module","n":"uwsgi_temp_file_write_size","d":"Limits the `_size_` of data written to a temporary file at a time, when buffering of responses from the uwsgi server to temporary files is enabled. By default, `_size_` is limited by two buffers set by the [uwsgi\\\\_buffer\\\\_size](#uwsgi_buffer_size) and [uwsgi\\\\_buffers](#uwsgi_buffers) directives. The maximum size of a temporary file is set by the [uwsgi\\\\_max\\\\_temp\\\\_file\\\\_size](#uwsgi_max_temp_file_size) directive."},{"m":"ngx_http_v2_module","n":"summary","d":"The `ngx_http_v2_module` module (1.9.5) provides support for [HTTP/2](https://tools.ietf.org/html/rfc7540) and supersedes the [ngx\\\\_http\\\\_spdy\\\\_module](ngx_http_spdy_module.html) module.\\nThis module is not built by default, it should be enabled with the `--with-http_v2_module` configuration parameter."},{"m":"ngx_http_v2_module","n":"issues","d":"#### Known Issues\\nBefore version 1.9.14, buffering of a client request body could not be disabled regardless of [proxy\\\\_request\\\\_buffering](ngx_http_proxy_module.html#proxy_request_buffering), [fastcgi\\\\_request\\\\_buffering](ngx_http_fastcgi_module.html#fastcgi_request_buffering), [uwsgi\\\\_request\\\\_buffering](ngx_http_uwsgi_module.html#uwsgi_request_buffering), and [scgi\\\\_request\\\\_buffering](ngx_http_scgi_module.html#scgi_request_buffering) directive values.\\nBefore version 1.19.1, the [lingering\\\\_close](ngx_http_core_module.html#lingering_close) mechanism was not used to control closing HTTP/2 connections."},{"m":"ngx_http_v2_module","n":"http2_body_preread_size","d":"Sets the `_size_` of the buffer per each request in which the request body may be saved before it is started to be processed."},{"m":"ngx_http_v2_module","n":"http2_chunk_size","d":"Sets the maximum size of chunks into which the response body is sliced. A too low value results in higher overhead. A too high value impairs prioritization due to [HOL blocking](http://en.wikipedia.org/wiki/Head-of-line_blocking)."},{"m":"ngx_http_v2_module","n":"http2_idle_timeout","d":"Sets the timeout of inactivity after which the connection is closed."},{"m":"ngx_http_v2_module","n":"http2_max_concurrent_pushes","d":"Limits the maximum number of concurrent [push](#http2_push) requests in a connection."},{"m":"ngx_http_v2_module","n":"http2_max_concurrent_streams","d":"Sets the maximum number of concurrent HTTP/2 streams in a connection."},{"m":"ngx_http_v2_module","n":"http2_max_field_size","d":"Limits the maximum size of an [HPACK](https://tools.ietf.org/html/rfc7541)\\\\-compressed request header field. The limit applies equally to both name and value. Note that if Huffman encoding is applied, the actual size of decompressed name and value strings may be larger. For most requests, the default limit should be enough."},{"m":"ngx_http_v2_module","n":"http2_max_header_size","d":"Limits the maximum size of the entire request header list after [HPACK](https://tools.ietf.org/html/rfc7541) decompression. For most requests, the default limit should be enough."},{"m":"ngx_http_v2_module","n":"http2_max_requests","d":"Sets the maximum number of requests (including [push](#http2_push) requests) that can be served through one HTTP/2 connection, after which the next client request will lead to connection closing and the need of establishing a new connection.\\nClosing connections periodically is necessary to free per-connection memory allocations. Therefore, using too high maximum number of requests could result in excessive memory usage and not recommended."},{"m":"ngx_http_v2_module","n":"http2_push","d":"Pre-emptively sends ([pushes](https://tools.ietf.org/html/rfc7540#section-8.2)) a request to the specified `_uri_` along with the response to the original request. Only relative URIs with absolute path will be processed, for example:\\n```\\nhttp2_push /static/css/main.css;\\n\\n```\\nThe `_uri_` value can contain variables.\\nSeveral `http2_push` directives can be specified on the same configuration level. The `off` parameter cancels the effect of the `http2_push` directives inherited from the previous configuration level."},{"m":"ngx_http_v2_module","n":"http2_push_preload","d":"Enables automatic conversion of [preload links](https://www.w3.org/TR/preload/#server-push-http-2) specified in the \u201cLink\u201d response header fields into [push](https://tools.ietf.org/html/rfc7540#section-8.2) requests."},{"m":"ngx_http_v2_module","n":"http2_recv_buffer_size","d":"Sets the size of the per [worker](../ngx_core_module.html#worker_processes) input buffer."},{"m":"ngx_http_v2_module","n":"http2_recv_timeout","d":"Sets the timeout for expecting more data from the client, after which the connection is closed."},{"m":"ngx_http_xslt_module","n":"summary","d":"The `ngx_http_xslt_module` (0.7.8+) is a filter that transforms XML responses using one or more XSLT stylesheets.\\nThis module is not built by default, it should be enabled with the `--with-http_xslt_module` configuration parameter.\\nThis module requires the [libxml2](http://xmlsoft.org) and [libxslt](http://xmlsoft.org/XSLT/) libraries.\\n"},{"m":"ngx_http_xslt_module","n":"xml_entities","d":"Specifies the DTD file that declares character entities. This file is compiled at the configuration stage. For technical reasons, the module is unable to use the external subset declared in the processed XML, so it is ignored and a specially defined file is used instead. This file should not describe the XML structure. It is enough to declare just the required character entities, for example:\\n```\\n<!ENTITY nbsp \\"&#xa0;\\">\\n\\n```\\n"},{"m":"ngx_http_xslt_module","n":"xslt_last_modified","d":"Allows preserving the \u201cLast-Modified\u201d header field from the original response during XSLT transformations to facilitate response caching.\\nBy default, the header field is removed as contents of the response are modified during transformations and may contain dynamically generated elements or parts that are changed independently of the original response."},{"m":"ngx_http_xslt_module","n":"xslt_param","d":"Defines the parameters for XSLT stylesheets. The `_value_` is treated as an XPath expression. The `_value_` can contain variables. To pass a string value to a stylesheet, the [xslt\\\\_string\\\\_param](#xslt_string_param) directive can be used.\\nThere could be several `xslt_param` directives. These directives are inherited from the previous configuration level if and only if there are no `xslt_param` and [xslt\\\\_string\\\\_param](#xslt_string_param) directives defined on the current level."},{"m":"ngx_http_xslt_module","n":"xslt_string_param","d":"Defines the string parameters for XSLT stylesheets. XPath expressions in the `_value_` are not interpreted. The `_value_` can contain variables.\\nThere could be several `xslt_string_param` directives. These directives are inherited from the previous configuration level if and only if there are no [xslt\\\\_param](#xslt_param) and `xslt_string_param` directives defined on the current level."},{"m":"ngx_http_xslt_module","n":"xslt_stylesheet","d":"Defines the XSLT stylesheet and its optional parameters. A stylesheet is compiled at the configuration stage.\\nParameters can either be specified separately, or grouped in a single line using the \u201c`:`\u201d delimiter. If a parameter includes the \u201c`:`\u201d character, it should be escaped as \u201c`%3A`\u201d. Also, `libxslt` requires to enclose parameters that contain non-alphanumeric characters into single or double quotes, for example:\\n```\\nparam1=\'http%3A//www.example.com\':param2=value2\\n\\n```\\n\\nThe parameters description can contain variables, for example, the whole line of parameters can be taken from a single variable:\\n```\\nlocation / {\\n    xslt_stylesheet /site/xslt/one.xslt\\n                    $arg_xslt_params\\n                    param1=\'$value1\':param2=value2\\n                    param3=value3;\\n}\\n\\n```\\n\\nIt is possible to specify several stylesheets. They will be applied sequentially in the specified order."},{"m":"ngx_mail_core_module","n":"summary","d":"This module is not built by default, it should be enabled with the `--with-mail` configuration parameter."},{"m":"ngx_mail_core_module","n":"listen","d":"Sets the `_address_` and `_port_` for the socket on which the server will accept requests. It is possible to specify just the port. The address can also be a hostname, for example:\\n```\\nlisten 127.0.0.1:110;\\nlisten *:110;\\nlisten 110;     # same as *:110\\nlisten localhost:110;\\n\\n```\\nIPv6 addresses (0.7.58) are specified in square brackets:\\n```\\nlisten [::1]:110;\\nlisten [::]:110;\\n\\n```\\nUNIX-domain sockets (1.3.5) are specified with the \u201c`unix:`\u201d prefix:\\n```\\nlisten unix:/var/run/nginx.sock;\\n\\n```\\n\\nDifferent servers must listen on different `_address_`:`_port_` pairs.\\nThe `ssl` parameter allows specifying that all connections accepted on this port should work in SSL mode.\\nThe `listen` directive can have several additional parameters specific to socket-related system calls.\\n`backlog`\\\\=`_number_`\\n\\nsets the `backlog` parameter in the `listen()` call that limits the maximum length for the queue of pending connections (1.9.2). By default, `backlog` is set to -1 on FreeBSD, DragonFly BSD, and macOS, and to 511 on other platforms.\\n\\n`rcvbuf`\\\\=`_size_`\\n\\nsets the receive buffer size (the `SO_RCVBUF` option) for the listening socket (1.11.13).\\n\\n`sndbuf`\\\\=`_size_`\\n\\nsets the send buffer size (the `SO_SNDBUF` option) for the listening socket (1.11.13).\\n\\n`bind`\\n\\nthis parameter instructs to make a separate `bind()` call for a given address:port pair. The fact is that if there are several `listen` directives with the same port but different addresses, and one of the `listen` directives listens on all addresses for the given port (`*:``_port_`), nginx will `bind()` only to `*:``_port_`. It should be noted that the `getsockname()` system call will be made in this case to determine the address that accepted the connection. If the `ipv6only` or `so_keepalive` parameters are used then for a given `_address_`:`_port_` pair a separate `bind()` call will always be made.\\n\\n`ipv6only`\\\\=`on`|`off`\\n\\nthis parameter determines (via the `IPV6_V6ONLY` socket option) whether an IPv6 socket listening on a wildcard address `[::]` will accept only IPv6 connections or both IPv6 and IPv4 connections. This parameter is turned on by default. It can only be set once on start.\\n\\n`so_keepalive`\\\\=`on`|`off`|\\\\[`_keepidle_`\\\\]:\\\\[`_keepintvl_`\\\\]:\\\\[`_keepcnt_`\\\\]\\n\\nthis parameter configures the \u201cTCP keepalive\u201d behavior for the listening socket. If this parameter is omitted then the operating system\u2019s settings will be in effect for the socket. If it is set to the value \u201c`on`\u201d, the `SO_KEEPALIVE` option is turned on for the socket. If it is set to the value \u201c`off`\u201d, the `SO_KEEPALIVE` option is turned off for the socket. Some operating systems support setting of TCP keepalive parameters on a per-socket basis using the `TCP_KEEPIDLE`, `TCP_KEEPINTVL`, and `TCP_KEEPCNT` socket options. On such systems (currently, Linux\xa02.4+, NetBSD\xa05+, and FreeBSD\xa09.0-STABLE), they can be configured using the `_keepidle_`, `_keepintvl_`, and `_keepcnt_` parameters. One or two parameters may be omitted, in which case the system default setting for the corresponding socket option will be in effect. For example,\\n\\n> so\\\\_keepalive=30m::10\\n\\nwill set the idle timeout (`TCP_KEEPIDLE`) to 30 minutes, leave the probe interval (`TCP_KEEPINTVL`) at its system default, and set the probes count (`TCP_KEEPCNT`) to 10 probes.\\n"},{"m":"ngx_mail_core_module","n":"mail","d":"Provides the configuration file context in which the mail server directives are specified."},{"m":"ngx_mail_core_module","n":"protocol","d":"Sets the protocol for a proxied server. Supported protocols are [IMAP](ngx_mail_imap_module.html), [POP3](ngx_mail_pop3_module.html), and [SMTP](ngx_mail_smtp_module.html).\\nIf the directive is not set, the protocol can be detected automatically based on the well-known port specified in the [listen](#listen) directive:\\n*   `imap`: 143, 993\\n*   `pop3`: 110, 995\\n*   `smtp`: 25, 587, 465\\n\\nUnnecessary protocols can be disabled using the [configuration](../configure.html) parameters `--without-mail_imap_module`, `--without-mail_pop3_module`, and `--without-mail_smtp_module`."},{"m":"ngx_mail_core_module","n":"resolver","d":"Configures name servers used to find the client\u2019s hostname to pass it to the [authentication server](ngx_mail_auth_http_module.html), and in the [XCLIENT](ngx_mail_proxy_module.html#xclient) command when proxying SMTP. For example:\\n```\\nresolver 127.0.0.1 [::1]:5353;\\n\\n```\\nThe address can be specified as a domain name or IP address, with an optional port (1.3.1, 1.2.2). If port is not specified, the port 53 is used. Name servers are queried in a round-robin fashion.\\nBefore version 1.1.7, only a single name server could be configured. Specifying name servers using IPv6 addresses is supported starting from versions 1.3.1 and 1.2.2.\\n"},{"m":"ngx_mail_core_module","n":"resolver_ipv6","d":"By default, nginx will look up both IPv4 and IPv6 addresses while resolving. If looking up of IPv6 addresses is not desired, the `ipv6=off` parameter can be specified.\\nResolving of names into IPv6 addresses is supported starting from version 1.5.8.\\n"},{"m":"ngx_mail_core_module","n":"resolver_valid","d":"By default, nginx caches answers using the TTL value of a response. An optional `valid` parameter allows overriding it:\\n```\\nresolver 127.0.0.1 [::1]:5353 valid=30s;\\n\\n```\\n\\nBefore version 1.1.9, tuning of caching time was not possible, and nginx always cached answers for the duration of 5 minutes.\\n\\nTo prevent DNS spoofing, it is recommended configuring DNS servers in a properly secured trusted local network.\\n"},{"m":"ngx_mail_core_module","n":"resolver_status_zone","d":"The optional `status_zone` parameter (1.17.1) enables [collection](../http/ngx_http_api_module.html#resolvers_) of DNS server statistics of requests and responses in the specified `_zone_`. The parameter is available as part of our [commercial subscription](http://nginx.com/products/)."},{"m":"ngx_mail_core_module","n":"resolver_off","d":"The special value `off` disables resolving."},{"m":"ngx_mail_core_module","n":"resolver_timeout","d":"Sets a timeout for DNS operations, for example:\\n```\\nresolver_timeout 5s;\\n\\n```\\n"},{"m":"ngx_mail_core_module","n":"server","d":"Sets the configuration for a server."},{"m":"ngx_mail_core_module","n":"server_name","d":"Sets the server name that is used:\\n*   in the initial POP3/SMTP server greeting;\\n*   in the salt during the SASL CRAM-MD5 authentication;\\n*   in the `EHLO` command when connecting to the SMTP backend, if the passing of the [XCLIENT](ngx_mail_proxy_module.html#xclient) command is enabled.\\n\\nIf the directive is not specified, the machine\u2019s hostname is used."},{"m":"ngx_mail_auth_http_module","n":"auth_http","d":"Sets the URL of the HTTP authentication server. The protocol is described [below](#protocol)."},{"m":"ngx_mail_auth_http_module","n":"auth_http_header","d":"Appends the specified header to requests sent to the authentication server. This header can be used as the shared secret to verify that the request comes from nginx. For example:\\n```\\nauth_http_header X-Auth-Key \\"secret_string\\";\\n\\n```\\n"},{"m":"ngx_mail_auth_http_module","n":"auth_http_pass_client_cert","d":"Appends the \u201cAuth-SSL-Cert\u201d header with the [client](ngx_mail_ssl_module.html#ssl_verify_client) certificate in the PEM format (urlencoded) to requests sent to the authentication server."},{"m":"ngx_mail_auth_http_module","n":"auth_http_timeout","d":"Sets the timeout for communication with the authentication server."},{"m":"ngx_mail_proxy_module","n":"proxy_buffer","d":"Sets the size of the buffer used for proxying. By default, the buffer size is equal to one memory page. Depending on a platform, it is either 4K or 8K."},{"m":"ngx_mail_proxy_module","n":"proxy_pass_error_message","d":"Indicates whether to pass the error message obtained during the authentication on the backend to the client.\\nUsually, if the authentication in nginx is a success, the backend cannot return an error. If it nevertheless returns an error, it means some internal error has occurred. In such case the backend message can contain information that should not be shown to the client. However, responding with an error for the correct password is a normal behavior for some POP3 servers. For example, CommuniGatePro informs a user about [mailbox overflow](http://www.stalker.com/CommuniGatePro/Alerts.html#Quota) or other events by periodically outputting the [authentication error](http://www.stalker.com/CommuniGatePro/POP.html#Alerts). The directive should be enabled in this case."},{"m":"ngx_mail_proxy_module","n":"proxy_smtp_auth","d":"Enables or disables user authentication on the SMTP backend using the `AUTH` command.\\nIf [XCLIENT](#xclient) is also enabled, then the `XCLIENT` command will not send the `LOGIN` parameter."},{"m":"ngx_mail_proxy_module","n":"proxy_timeout","d":"Sets the `_timeout_` between two successive read or write operations on client or proxied server connections. If no data is transmitted within this time, the connection is closed."},{"m":"ngx_mail_ssl_module","n":"summary","d":"The `ngx_mail_ssl_module` module provides the necessary support for a mail proxy server to work with the SSL/TLS protocol.\\nThis module is not built by default, it should be enabled with the `--with-mail_ssl_module` configuration parameter.\\nThis module requires the [OpenSSL](http://www.openssl.org) library.\\n"},{"m":"ngx_mail_ssl_module","n":"ssl","d":"This directive was made obsolete in version 1.15.0. The `ssl` parameter of the [listen](ngx_mail_core_module.html#listen) directive should be used instead."},{"m":"ngx_mail_ssl_module","n":"ssl_certificate","d":"Specifies a `_file_` with the certificate in the PEM format for the given server. If intermediate certificates should be specified in addition to a primary certificate, they should be specified in the same file in the following order: the primary certificate comes first, then the intermediate certificates. A secret key in the PEM format may be placed in the same file.\\nSince version 1.11.0, this directive can be specified multiple times to load certificates of different types, for example, RSA and ECDSA:\\n```\\nserver {\\n    listen              993 ssl;\\n\\n    ssl_certificate     example.com.rsa.crt;\\n    ssl_certificate_key example.com.rsa.key;\\n\\n    ssl_certificate     example.com.ecdsa.crt;\\n    ssl_certificate_key example.com.ecdsa.key;\\n\\n    ...\\n}\\n\\n```\\n\\nOnly OpenSSL 1.0.2 or higher supports separate certificate chains for different certificates. With older versions, only one certificate chain can be used.\\n"},{"m":"ngx_mail_ssl_module","n":"ssl_certificate_data","d":"The value `data`:`_certificate_` can be specified instead of the `_file_` (1.15.10), which loads a certificate without using intermediate files. Note that inappropriate use of this syntax may have its security implications, such as writing secret key data to [error log](../ngx_core_module.html#error_log)."},{"m":"ngx_mail_ssl_module","n":"ssl_certificate_key","d":"Specifies a `_file_` with the secret key in the PEM format for the given server.\\nThe value `engine`:`_name_`:`_id_` can be specified instead of the `_file_` (1.7.9), which loads a secret key with a specified `_id_` from the OpenSSL engine `_name_`."},{"m":"ngx_mail_ssl_module","n":"ssl_certificate_key_data","d":"The value `data`:`_key_` can be specified instead of the `_file_` (1.15.10), which loads a secret key without using intermediate files. Note that inappropriate use of this syntax may have its security implications, such as writing secret key data to [error log](../ngx_core_module.html#error_log)."},{"m":"ngx_mail_ssl_module","n":"ssl_ciphers","d":"Specifies the enabled ciphers. The ciphers are specified in the format understood by the OpenSSL library, for example:\\n```\\nssl_ciphers ALL:!aNULL:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP;\\n\\n```\\n\\nThe full list can be viewed using the \u201c`openssl ciphers`\u201d command.\\n\\nThe previous versions of nginx used [different](../http/configuring_https_servers.html#compatibility) ciphers by default.\\n"},{"m":"ngx_mail_ssl_module","n":"ssl_client_certificate","d":"Specifies a `_file_` with trusted CA certificates in the PEM format used to [verify](#ssl_verify_client) client certificates.\\nThe list of certificates will be sent to clients. If this is not desired, the [ssl\\\\_trusted\\\\_certificate](#ssl_trusted_certificate) directive can be used."},{"m":"ngx_mail_ssl_module","n":"ssl_conf_command","d":"Sets arbitrary OpenSSL configuration [commands](https://www.openssl.org/docs/man1.1.1/man3/SSL_CONF_cmd.html).\\nThe directive is supported when using OpenSSL 1.0.2 or higher.\\n\\nSeveral `ssl_conf_command` directives can be specified on the same level:\\n```\\nssl_conf_command Options PrioritizeChaCha;\\nssl_conf_command Ciphersuites TLS_CHACHA20_POLY1305_SHA256;\\n\\n```\\nThese directives are inherited from the previous configuration level if and only if there are no `ssl_conf_command` directives defined on the current level.\\n\\nNote that configuring OpenSSL directly might result in unexpected behavior.\\n"},{"m":"ngx_mail_ssl_module","n":"ssl_crl","d":"Specifies a `_file_` with revoked certificates (CRL) in the PEM format used to [verify](#ssl_verify_client) client certificates."},{"m":"ngx_mail_ssl_module","n":"ssl_dhparam","d":"Specifies a `_file_` with DH parameters for DHE ciphers.\\nBy default no parameters are set, and therefore DHE ciphers will not be used.\\nPrior to version 1.11.0, builtin parameters were used by default.\\n"},{"m":"ngx_mail_ssl_module","n":"ssl_ecdh_curve","d":"Specifies a `_curve_` for ECDHE ciphers.\\nWhen using OpenSSL 1.0.2 or higher, it is possible to specify multiple curves (1.11.0), for example:\\n```\\nssl_ecdh_curve prime256v1:secp384r1;\\n\\n```\\n\\nThe special value `auto` (1.11.0) instructs nginx to use a list built into the OpenSSL library when using OpenSSL 1.0.2 or higher, or `prime256v1` with older versions.\\n\\nPrior to version 1.11.0, the `prime256v1` curve was used by default.\\n\\n\\nWhen using OpenSSL 1.0.2 or higher, this directive sets the list of curves supported by the server. Thus, in order for ECDSA certificates to work, it is important to include the curves used in the certificates.\\n"},{"m":"ngx_mail_ssl_module","n":"ssl_password_file","d":"Specifies a `_file_` with passphrases for [secret keys](#ssl_certificate_key) where each passphrase is specified on a separate line. Passphrases are tried in turn when loading the key.\\nExample:\\n```\\nmail {\\n    ssl_password_file /etc/keys/global.pass;\\n    ...\\n\\n    server {\\n        server_name mail1.example.com;\\n        ssl_certificate_key /etc/keys/first.key;\\n    }\\n\\n    server {\\n        server_name mail2.example.com;\\n\\n        # named pipe can also be used instead of a file\\n        ssl_password_file /etc/keys/fifo;\\n        ssl_certificate_key /etc/keys/second.key;\\n    }\\n}\\n\\n```\\n"},{"m":"ngx_mail_ssl_module","n":"ssl_prefer_server_ciphers","d":"Specifies that server ciphers should be preferred over client ciphers when the SSLv3 and TLS protocols are used."},{"m":"ngx_mail_ssl_module","n":"ssl_protocols","d":"Enables the specified protocols.\\nThe `TLSv1.1` and `TLSv1.2` parameters (1.1.13, 1.0.12) work only when OpenSSL 1.0.1 or higher is used.\\n\\nThe `TLSv1.3` parameter (1.13.0) works only when OpenSSL 1.1.1 built with TLSv1.3 support is used.\\n"},{"m":"ngx_mail_ssl_module","n":"ssl_session_cache","d":"Sets the types and sizes of caches that store session parameters. A cache can be of any of the following types:\\n`off`\\n\\nthe use of a session cache is strictly prohibited: nginx explicitly tells a client that sessions may not be reused.\\n\\n`none`\\n\\nthe use of a session cache is gently disallowed: nginx tells a client that sessions may be reused, but does not actually store session parameters in the cache.\\n\\n`builtin`\\n\\na cache built in OpenSSL; used by one worker process only. The cache size is specified in sessions. If size is not given, it is equal to 20480 sessions. Use of the built-in cache can cause memory fragmentation.\\n\\n`shared`\\n\\na cache shared between all worker processes. The cache size is specified in bytes; one megabyte can store about 4000 sessions. Each shared cache should have an arbitrary name. A cache with the same name can be used in several servers.\\n\\nBoth cache types can be used simultaneously, for example:\\n```\\nssl_session_cache builtin:1000 shared:SSL:10m;\\n\\n```\\nbut using only shared cache without the built-in cache should be more efficient."},{"m":"ngx_mail_ssl_module","n":"ssl_session_ticket_key","d":"Sets a `_file_` with the secret key used to encrypt and decrypt TLS session tickets. The directive is necessary if the same key has to be shared between multiple servers. By default, a randomly generated key is used.\\nIf several keys are specified, only the first key is used to encrypt TLS session tickets. This allows configuring key rotation, for example:\\n```\\nssl_session_ticket_key current.key;\\nssl_session_ticket_key previous.key;\\n\\n```\\n\\nThe `_file_` must contain 80 or 48 bytes of random data and can be created using the following command:\\n```\\nopenssl rand 80 > ticket.key\\n\\n```\\nDepending on the file size either AES256 (for 80-byte keys, 1.11.8) or AES128 (for 48-byte keys) is used for encryption."},{"m":"ngx_mail_ssl_module","n":"ssl_session_tickets","d":"Enables or disables session resumption through [TLS session tickets](https://tools.ietf.org/html/rfc5077)."},{"m":"ngx_mail_ssl_module","n":"ssl_session_timeout","d":"Specifies a time during which a client may reuse the session parameters."},{"m":"ngx_mail_ssl_module","n":"ssl_trusted_certificate","d":"Specifies a `_file_` with trusted CA certificates in the PEM format used to [verify](#ssl_verify_client) client certificates.\\nIn contrast to the certificate set by [ssl\\\\_client\\\\_certificate](#ssl_client_certificate), the list of these certificates will not be sent to clients."},{"m":"ngx_mail_ssl_module","n":"ssl_verify_client","d":"Enables verification of client certificates. The verification result is passed in the \u201cAuth-SSL-Verify\u201d header of the [authentication](ngx_mail_auth_http_module.html#auth_http) request.\\nThe `optional` parameter requests the client certificate and verifies it if the certificate is present.\\nThe `optional_no_ca` parameter requests the client certificate but does not require it to be signed by a trusted CA certificate. This is intended for the use in cases when a service that is external to nginx performs the actual certificate verification. The contents of the certificate is accessible through requests [sent](ngx_mail_auth_http_module.html#auth_http_pass_client_cert) to the authentication server."},{"m":"ngx_mail_ssl_module","n":"ssl_verify_depth","d":"Sets the verification depth in the client certificates chain."},{"m":"ngx_mail_imap_module","n":"imap_auth","d":"Sets permitted methods of authentication for IMAP clients. Supported methods are:\\n`login`\\n\\n[AUTH=LOGIN](https://tools.ietf.org/html/draft-murchison-sasl-login-00)\\n\\n`plain`\\n\\n[AUTH=PLAIN](https://tools.ietf.org/html/rfc4616)\\n\\n`cram-md5`\\n\\n[AUTH=CRAM-MD5](https://tools.ietf.org/html/rfc2195). In order for this method to work, the password must be stored unencrypted.\\n\\n`external`\\n\\n[AUTH=EXTERNAL](https://tools.ietf.org/html/rfc4422) (1.11.6).\\n"},{"m":"ngx_mail_imap_module","n":"imap_capabilities","d":"Sets the [IMAP protocol](https://tools.ietf.org/html/rfc3501) extensions list that is passed to the client in response to the `CAPABILITY` command. The authentication methods specified in the [imap\\\\_auth](#imap_auth) directive and [STARTTLS](https://tools.ietf.org/html/rfc2595) are automatically added to this list depending on the [starttls](ngx_mail_ssl_module.html#starttls) directive value.\\nIt makes sense to specify the extensions supported by the IMAP backends to which the clients are proxied (if these extensions are related to commands used after the authentication, when nginx transparently proxies a client connection to the backend).\\nThe current list of standardized extensions is published at [www.iana.org](http://www.iana.org/assignments/imap4-capabilities)."},{"m":"ngx_mail_pop3_module","n":"pop3_auth","d":"Sets permitted methods of authentication for POP3 clients. Supported methods are:\\n`plain`\\n\\n[USER/PASS](https://tools.ietf.org/html/rfc1939), [AUTH PLAIN](https://tools.ietf.org/html/rfc4616), [AUTH LOGIN](https://tools.ietf.org/html/draft-murchison-sasl-login-00). It is not possible to disable these methods.\\n\\n`apop`\\n\\n[APOP](https://tools.ietf.org/html/rfc1939). In order for this method to work, the password must be stored unencrypted.\\n\\n`cram-md5`\\n\\n[AUTH CRAM-MD5](https://tools.ietf.org/html/rfc2195). In order for this method to work, the password must be stored unencrypted.\\n\\n`external`\\n\\n[AUTH EXTERNAL](https://tools.ietf.org/html/rfc4422) (1.11.6).\\n"},{"m":"ngx_mail_smtp_module","n":"smtp_auth","d":"Sets permitted methods of [SASL authentication](https://tools.ietf.org/html/rfc2554) for SMTP clients. Supported methods are:\\n`login`\\n\\n[AUTH LOGIN](https://tools.ietf.org/html/draft-murchison-sasl-login-00)\\n\\n`plain`\\n\\n[AUTH PLAIN](https://tools.ietf.org/html/rfc4616)\\n\\n`cram-md5`\\n\\n[AUTH CRAM-MD5](https://tools.ietf.org/html/rfc2195). In order for this method to work, the password must be stored unencrypted.\\n\\n`external`\\n\\n[AUTH EXTERNAL](https://tools.ietf.org/html/rfc4422) (1.11.6).\\n\\n`none`\\n\\nAuthentication is not required.\\n"},{"m":"ngx_mail_smtp_module","n":"smtp_capabilities","d":"Sets the SMTP protocol extensions list that is passed to the client in response to the `EHLO` command. The authentication methods specified in the [smtp\\\\_auth](#smtp_auth) directive and [STARTTLS](https://tools.ietf.org/html/rfc3207) are automatically added to this list depending on the [starttls](ngx_mail_ssl_module.html#starttls) directive value.\\nIt makes sense to specify the extensions supported by the MTA to which the clients are proxied (if these extensions are related to commands used after the authentication, when nginx transparently proxies the client connection to the backend).\\nThe current list of standardized extensions is published at [www.iana.org](http://www.iana.org/assignments/mail-parameters)."},{"m":"ngx_mail_smtp_module","n":"smtp_client_buffer","d":"Sets the `_size_` of the buffer used for reading SMTP commands. By default, the buffer size is equal to one memory page. This is either 4K or 8K, depending on a platform."},{"m":"ngx_stream_core_module","n":"summary","d":"The `ngx_stream_core_module` module is available since version 1.9.0. This module is not built by default, it should be enabled with the `--with-stream` configuration parameter."},{"m":"ngx_stream_core_module","n":"listen","d":"Sets the `_address_` and `_port_` for the socket on which the server will accept connections. It is possible to specify just the port. The address can also be a hostname, for example:\\n```\\nlisten 127.0.0.1:12345;\\nlisten *:12345;\\nlisten 12345;     # same as *:12345\\nlisten localhost:12345;\\n\\n```\\nIPv6 addresses are specified in square brackets:\\n```\\nlisten [::1]:12345;\\nlisten [::]:12345;\\n\\n```\\nUNIX-domain sockets are specified with the \u201c`unix:`\u201d prefix:\\n```\\nlisten unix:/var/run/nginx.sock;\\n\\n```\\n"},{"m":"ngx_stream_core_module","n":"listen_port_range","d":"Port ranges (1.15.10) are specified with the first and last port separated by a hyphen:\\n```\\nlisten 127.0.0.1:12345-12399;\\nlisten 12345-12399;\\n\\n```\\n\\nThe `ssl` parameter allows specifying that all connections accepted on this port should work in SSL mode."},{"m":"ngx_stream_core_module","n":"udp","d":"The `udp` parameter configures a listening socket for working with datagrams (1.9.13). In order to handle packets from the same address and port in the same session, the [`reuseport`](#reuseport) parameter should also be specified."},{"m":"ngx_stream_core_module","n":"proxy_protocol","d":"The `proxy_protocol` parameter (1.11.4) allows specifying that all connections accepted on this port should use the [PROXY protocol](http://www.haproxy.org/download/1.5/doc/proxy-protocol.txt).\\nThe PROXY protocol version 2 is supported since version 1.13.11.\\n\\nThe `listen` directive can have several additional parameters specific to socket-related system calls.\\n`backlog`\\\\=`_number_`\\n\\nsets the `backlog` parameter in the `listen()` call that limits the maximum length for the queue of pending connections (1.9.2). By default, `backlog` is set to -1 on FreeBSD, DragonFly BSD, and macOS, and to 511 on other platforms.\\n\\n`rcvbuf`\\\\=`_size_`\\n\\nsets the receive buffer size (the `SO_RCVBUF` option) for the listening socket (1.11.13).\\n\\n`sndbuf`\\\\=`_size_`\\n\\nsets the send buffer size (the `SO_SNDBUF` option) for the listening socket (1.11.13).\\n\\n`bind`\\n\\nthis parameter instructs to make a separate `bind()` call for a given address:port pair. The fact is that if there are several `listen` directives with the same port but different addresses, and one of the `listen` directives listens on all addresses for the given port (`*:``_port_`), nginx will `bind()` only to `*:``_port_`. It should be noted that the `getsockname()` system call will be made in this case to determine the address that accepted the connection. If the `ipv6only` or `so_keepalive` parameters are used then for a given `_address_`:`_port_` pair a separate `bind()` call will always be made.\\n\\n`ipv6only`\\\\=`on`|`off`\\n\\nthis parameter determines (via the `IPV6_V6ONLY` socket option) whether an IPv6 socket listening on a wildcard address `[::]` will accept only IPv6 connections or both IPv6 and IPv4 connections. This parameter is turned on by default. It can only be set once on start.\\n\\n`reuseport`\\n\\nthis parameter (1.9.1) instructs to create an individual listening socket for each worker process (using the `SO_REUSEPORT` socket option on Linux 3.9+ and DragonFly BSD, or `SO_REUSEPORT_LB` on FreeBSD 12+), allowing a kernel to distribute incoming connections between worker processes. This currently works only on Linux\xa03.9+, DragonFly BSD, and FreeBSD 12+ (1.15.1).\\n\\n> Inappropriate use of this option may have its security [implications](http://man7.org/linux/man-pages/man7/socket.7.html).\\n\\n`so_keepalive`\\\\=`on`|`off`|\\\\[`_keepidle_`\\\\]:\\\\[`_keepintvl_`\\\\]:\\\\[`_keepcnt_`\\\\]\\n\\nthis parameter configures the \u201cTCP keepalive\u201d behavior for the listening socket. If this parameter is omitted then the operating system\u2019s settings will be in effect for the socket. If it is set to the value \u201c`on`\u201d, the `SO_KEEPALIVE` option is turned on for the socket. If it is set to the value \u201c`off`\u201d, the `SO_KEEPALIVE` option is turned off for the socket. Some operating systems support setting of TCP keepalive parameters on a per-socket basis using the `TCP_KEEPIDLE`, `TCP_KEEPINTVL`, and `TCP_KEEPCNT` socket options. On such systems (currently, Linux\xa02.4+, NetBSD\xa05+, and FreeBSD\xa09.0-STABLE), they can be configured using the `_keepidle_`, `_keepintvl_`, and `_keepcnt_` parameters. One or two parameters may be omitted, in which case the system default setting for the corresponding socket option will be in effect. For example,\\n\\n> so\\\\_keepalive=30m::10\\n\\nwill set the idle timeout (`TCP_KEEPIDLE`) to 30 minutes, leave the probe interval (`TCP_KEEPINTVL`) at its system default, and set the probes count (`TCP_KEEPCNT`) to 10 probes.\\n\\nDifferent servers must listen on different `_address_`:`_port_` pairs."},{"m":"ngx_stream_core_module","n":"preread_buffer_size","d":"Specifies a `_size_` of the [preread](stream_processing.html#preread_phase) buffer."},{"m":"ngx_stream_core_module","n":"preread_timeout","d":"Specifies a `_timeout_` of the [preread](stream_processing.html#preread_phase) phase."},{"m":"ngx_stream_core_module","n":"proxy_protocol_timeout","d":"Specifies a `_timeout_` for reading the PROXY protocol header to complete. If no entire header is transmitted within this time, the connection is closed."},{"m":"ngx_stream_core_module","n":"resolver","d":"Configures name servers used to resolve names of upstream servers into addresses, for example:\\n```\\nresolver 127.0.0.1 [::1]:5353;\\n\\n```\\nThe address can be specified as a domain name or IP address, with an optional port. If port is not specified, the port 53 is used. Name servers are queried in a round-robin fashion."},{"m":"ngx_stream_core_module","n":"resolver_ipv6","d":"By default, nginx will look up both IPv4 and IPv6 addresses while resolving. If looking up of IPv6 addresses is not desired, the `ipv6=off` parameter can be specified."},{"m":"ngx_stream_core_module","n":"resolver_valid","d":"By default, nginx caches answers using the TTL value of a response. The optional `valid` parameter allows overriding it:\\n```\\nresolver 127.0.0.1 [::1]:5353 valid=30s;\\n\\n```\\n\\nTo prevent DNS spoofing, it is recommended configuring DNS servers in a properly secured trusted local network.\\n"},{"m":"ngx_stream_core_module","n":"resolver_status_zone","d":"The optional `status_zone` parameter (1.17.1) enables [collection](../http/ngx_http_api_module.html#resolvers_) of DNS server statistics of requests and responses in the specified `_zone_`. The parameter is available as part of our [commercial subscription](http://nginx.com/products/).\\n\\nBefore version 1.11.3, this directive was available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_stream_core_module","n":"resolver_timeout","d":"Sets a timeout for name resolution, for example:\\n```\\nresolver_timeout 5s;\\n\\n```\\n\\nBefore version 1.11.3, this directive was available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_stream_core_module","n":"server","d":"Sets the configuration for a server."},{"m":"ngx_stream_core_module","n":"stream","d":"Provides the configuration file context in which the stream server directives are specified."},{"m":"ngx_stream_core_module","n":"tcp_nodelay","d":"Enables or disables the use of the `TCP_NODELAY` option. The option is enabled for both client and proxied server connections."},{"m":"ngx_stream_core_module","n":"variables_hash_bucket_size","d":"Sets the bucket size for the variables hash table. The details of setting up hash tables are provided in a separate [document](../hash.html)."},{"m":"ngx_stream_core_module","n":"variables_hash_max_size","d":"Sets the maximum `_size_` of the variables hash table. The details of setting up hash tables are provided in a separate [document](../hash.html)."},{"m":"ngx_stream_core_module","n":"$binary_remote_addr","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$bytes_received","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$bytes_sent","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$connection","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$hostname","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$msec","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$nginx_version","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$pid","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$protocol","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$proxy_protocol_addr","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$proxy_protocol_port","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$proxy_protocol_server_addr","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$proxy_protocol_server_port","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$remote_addr","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$remote_port","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$server_addr","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$server_port","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$session_time","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$status","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$time_iso8601","d":"local time in the Common Log Format"},{"m":"ngx_stream_core_module","n":"$time_local","d":"local time in the Common Log Format"},{"m":"ngx_stream_access_module","n":"summary","d":"The `ngx_stream_access_module` module (1.9.2) allows limiting access to certain client addresses."},{"m":"ngx_stream_access_module","n":"allow","d":"Allows access for the specified network or address. If the special value `unix:` is specified, allows access for all UNIX-domain sockets."},{"m":"ngx_stream_geo_module","n":"summary","d":"The `ngx_stream_geo_module` module (1.11.3) creates variables with values depending on the client IP address."},{"m":"ngx_stream_geoip_module","n":"summary","d":"The `ngx_stream_geoip_module` module (1.11.3) creates variables with values depending on the client IP address, using the precompiled [MaxMind](http://www.maxmind.com) databases.\\nWhen using the databases with IPv6 support, IPv4 addresses are looked up as IPv4-mapped IPv6 addresses.\\nThis module is not built by default, it should be enabled with the `--with-stream_geoip_module` configuration parameter.\\nThis module requires the [MaxMind GeoIP](http://www.maxmind.com/app/c) library.\\n"},{"m":"ngx_stream_geoip_module","n":"geoip_country","d":"Specifies a database used to determine the country depending on the client IP address. The following variables are available when using this database:\\n`$geoip_country_code`\\n\\ntwo-letter country code, for example, \u201c`RU`\u201d, \u201c`US`\u201d.\\n\\n`$geoip_country_code3`\\n\\nthree-letter country code, for example, \u201c`RUS`\u201d, \u201c`USA`\u201d.\\n\\n`$geoip_country_name`\\n\\ncountry name, for example, \u201c`Russian Federation`\u201d, \u201c`United States`\u201d.\\n"},{"m":"ngx_stream_geoip_module","n":"geoip_city","d":"Specifies a database used to determine the country, region, and city depending on the client IP address. The following variables are available when using this database:\\n`$geoip_area_code`\\n\\ntelephone area code (US only).\\n\\n> This variable may contain outdated information since the corresponding database field is deprecated.\\n\\n`$geoip_city_continent_code`\\n\\ntwo-letter continent code, for example, \u201c`EU`\u201d, \u201c`NA`\u201d.\\n\\n`$geoip_city_country_code`\\n\\ntwo-letter country code, for example, \u201c`RU`\u201d, \u201c`US`\u201d.\\n\\n`$geoip_city_country_code3`\\n\\nthree-letter country code, for example, \u201c`RUS`\u201d, \u201c`USA`\u201d.\\n\\n`$geoip_city_country_name`\\n\\ncountry name, for example, \u201c`Russian Federation`\u201d, \u201c`United States`\u201d.\\n\\n`$geoip_dma_code`\\n\\nDMA region code in US (also known as \u201cmetro code\u201d), according to the [geotargeting](https://developers.google.com/adwords/api/docs/appendix/cities-DMAregions) in Google AdWords API.\\n\\n`$geoip_latitude`\\n\\nlatitude.\\n\\n`$geoip_longitude`\\n\\nlongitude.\\n\\n`$geoip_region`\\n\\ntwo-symbol country region code (region, territory, state, province, federal land and the like), for example, \u201c`48`\u201d, \u201c`DC`\u201d.\\n\\n`$geoip_region_name`\\n\\ncountry region name (region, territory, state, province, federal land and the like), for example, \u201c`Moscow City`\u201d, \u201c`District of Columbia`\u201d.\\n\\n`$geoip_city`\\n\\ncity name, for example, \u201c`Moscow`\u201d, \u201c`Washington`\u201d.\\n\\n`$geoip_postal_code`\\n\\npostal code.\\n"},{"m":"ngx_stream_js_module","n":"summary","d":"The `ngx_stream_js_module` module is used to implement handlers in [njs](../njs/index.html)\xa0\u2014 a subset of the JavaScript language.\\nDownload and install instructions are available [here](../njs/install.html)."},{"m":"ngx_stream_js_module","n":"js_access","d":"Sets an njs function which will be called at the [access](stream_processing.html#access_phase) phase. Since [0.4.0](../njs/changes.html#njs0.4.0), a module function can be referenced."},{"m":"ngx_stream_js_module","n":"js_filter","d":"Sets a data filter. Since [0.4.0](../njs/changes.html#njs0.4.0), a module function can be referenced."},{"m":"ngx_stream_js_module","n":"js_import","d":"Imports a module that implements location and variable handlers in njs. The `export_name` is used as a namespace to access module functions. If the `export_name` is not specified, the module name will be used as a namespace.\\n```\\njs_import stream.js;\\n\\n```\\nHere, the module name `stream` is used as a namespace while accessing exports. If the imported module contains `foo()`, `stream.foo` is used to refer to it.\\nSeveral `js_import` directives can be specified."},{"m":"ngx_stream_js_module","n":"js_include","d":"Specifies a file that implements server and variable handlers in njs:\\n```\\nnginx.conf:\\njs_include stream.js;\\njs_set     $js_addr address;\\nserver {\\n    listen 127.0.0.1:12345;\\n    return $js_addr;\\n}\\n\\nstream.js:\\nfunction address(s) {\\n    return s.remoteAddress;\\n}\\n\\n```\\n\\nThe directive is deprecated since [0.4.0](../njs/changes.html#njs0.4.0), the [js\\\\_import](#js_import) directive should be used instead."},{"m":"ngx_stream_js_module","n":"js_path","d":"Sets an additional path for njs modules."},{"m":"ngx_stream_js_module","n":"js_preread","d":"Sets an njs function which will be called at the [preread](stream_processing.html#preread_phase) phase. Since [0.4.0](../njs/changes.html#njs0.4.0), a module function can be referenced."},{"m":"ngx_stream_js_module","n":"js_set","d":"Sets an njs function for the specified variable. Since [0.4.0](../njs/changes.html#njs0.4.0), a module function can be referenced."},{"m":"ngx_stream_keyval_module","n":"summary","d":"The `ngx_stream_keyval_module` module (1.13.7) creates variables with values taken from key-value pairs managed by the [API](../http/ngx_http_api_module.html#stream_keyvals_).\\n\\nThis module is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_stream_keyval_module","n":"keyval","d":"Creates a new `_$variable_` whose value is looked up by the `_key_` in the key-value database. Matching rules are defined by the [`type`](#keyval_type) parameter of the [`keyval_zone`](#keyval_zone) directive. The database is stored in a shared memory zone specified by the `zone` parameter."},{"m":"ngx_stream_keyval_module","n":"keyval_zone","d":"Sets the `_name_` and `_size_` of the shared memory zone that keeps the key-value database. Key-value pairs are managed by the [API](../http/ngx_http_api_module.html#stream_keyvals_)."},{"m":"ngx_stream_keyval_module","n":"keyval_state","d":"The optional `state` parameter specifies a `_file_` that keeps the current state of the key-value database in the JSON format and makes it persistent across nginx restarts.\\nExamples:\\n```\\nkeyval_zone zone=one:32k state=/var/lib/nginx/state/one.keyval; # path for Linux\\nkeyval_zone zone=one:32k state=/var/db/nginx/state/one.keyval;  # path for FreeBSD\\n\\n```\\n"},{"m":"ngx_stream_keyval_module","n":"keyval_timeout","d":"The optional `timeout` parameter (1.15.0) sets the time after which key-value pairs are removed from the zone."},{"m":"ngx_stream_keyval_module","n":"keyval_type","d":"The optional `type` parameter (1.17.1) activates an extra index optimized for matching the key of a certain type and defines matching rules when evaluating a [keyval](#keyval) `$variable`.\\nThe index is stored in the same shared memory zone and thus requires additional storage.\\n\\n`type=string`\\n\\ndefault, no index is enabled; variable lookup is performed using exact match of the record key and a search key\\n\\n`type=ip`\\n\\nthe search key is the textual representation of IPv4 or IPv6 address or CIDR range; to match a record key, the search key must belong to a subnet specified by a record key or exactly match an IP address\\n\\n`type=prefix`\\n\\nvariable lookup is performed using prefix match of a record key and a search key (1.17.5); to match a record key, the record key must be a prefix of the search key\\n"},{"m":"ngx_stream_limit_conn_module","n":"summary","d":"The `ngx_stream_limit_conn_module` module (1.9.3) is used to limit the number of connections per the defined key, in particular, the number of connections from a single IP address."},{"m":"ngx_stream_limit_conn_module","n":"limit_conn","d":"Sets the shared memory zone and the maximum allowed number of connections for a given key value. When this limit is exceeded, the server will close the connection. For example, the directives\\n```\\nlimit_conn_zone $binary_remote_addr zone=addr:10m;\\n\\nserver {\\n    ...\\n    limit_conn addr 1;\\n}\\n\\n```\\nallow only one connection per an IP address at a time.\\nWhen several `limit_conn` directives are specified, any configured limit will apply.\\nThese directives are inherited from the previous configuration level if and only if there are no `limit_conn` directives defined on the current level."},{"m":"ngx_stream_limit_conn_module","n":"limit_conn_dry_run","d":"Enables the dry run mode. In this mode, the number of connections is not limited, however, in the shared memory zone, the number of excessive connections is accounted as usual."},{"m":"ngx_stream_limit_conn_module","n":"limit_conn_log_level","d":"Sets the desired logging level for cases when the server limits the number of connections."},{"m":"ngx_stream_limit_conn_module","n":"limit_conn_zone","d":"Sets parameters for a shared memory zone that will keep states for various keys. In particular, the state includes the current number of connections. The `_key_` can contain text, variables, and their combinations (1.11.2). Connections with an empty key value are not accounted. Usage example:\\n```\\nlimit_conn_zone $binary_remote_addr zone=addr:10m;\\n\\n```\\nHere, the key is a client IP address set by the `$binary_remote_addr` variable. The size of `$binary_remote_addr` is 4 bytes for IPv4 addresses or 16 bytes for IPv6 addresses. The stored state always occupies 32 or 64 bytes on 32-bit platforms and 64 bytes on 64-bit platforms. One megabyte zone can keep about 32 thousand 32-byte states or about 16 thousand 64-byte states. If the zone storage is exhausted, the server will close the connection.\\n\\nAdditionally, as part of our [commercial subscription](http://nginx.com/products/), the [status information](../http/ngx_http_api_module.html#stream_limit_conns_) for each such shared memory zone can be [obtained](../http/ngx_http_api_module.html#getStreamLimitConnZone) or [reset](../http/ngx_http_api_module.html#deleteStreamLimitConnZoneStat) with the [API](../http/ngx_http_api_module.html) since 1.17.7.\\n"},{"m":"ngx_stream_limit_conn_module","n":"$limit_conn_status","d":"keeps the result of limiting the number of connections (1.17.6): `PASSED`, `REJECTED`, or `REJECTED_DRY_RUN`"},{"m":"ngx_stream_log_module","n":"summary","d":"The `ngx_stream_log_module` module (1.11.4) writes session logs in the specified format."},{"m":"ngx_stream_log_module","n":"access_log","d":"Sets the path, [format](#log_format), and configuration for a buffered log write. Several logs can be specified on the same configuration level. Logging to [syslog](../syslog.html) can be configured by specifying the \u201c`syslog:`\u201d prefix in the first parameter. The special value `off` cancels all `access_log` directives on the current level.\\nIf either the `buffer` or `gzip` parameter is used, writes to log will be buffered.\\nThe buffer size must not exceed the size of an atomic write to a disk file. For FreeBSD this size is unlimited.\\n\\nWhen buffering is enabled, the data will be written to the file:\\n*   if the next log line does not fit into the buffer;\\n*   if the buffered data is older than specified by the `flush` parameter;\\n*   when a worker process is [re-opening](../control.html) log files or is shutting down.\\n\\nIf the `gzip` parameter is used, then the buffered data will be compressed before writing to the file. The compression level can be set between 1 (fastest, less compression) and 9 (slowest, best compression). By default, the buffer size is equal to 64K bytes, and the compression level is set to 1. Since the data is compressed in atomic blocks, the log file can be decompressed or read by \u201c`zcat`\u201d at any time.\\nExample:\\n```\\naccess_log /path/to/log.gz basic gzip flush=5m;\\n\\n```\\n\\n\\nFor gzip compression to work, nginx must be built with the zlib library.\\n\\nThe file path can contain variables, but such logs have some constraints:\\n*   the [user](../ngx_core_module.html#user) whose credentials are used by worker processes should have permissions to create files in a directory with such logs;\\n*   buffered writes do not work;\\n*   the file is opened and closed for each log write. However, since the descriptors of frequently used files can be stored in a [cache](#open_log_file_cache), writing to the old file can continue during the time specified by the [open\\\\_log\\\\_file\\\\_cache](#open_log_file_cache) directive\u2019s `valid` parameter\\n\\nThe `if` parameter enables conditional logging. A session will not be logged if the `_condition_` evaluates to \u201c0\u201d or an empty string."},{"m":"ngx_stream_log_module","n":"log_format","d":"Specifies the log format, for example:\\n```\\nlog_format proxy \'$remote_addr [$time_local] \'\\n                 \'$protocol $status $bytes_sent $bytes_received \'\\n                 \'$session_time \\"$upstream_addr\\" \'\\n                 \'\\"$upstream_bytes_sent\\" \\"$upstream_bytes_received\\" \\"$upstream_connect_time\\"\';\\n\\n```\\n"},{"m":"ngx_stream_log_module","n":"log_format_escape","d":"The `escape` parameter (1.11.8) allows setting `json` or `default` characters escaping in variables, by default, `default` escaping is used. The `none` parameter (1.13.10) disables escaping."},{"m":"ngx_stream_log_module","n":"log_format_escape_default","d":"For `default` escaping, characters \u201c`\\"`\u201d, \u201c`\\\\`\u201d, and other characters with values less than 32 or above 126 are escaped as \u201c`\\\\xXX`\u201d. If the variable value is not found, a hyphen (\u201c`-`\u201d) will be logged."},{"m":"ngx_stream_log_module","n":"log_format_escape_json","d":"For `json` escaping, all characters not allowed in JSON [strings](https://tools.ietf.org/html/rfc8259#section-7) will be escaped: characters \u201c`\\"`\u201d and \u201c`\\\\`\u201d are escaped as \u201c`\\\\\\"`\u201d and \u201c`\\\\\\\\`\u201d, characters with values less than 32 are escaped as \u201c`\\\\n`\u201d, \u201c`\\\\r`\u201d, \u201c`\\\\t`\u201d, \u201c`\\\\b`\u201d, \u201c`\\\\f`\u201d, or \u201c`\\\\u00XX`\u201d."},{"m":"ngx_stream_map_module","n":"summary","d":"The `ngx_stream_map_module` module (1.11.2) creates variables whose values depend on values of other variables."},{"m":"ngx_stream_map_module","n":"map","d":"Creates a new variable whose value depends on values of one or more of the source variables specified in the first parameter.\\n\\nSince variables are evaluated only when they are used, the mere declaration even of a large number of \u201c`map`\u201d variables does not add any extra costs to connection processing.\\n\\nParameters inside the `map` block specify a mapping between source and resulting values.\\nSource values are specified as strings or regular expressions.\\nStrings are matched ignoring the case.\\nA regular expression should either start from the \u201c`~`\u201d symbol for a case-sensitive matching, or from the \u201c`~*`\u201d symbols for case-insensitive matching. A regular expression can contain named and positional captures that can later be used in other directives along with the resulting variable.\\nIf a source value matches one of the names of special parameters described below, it should be prefixed with the \u201c`\\\\`\u201d symbol.\\nThe resulting value can contain text, variable, and their combination.\\nThe following special parameters are also supported:\\n`default` `_value_`\\n\\nsets the resulting value if the source value matches none of the specified variants. When `default` is not specified, the default resulting value will be an empty string.\\n\\n`hostnames`\\n\\nindicates that source values can be hostnames with a prefix or suffix mask:\\n\\n> \\\\*.example.com 1;\\n> example.\\\\*     1;\\n\\nThe following two records\\n\\n> example.com   1;\\n> \\\\*.example.com 1;\\n\\ncan be combined:\\n\\n> .example.com  1;\\n\\nThis parameter should be specified before the list of values.\\n\\n`include` `_file_`\\n\\nincludes a file with values. There can be several inclusions.\\n\\n`volatile`\\n\\nindicates that the variable is not cacheable (1.11.7).\\n\\nIf the source value matches more than one of the specified variants, e.g. both a mask and a regular expression match, the first matching variant will be chosen, in the following order of priority:\\n*   string value without a mask\\n*   longest string value with a prefix mask, e.g. \u201c`*.example.com`\u201d\\n*   longest string value with a suffix mask, e.g. \u201c`mail.*`\u201d\\n*   first matching regular expression (in order of appearance in a configuration file)\\n*   default value\\n"},{"m":"ngx_stream_map_module","n":"map_hash_bucket_size","d":"Sets the bucket size for the [map](#map) variables hash tables. Default value depends on the processor\u2019s cache line size. The details of setting up hash tables are provided in a separate [document](../hash.html)."},{"m":"ngx_stream_proxy_module","n":"summary","d":"The `ngx_stream_proxy_module` module (1.9.0) allows proxying data streams over TCP, UDP (1.9.13), and UNIX-domain sockets."},{"m":"ngx_stream_proxy_module","n":"proxy_bind","d":"Makes outgoing connections to a proxied server originate from the specified local IP `_address_`. Parameter value can contain variables (1.11.2). The special value `off` cancels the effect of the `proxy_bind` directive inherited from the previous configuration level, which allows the system to auto-assign the local IP address."},{"m":"ngx_stream_proxy_module","n":"proxy_bind_transparent","d":"The `transparent` parameter (1.11.0) allows outgoing connections to a proxied server originate from a non-local IP address, for example, from a real IP address of a client:\\n```\\nproxy_bind $remote_addr transparent;\\n\\n```\\nIn order for this parameter to work, it is usually necessary to run nginx worker processes with the [superuser](../ngx_core_module.html#user) privileges. On Linux it is not required (1.13.8) as if the `transparent` parameter is specified, worker processes inherit the `CAP_NET_RAW` capability from the master process. It is also necessary to configure kernel routing table to intercept network traffic from the proxied server."},{"m":"ngx_stream_proxy_module","n":"proxy_buffer_size","d":"Sets the `_size_` of the buffer used for reading data from the proxied server. Also sets the `_size_` of the buffer used for reading data from the client."},{"m":"ngx_stream_proxy_module","n":"proxy_connect_timeout","d":"Defines a timeout for establishing a connection with a proxied server."},{"m":"ngx_stream_proxy_module","n":"proxy_download_rate","d":"Limits the speed of reading the data from the proxied server. The `_rate_` is specified in bytes per second. The zero value disables rate limiting. The limit is set per a connection, so if nginx simultaneously opens two connections to the proxied server, the overall rate will be twice as much as the specified limit.\\nParameter value can contain variables (1.17.0). It may be useful in cases where rate should be limited depending on a certain condition:\\n```\\nmap $slow $rate {\\n    1     4k;\\n    2     8k;\\n}\\n\\nproxy_download_rate $rate;\\n\\n```\\n"},{"m":"ngx_stream_proxy_module","n":"proxy_next_upstream","d":"When a connection to the proxied server cannot be established, determines whether a client connection will be passed to the next server.\\nPassing a connection to the next server can be limited by [the number of tries](#proxy_next_upstream_tries) and by [time](#proxy_next_upstream_timeout)."},{"m":"ngx_stream_proxy_module","n":"proxy_next_upstream_timeout","d":"Limits the time allowed to pass a connection to the [next server](#proxy_next_upstream). The `0` value turns off this limitation."},{"m":"ngx_stream_proxy_module","n":"proxy_next_upstream_tries","d":"Limits the number of possible tries for passing a connection to the [next server](#proxy_next_upstream). The `0` value turns off this limitation."},{"m":"ngx_stream_proxy_module","n":"proxy_pass","d":"Sets the address of a proxied server. The address can be specified as a domain name or IP address, and a port:\\n```\\nproxy_pass localhost:12345;\\n\\n```\\nor as a UNIX-domain socket path:\\n```\\nproxy_pass unix:/tmp/stream.socket;\\n\\n```\\n\\nIf a domain name resolves to several addresses, all of them will be used in a round-robin fashion. In addition, an address can be specified as a [server group](ngx_stream_upstream_module.html).\\nThe address can also be specified using variables (1.11.3):\\n```\\nproxy_pass $upstream;\\n\\n```\\nIn this case, the server name is searched among the described [server groups](ngx_stream_upstream_module.html), and, if not found, is determined using a [resolver](ngx_stream_core_module.html#resolver)."},{"m":"ngx_stream_proxy_module","n":"proxy_protocol","d":"Enables the [PROXY protocol](http://www.haproxy.org/download/1.5/doc/proxy-protocol.txt) for connections to a proxied server."},{"m":"ngx_stream_proxy_module","n":"proxy_requests","d":"Sets the number of client datagrams at which binding between a client and existing UDP stream session is dropped. After receiving the specified number of datagrams, next datagram from the same client starts a new session. The session terminates when all client datagrams are transmitted to a proxied server and the expected number of [responses](#proxy_responses) is received, or when it reaches a [timeout](#proxy_timeout)."},{"m":"ngx_stream_proxy_module","n":"proxy_responses","d":"Sets the number of datagrams expected from the proxied server in response to a client datagram if the [UDP](ngx_stream_core_module.html#udp) protocol is used. The number serves as a hint for session termination. By default, the number of datagrams is not limited.\\nIf zero value is specified, no response is expected. However, if a response is received and the session is still not finished, the response will be handled."},{"m":"ngx_stream_proxy_module","n":"proxy_session_drop","d":"Enables terminating all sessions to a proxied server after it was removed from the group or marked as permanently unavailable. This can occur because of [re-resolve](ngx_stream_core_module.html#resolver) or with the API [`DELETE`](../http/ngx_http_api_module.html#deleteStreamUpstreamServer) command. A server can be marked as permanently unavailable if it is considered [unhealthy](ngx_stream_upstream_hc_module.html#health_check) or with the API [`PATCH`](../http/ngx_http_api_module.html#patchStreamUpstreamServer) command. Each session is terminated when the next read or write event is processed for the client or proxied server.\\n\\nThis directive is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_stream_proxy_module","n":"proxy_socket_keepalive","d":"Configures the \u201cTCP keepalive\u201d behavior for outgoing connections to a proxied server. By default, the operating system\u2019s settings are in effect for the socket. If the directive is set to the value \u201c`on`\u201d, the `SO_KEEPALIVE` socket option is turned on for the socket."},{"m":"ngx_stream_proxy_module","n":"proxy_ssl","d":"Enables the SSL/TLS protocol for connections to a proxied server."},{"m":"ngx_stream_proxy_module","n":"proxy_ssl_certificate","d":"Specifies a `_file_` with the certificate in the PEM format used for authentication to a proxied server."},{"m":"ngx_stream_proxy_module","n":"proxy_ssl_certificate_key","d":"Specifies a `_file_` with the secret key in the PEM format used for authentication to a proxied server."},{"m":"ngx_stream_proxy_module","n":"proxy_ssl_ciphers","d":"Specifies the enabled ciphers for connections to a proxied server. The ciphers are specified in the format understood by the OpenSSL library.\\nThe full list can be viewed using the \u201c`openssl ciphers`\u201d command."},{"m":"ngx_stream_proxy_module","n":"proxy_ssl_conf_command","d":"Sets arbitrary OpenSSL configuration [commands](https://www.openssl.org/docs/man1.1.1/man3/SSL_CONF_cmd.html) when establishing a connection with the proxied server.\\nThe directive is supported when using OpenSSL 1.0.2 or higher.\\n\\nSeveral `proxy_ssl_conf_command` directives can be specified on the same level. These directives are inherited from the previous configuration level if and only if there are no `proxy_ssl_conf_command` directives defined on the current level.\\n\\nNote that configuring OpenSSL directly might result in unexpected behavior.\\n"},{"m":"ngx_stream_proxy_module","n":"proxy_ssl_crl","d":"Specifies a `_file_` with revoked certificates (CRL) in the PEM format used to [verify](#proxy_ssl_verify) the certificate of the proxied server."},{"m":"ngx_stream_proxy_module","n":"proxy_ssl_name","d":"Allows overriding the server name used to [verify](#proxy_ssl_verify) the certificate of the proxied server and to be [passed through SNI](#proxy_ssl_server_name) when establishing a connection with the proxied server. The server name can also be specified using variables (1.11.3).\\nBy default, the host part of the [proxy\\\\_pass](#proxy_pass) address is used."},{"m":"ngx_stream_proxy_module","n":"proxy_ssl_password_file","d":"Specifies a `_file_` with passphrases for [secret keys](#proxy_ssl_certificate_key) where each passphrase is specified on a separate line. Passphrases are tried in turn when loading the key."},{"m":"ngx_stream_proxy_module","n":"proxy_ssl_protocols","d":"Enables the specified protocols for connections to a proxied server."},{"m":"ngx_stream_proxy_module","n":"proxy_ssl_server_name","d":"Enables or disables passing of the server name through [TLS Server Name Indication extension](http://en.wikipedia.org/wiki/Server_Name_Indication) (SNI, RFC 6066) when establishing a connection with the proxied server."},{"m":"ngx_stream_proxy_module","n":"proxy_ssl_session_reuse","d":"Determines whether SSL sessions can be reused when working with the proxied server. If the errors \u201c`SSL3_GET_FINISHED:digest check failed`\u201d appear in the logs, try disabling session reuse."},{"m":"ngx_stream_proxy_module","n":"proxy_ssl_trusted_certificate","d":"Specifies a `_file_` with trusted CA certificates in the PEM format used to [verify](#proxy_ssl_verify) the certificate of the proxied server."},{"m":"ngx_stream_proxy_module","n":"proxy_ssl_verify","d":"Enables or disables verification of the proxied server certificate."},{"m":"ngx_stream_proxy_module","n":"proxy_ssl_verify_depth","d":"Sets the verification depth in the proxied server certificates chain."},{"m":"ngx_stream_proxy_module","n":"proxy_timeout","d":"Sets the `_timeout_` between two successive read or write operations on client or proxied server connections. If no data is transmitted within this time, the connection is closed."},{"m":"ngx_stream_realip_module","n":"summary","d":"The `ngx_stream_realip_module` module is used to change the client address and port to the ones sent in the PROXY protocol header (1.11.4). The PROXY protocol must be previously enabled by setting the [proxy\\\\_protocol](ngx_stream_core_module.html#proxy_protocol) parameter in the `listen` directive.\\nThis module is not built by default, it should be enabled with the `--with-stream_realip_module` configuration parameter."},{"m":"ngx_stream_realip_module","n":"set_real_ip_from","d":"Defines trusted addresses that are known to send correct replacement addresses. If the special value `unix:` is specified, all UNIX-domain sockets will be trusted."},{"m":"ngx_stream_realip_module","n":"$realip_remote_addr","d":"keeps the original client port"},{"m":"ngx_stream_realip_module","n":"$realip_remote_port","d":"keeps the original client port"},{"m":"ngx_stream_return_module","n":"summary","d":"The `ngx_stream_return_module` module (1.11.2) allows sending a specified value to the client and then closing the connection."},{"m":"ngx_stream_set_module","n":"summary","d":"The `ngx_stream_set_module` module (1.19.3) allows setting a value for a variable."},{"m":"ngx_stream_split_clients_module","n":"summary","d":"The `ngx_stream_split_clients_module` module (1.11.3) creates variables suitable for A/B testing, also known as split testing."},{"m":"ngx_stream_ssl_module","n":"summary","d":"The `ngx_stream_ssl_module` module (1.9.0) provides the necessary support for a stream proxy server to work with the SSL/TLS protocol. This module is not built by default, it should be enabled with the `--with-stream_ssl_module` configuration parameter."},{"m":"ngx_stream_ssl_module","n":"ssl_certificate","d":"Specifies a `_file_` with the certificate in the PEM format for the given server. If intermediate certificates should be specified in addition to a primary certificate, they should be specified in the same file in the following order: the primary certificate comes first, then the intermediate certificates. A secret key in the PEM format may be placed in the same file.\\nSince version 1.11.0, this directive can be specified multiple times to load certificates of different types, for example, RSA and ECDSA:\\n```\\nserver {\\n    listen              12345 ssl;\\n\\n    ssl_certificate     example.com.rsa.crt;\\n    ssl_certificate_key example.com.rsa.key;\\n\\n    ssl_certificate     example.com.ecdsa.crt;\\n    ssl_certificate_key example.com.ecdsa.key;\\n\\n    ...\\n}\\n\\n```\\n\\nOnly OpenSSL 1.0.2 or higher supports separate certificate chains for different certificates. With older versions, only one certificate chain can be used.\\n\\nSince version 1.15.9, variables can be used in the `_file_` name when using OpenSSL 1.0.2 or higher:\\n```\\nssl_certificate     $ssl_server_name.crt;\\nssl_certificate_key $ssl_server_name.key;\\n\\n```\\nNote that using variables implies that a certificate will be loaded for each SSL handshake, and this may have a negative impact on performance."},{"m":"ngx_stream_ssl_module","n":"ssl_certificate_data","d":"The value `data`:`_$variable_` can be specified instead of the `_file_` (1.15.10), which loads a certificate from a variable without using intermediate files. Note that inappropriate use of this syntax may have its security implications, such as writing secret key data to [error log](../ngx_core_module.html#error_log)."},{"m":"ngx_stream_ssl_module","n":"ssl_certificate_key","d":"Specifies a `_file_` with the secret key in the PEM format for the given server.\\nThe value `engine`:`_name_`:`_id_` can be specified instead of the `_file_`, which loads a secret key with a specified `_id_` from the OpenSSL engine `_name_`."},{"m":"ngx_stream_ssl_module","n":"ssl_certificate_key_data","d":"The value `data`:`_$variable_` can be specified instead of the `_file_` (1.15.10), which loads a secret key from a variable without using intermediate files. Note that inappropriate use of this syntax may have its security implications, such as writing secret key data to [error log](../ngx_core_module.html#error_log).\\nSince version 1.15.9, variables can be used in the `_file_` name when using OpenSSL 1.0.2 or higher."},{"m":"ngx_stream_ssl_module","n":"ssl_ciphers","d":"Specifies the enabled ciphers. The ciphers are specified in the format understood by the OpenSSL library, for example:\\n```\\nssl_ciphers ALL:!aNULL:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP;\\n\\n```\\n\\nThe full list can be viewed using the \u201c`openssl ciphers`\u201d command."},{"m":"ngx_stream_ssl_module","n":"ssl_client_certificate","d":"Specifies a `_file_` with trusted CA certificates in the PEM format used to [verify](#ssl_verify_client) client certificates.\\nThe list of certificates will be sent to clients. If this is not desired, the [ssl\\\\_trusted\\\\_certificate](#ssl_trusted_certificate) directive can be used."},{"m":"ngx_stream_ssl_module","n":"ssl_conf_command","d":"Sets arbitrary OpenSSL configuration [commands](https://www.openssl.org/docs/man1.1.1/man3/SSL_CONF_cmd.html).\\nThe directive is supported when using OpenSSL 1.0.2 or higher.\\n\\nSeveral `ssl_conf_command` directives can be specified on the same level:\\n```\\nssl_conf_command Options PrioritizeChaCha;\\nssl_conf_command Ciphersuites TLS_CHACHA20_POLY1305_SHA256;\\n\\n```\\nThese directives are inherited from the previous configuration level if and only if there are no `ssl_conf_command` directives defined on the current level.\\n\\nNote that configuring OpenSSL directly might result in unexpected behavior.\\n"},{"m":"ngx_stream_ssl_module","n":"ssl_crl","d":"Specifies a `_file_` with revoked certificates (CRL) in the PEM format used to [verify](#ssl_verify_client) client certificates."},{"m":"ngx_stream_ssl_module","n":"ssl_dhparam","d":"Specifies a `_file_` with DH parameters for DHE ciphers.\\nBy default no parameters are set, and therefore DHE ciphers will not be used.\\nPrior to version 1.11.0, builtin parameters were used by default.\\n"},{"m":"ngx_stream_ssl_module","n":"ssl_ecdh_curve","d":"Specifies a `_curve_` for ECDHE ciphers.\\nWhen using OpenSSL 1.0.2 or higher, it is possible to specify multiple curves (1.11.0), for example:\\n```\\nssl_ecdh_curve prime256v1:secp384r1;\\n\\n```\\n\\nThe special value `auto` (1.11.0) instructs nginx to use a list built into the OpenSSL library when using OpenSSL 1.0.2 or higher, or `prime256v1` with older versions.\\n\\nPrior to version 1.11.0, the `prime256v1` curve was used by default.\\n\\n\\nWhen using OpenSSL 1.0.2 or higher, this directive sets the list of curves supported by the server. Thus, in order for ECDSA certificates to work, it is important to include the curves used in the certificates.\\n"},{"m":"ngx_stream_ssl_module","n":"ssl_handshake_timeout","d":"Specifies a timeout for the SSL handshake to complete."},{"m":"ngx_stream_ssl_module","n":"ssl_password_file","d":"Specifies a `_file_` with passphrases for [secret keys](#ssl_certificate_key) where each passphrase is specified on a separate line. Passphrases are tried in turn when loading the key.\\nExample:\\n```\\nstream {\\n    ssl_password_file /etc/keys/global.pass;\\n    ...\\n\\n    server {\\n        listen 127.0.0.1:12345;\\n        ssl_certificate_key /etc/keys/first.key;\\n    }\\n\\n    server {\\n        listen 127.0.0.1:12346;\\n\\n        # named pipe can also be used instead of a file\\n        ssl_password_file /etc/keys/fifo;\\n        ssl_certificate_key /etc/keys/second.key;\\n    }\\n}\\n\\n```\\n"},{"m":"ngx_stream_ssl_module","n":"ssl_prefer_server_ciphers","d":"Specifies that server ciphers should be preferred over client ciphers when the SSLv3 and TLS protocols are used."},{"m":"ngx_stream_ssl_module","n":"ssl_protocols","d":"Enables the specified protocols.\\nThe `TLSv1.1` and `TLSv1.2` parameters work only when OpenSSL 1.0.1 or higher is used.\\n\\nThe `TLSv1.3` parameter (1.13.0) works only when OpenSSL 1.1.1 built with TLSv1.3 support is used.\\n"},{"m":"ngx_stream_ssl_module","n":"ssl_session_cache","d":"Sets the types and sizes of caches that store session parameters. A cache can be of any of the following types:\\n`off`\\n\\nthe use of a session cache is strictly prohibited: nginx explicitly tells a client that sessions may not be reused.\\n\\n`none`\\n\\nthe use of a session cache is gently disallowed: nginx tells a client that sessions may be reused, but does not actually store session parameters in the cache.\\n\\n`builtin`\\n\\na cache built in OpenSSL; used by one worker process only. The cache size is specified in sessions. If size is not given, it is equal to 20480 sessions. Use of the built-in cache can cause memory fragmentation.\\n\\n`shared`\\n\\na cache shared between all worker processes. The cache size is specified in bytes; one megabyte can store about 4000 sessions. Each shared cache should have an arbitrary name. A cache with the same name can be used in several servers.\\n\\nBoth cache types can be used simultaneously, for example:\\n```\\nssl_session_cache builtin:1000 shared:SSL:10m;\\n\\n```\\nbut using only shared cache without the built-in cache should be more efficient."},{"m":"ngx_stream_ssl_module","n":"ssl_session_ticket_key","d":"Sets a `_file_` with the secret key used to encrypt and decrypt TLS session tickets. The directive is necessary if the same key has to be shared between multiple servers. By default, a randomly generated key is used.\\nIf several keys are specified, only the first key is used to encrypt TLS session tickets. This allows configuring key rotation, for example:\\n```\\nssl_session_ticket_key current.key;\\nssl_session_ticket_key previous.key;\\n\\n```\\n\\nThe `_file_` must contain 80 or 48 bytes of random data and can be created using the following command:\\n```\\nopenssl rand 80 > ticket.key\\n\\n```\\nDepending on the file size either AES256 (for 80-byte keys, 1.11.8) or AES128 (for 48-byte keys) is used for encryption."},{"m":"ngx_stream_ssl_module","n":"ssl_session_tickets","d":"Enables or disables session resumption through [TLS session tickets](https://tools.ietf.org/html/rfc5077)."},{"m":"ngx_stream_ssl_module","n":"ssl_session_timeout","d":"Specifies a time during which a client may reuse the session parameters."},{"m":"ngx_stream_ssl_module","n":"ssl_trusted_certificate","d":"Specifies a `_file_` with trusted CA certificates in the PEM format used to [verify](#ssl_verify_client) client certificates.\\nIn contrast to the certificate set by [ssl\\\\_client\\\\_certificate](#ssl_client_certificate), the list of these certificates will not be sent to clients."},{"m":"ngx_stream_ssl_module","n":"ssl_verify_client","d":"Enables verification of client certificates. The verification result is stored in the [$ssl\\\\_client\\\\_verify](#var_ssl_client_verify) variable. If an error has occurred during the client certificate verification or a client has not presented the required certificate, the connection is closed.\\nThe `optional` parameter requests the client certificate and verifies it if the certificate is present.\\nThe `optional_no_ca` parameter requests the client certificate but does not require it to be signed by a trusted CA certificate. This is intended for the use in cases when a service that is external to nginx performs the actual certificate verification. The contents of the certificate is accessible through the [$ssl\\\\_client\\\\_cert](#var_ssl_client_cert) variable."},{"m":"ngx_stream_ssl_module","n":"ssl_verify_depth","d":"Sets the verification depth in the client certificates chain."},{"m":"ngx_stream_ssl_module","n":"$ssl_cipher","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise."},{"m":"ngx_stream_ssl_module","n":"$ssl_ciphers","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise."},{"m":"ngx_stream_ssl_module","n":"$ssl_client_cert","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise."},{"m":"ngx_stream_ssl_module","n":"$ssl_client_fingerprint","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise."},{"m":"ngx_stream_ssl_module","n":"$ssl_client_i_dn","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise."},{"m":"ngx_stream_ssl_module","n":"$ssl_client_raw_cert\\n","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise."},{"m":"ngx_stream_ssl_module","n":"$ssl_client_s_dn","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise."},{"m":"ngx_stream_ssl_module","n":"$ssl_client_serial","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise."},{"m":"ngx_stream_ssl_module","n":"$ssl_client_v_end","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise."},{"m":"ngx_stream_ssl_module","n":"$ssl_client_v_remain","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise."},{"m":"ngx_stream_ssl_module","n":"$ssl_client_v_start","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise."},{"m":"ngx_stream_ssl_module","n":"$ssl_client_verify","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise."},{"m":"ngx_stream_ssl_module","n":"$ssl_curves","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise."},{"m":"ngx_stream_ssl_module","n":"$ssl_protocol","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise."},{"m":"ngx_stream_ssl_module","n":"$ssl_server_name","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise."},{"m":"ngx_stream_ssl_module","n":"$ssl_session_id","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise."},{"m":"ngx_stream_ssl_module","n":"$ssl_session_reused","d":"returns \u201c`r`\u201d if an SSL session was reused, or \u201c`.`\u201d otherwise."},{"m":"ngx_stream_ssl_preread_module","n":"summary","d":"The `ngx_stream_ssl_preread_module` module (1.11.5) allows extracting information from the [ClientHello](https://tools.ietf.org/html/rfc5246#section-7.4.1.2) message without terminating SSL/TLS, for example, the server name requested through [SNI](https://tools.ietf.org/html/rfc6066#section-3) or protocols advertised in [ALPN](https://tools.ietf.org/html/rfc7301). This module is not built by default, it should be enabled with the `--with-stream_ssl_preread_module` configuration parameter."},{"m":"ngx_stream_ssl_preread_module","n":"ssl_preread","d":"Enables extracting information from the ClientHello message at the [preread](stream_processing.html#preread_phase) phase."},{"m":"ngx_stream_ssl_preread_module","n":"$ssl_preread_protocol","d":"list of protocols advertised by the client through ALPN (1.13.10). The values are separated by commas."},{"m":"ngx_stream_ssl_preread_module","n":"$ssl_preread_server_name","d":"list of protocols advertised by the client through ALPN (1.13.10). The values are separated by commas."},{"m":"ngx_stream_ssl_preread_module","n":"$ssl_preread_alpn_protocols","d":"list of protocols advertised by the client through ALPN (1.13.10). The values are separated by commas."},{"m":"ngx_stream_upstream_module","n":"summary","d":"The `ngx_stream_upstream_module` module (1.9.0) is used to define groups of servers that can be referenced by the [proxy\\\\_pass](ngx_stream_proxy_module.html#proxy_pass) directive."},{"m":"ngx_stream_upstream_module","n":"upstream","d":"Defines a group of servers. Servers can listen on different ports. In addition, servers listening on TCP and UNIX-domain sockets can be mixed.\\nExample:\\n```\\nupstream backend {\\n    server backend1.example.com:12345 weight=5;\\n    server 127.0.0.1:12345            max_fails=3 fail_timeout=30s;\\n    server unix:/tmp/backend2;\\n    server backend3.example.com:12345 resolve;\\n\\n    server backup1.example.com:12345  backup;\\n}\\n\\n```\\n\\nBy default, connections are distributed between the servers using a weighted round-robin balancing method. In the above example, each 7 connections will be distributed as follows: 5 connections go to `backend1.example.com:12345` and one connection to each of the second and third servers. If an error occurs during communication with a server, the connection will be passed to the next server, and so on until all of the functioning servers will be tried. If communication with all servers fails, the connection will be closed."},{"m":"ngx_stream_upstream_module","n":"server","d":"Defines the `_address_` and other `_parameters_` of a server. The address can be specified as a domain name or IP address with an obligatory port, or as a UNIX-domain socket path specified after the \u201c`unix:`\u201d prefix. A domain name that resolves to several IP addresses defines multiple servers at once.\\nThe following parameters can be defined:\\n`weight`\\\\=`_number_`\\n\\nsets the weight of the server, by default, 1.\\n\\n`max_conns`\\\\=`_number_`\\n\\nlimits the maximum `_number_` of simultaneous connections to the proxied server (1.11.5). Default value is zero, meaning there is no limit. If the server group does not reside in the [shared memory](#zone), the limitation works per each worker process.\\n\\n> Prior to version 1.11.5, this parameter was available as part of our [commercial subscription](http://nginx.com/products/).\\n\\n`max_fails`\\\\=`_number_`\\n\\nsets the number of unsuccessful attempts to communicate with the server that should happen in the duration set by the `fail_timeout` parameter to consider the server unavailable for a duration also set by the `fail_timeout` parameter. By default, the number of unsuccessful attempts is set to 1. The zero value disables the accounting of attempts. Here, an unsuccessful attempt is an error or timeout while establishing a connection with the server.\\n\\n`fail_timeout`\\\\=`_time_`\\n\\nsets\\n\\n*   the time during which the specified number of unsuccessful attempts to communicate with the server should happen to consider the server unavailable;\\n*   and the period of time the server will be considered unavailable.\\n\\nBy default, the parameter is set to 10 seconds.\\n\\n`backup`\\n\\nmarks the server as a backup server. Connections to the backup server will be passed when the primary servers are unavailable.\\n\\n> The parameter cannot be used along with the [hash](#hash) and [random](#random) load balancing methods.\\n\\n`down`\\n\\nmarks the server as permanently unavailable.\\n\\nAdditionally, the following parameters are available as part of our [commercial subscription](http://nginx.com/products/):\\n`resolve`\\n\\nmonitors changes of the IP addresses that correspond to a domain name of the server, and automatically modifies the upstream configuration without the need of restarting nginx. The server group must reside in the [shared memory](#zone).\\n\\nIn order for this parameter to work, the `resolver` directive must be specified in the [stream](ngx_stream_core_module.html#resolver) block or in the corresponding [upstream](#resolver) block.\\n\\n`service`\\\\=`_name_`\\n\\nenables resolving of DNS [SRV](https://tools.ietf.org/html/rfc2782) records and sets the service `_name_` (1.9.13). In order for this parameter to work, it is necessary to specify the [resolve](#resolve) parameter for the server and specify a hostname without a port number.\\n\\nIf the service name does not contain a dot (\u201c`.`\u201d), then the [RFC](https://tools.ietf.org/html/rfc2782)\\\\-compliant name is constructed and the TCP protocol is added to the service prefix. For example, to look up the `_http._tcp.backend.example.com` SRV record, it is necessary to specify the directive:\\n\\n> server backend.example.com service=http resolve;\\n\\nIf the service name contains one or more dots, then the name is constructed by joining the service prefix and the server name. For example, to look up the `_http._tcp.backend.example.com` and `server1.backend.example.com` SRV records, it is necessary to specify the directives:\\n\\n> server backend.example.com service=\\\\_http.\\\\_tcp resolve;\\n> server example.com service=server1.backend resolve;\\n\\nHighest-priority SRV records (records with the same lowest-number priority value) are resolved as primary servers, the rest of SRV records are resolved as backup servers. If the [backup](#backup) parameter is specified for the server, high-priority SRV records are resolved as backup servers, the rest of SRV records are ignored.\\n\\n`slow_start`\\\\=`_time_`\\n\\nsets the `_time_` during which the server will recover its weight from zero to a nominal value, when unhealthy server becomes [healthy](ngx_stream_upstream_hc_module.html#health_check), or when the server becomes available after a period of time it was considered [unavailable](#fail_timeout). Default value is zero, i.e. slow start is disabled.\\n\\n> The parameter cannot be used along with the [hash](#hash) and [random](#random) load balancing methods.\\n\\n\\nIf there is only a single server in a group, `max_fails`, `fail_timeout` and `slow_start` parameters are ignored, and such a server will never be considered unavailable.\\n"},{"m":"ngx_stream_upstream_module","n":"zone","d":"Defines the `_name_` and `_size_` of the shared memory zone that keeps the group\u2019s configuration and run-time state that are shared between worker processes. Several groups may share the same zone. In this case, it is enough to specify the `_size_` only once.\\nAdditionally, as part of our [commercial subscription](http://nginx.com/products/), such groups allow changing the group membership or modifying the settings of a particular server without the need of restarting nginx. The configuration is accessible via the [API](../http/ngx_http_api_module.html) module (1.13.3).\\nPrior to version 1.13.3, the configuration was accessible only via a special location handled by [upstream\\\\_conf](../http/ngx_http_upstream_conf_module.html#upstream_conf).\\n"},{"m":"ngx_stream_upstream_module","n":"state","d":"Specifies a `_file_` that keeps the state of the dynamically configurable group.\\nExamples:\\n```\\nstate /var/lib/nginx/state/servers.conf; # path for Linux\\nstate /var/db/nginx/state/servers.conf;  # path for FreeBSD\\n\\n```\\n\\nThe state is currently limited to the list of servers with their parameters. The file is read when parsing the configuration and is updated each time the upstream configuration is [changed](../http/ngx_http_api_module.html#stream_upstreams_stream_upstream_name_servers_). Changing the file content directly should be avoided. The directive cannot be used along with the [server](#server) directive.\\n\\nChanges made during [configuration reload](../control.html#reconfiguration) or [binary upgrade](../control.html#upgrade) can be lost.\\n\\n\\nThis directive is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_stream_upstream_module","n":"hash","d":"Specifies a load balancing method for a server group where the client-server mapping is based on the hashed `_key_` value. The `_key_` can contain text, variables, and their combinations (1.11.2). Usage example:\\n```\\nhash $remote_addr;\\n\\n```\\nNote that adding or removing a server from the group may result in remapping most of the keys to different servers. The method is compatible with the [Cache::Memcached](https://metacpan.org/pod/Cache::Memcached) Perl library.\\nIf the `consistent` parameter is specified, the [ketama](https://www.metabrew.com/article/libketama-consistent-hashing-algo-memcached-clients) consistent hashing method will be used instead. The method ensures that only a few keys will be remapped to different servers when a server is added to or removed from the group. This helps to achieve a higher cache hit ratio for caching servers. The method is compatible with the [Cache::Memcached::Fast](https://metacpan.org/pod/Cache::Memcached::Fast) Perl library with the `_ketama_points_` parameter set to 160."},{"m":"ngx_stream_upstream_module","n":"least_conn","d":"Specifies that a group should use a load balancing method where a connection is passed to the server with the least number of active connections, taking into account weights of servers. If there are several such servers, they are tried in turn using a weighted round-robin balancing method."},{"m":"ngx_stream_upstream_module","n":"least_time","d":"Specifies that a group should use a load balancing method where a connection is passed to the server with the least average time and least number of active connections, taking into account weights of servers. If there are several such servers, they are tried in turn using a weighted round-robin balancing method.\\nIf the `connect` parameter is specified, time to [connect](#var_upstream_connect_time) to the upstream server is used. If the `first_byte` parameter is specified, time to receive the [first byte](#var_upstream_first_byte_time) of data is used. If the `last_byte` is specified, time to receive the [last byte](#var_upstream_session_time) of data is used. If the `inflight` parameter is specified (1.11.6), incomplete connections are also taken into account.\\nPrior to version 1.11.6, incomplete connections were taken into account by default.\\n\\n\\nThis directive is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_stream_upstream_module","n":"random","d":"Specifies that a group should use a load balancing method where a connection is passed to a randomly selected server, taking into account weights of servers.\\nThe optional `two` parameter instructs nginx to randomly select [two](https://homes.cs.washington.edu/~karlin/papers/balls.pdf) servers and then choose a server using the specified `method`. The default method is `least_conn` which passes a connection to a server with the least number of active connections."},{"m":"ngx_stream_upstream_module","n":"random_least_time","d":"The `least_time` method passes a connection to a server with the least average time and least number of active connections. If `least_time=connect` parameter is specified, time to [connect](#var_upstream_connect_time) to the upstream server is used. If `least_time=first_byte` parameter is specified, time to receive the [first byte](#var_upstream_first_byte_time) of data is used. If `least_time=last_byte` is specified, time to receive the [last byte](#var_upstream_session_time) of data is used.\\nThe `least_time` method is available as a part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_stream_upstream_module","n":"resolver","d":"Configures name servers used to resolve names of upstream servers into addresses, for example:\\n```\\nresolver 127.0.0.1 [::1]:5353;\\n\\n```\\nThe address can be specified as a domain name or IP address, with an optional port. If port is not specified, the port 53 is used. Name servers are queried in a round-robin fashion."},{"m":"ngx_stream_upstream_module","n":"resolver_ipv6","d":"By default, nginx will look up both IPv4 and IPv6 addresses while resolving. If looking up of IPv6 addresses is not desired, the `ipv6=off` parameter can be specified."},{"m":"ngx_stream_upstream_module","n":"resolver_valid","d":"By default, nginx caches answers using the TTL value of a response. The optional `valid` parameter allows overriding it:\\n```\\nresolver 127.0.0.1 [::1]:5353 valid=30s;\\n\\n```\\n\\nTo prevent DNS spoofing, it is recommended configuring DNS servers in a properly secured trusted local network.\\n"},{"m":"ngx_stream_upstream_module","n":"resolver_status_zone","d":"The optional `status_zone` parameter enables [collection](../http/ngx_http_api_module.html#resolvers_) of DNS server statistics of requests and responses in the specified `_zone_`.\\n\\nThis directive is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_stream_upstream_module","n":"resolver_timeout","d":"Sets a timeout for name resolution, for example:\\n```\\nresolver_timeout 5s;\\n\\n```\\n\\n\\nThis directive is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_stream_upstream_module","n":"$upstream_addr","d":"session duration in seconds with millisecond resolution (1.11.4). Times of several connections are separated by commas like addresses in the [$upstream\\\\_addr](#var_upstream_addr) variable."},{"m":"ngx_stream_upstream_module","n":"$upstream_bytes_received","d":"session duration in seconds with millisecond resolution (1.11.4). Times of several connections are separated by commas like addresses in the [$upstream\\\\_addr](#var_upstream_addr) variable."},{"m":"ngx_stream_upstream_module","n":"$upstream_bytes_sent","d":"session duration in seconds with millisecond resolution (1.11.4). Times of several connections are separated by commas like addresses in the [$upstream\\\\_addr](#var_upstream_addr) variable."},{"m":"ngx_stream_upstream_module","n":"$upstream_connect_time","d":"session duration in seconds with millisecond resolution (1.11.4). Times of several connections are separated by commas like addresses in the [$upstream\\\\_addr](#var_upstream_addr) variable."},{"m":"ngx_stream_upstream_module","n":"$upstream_first_byte_time","d":"session duration in seconds with millisecond resolution (1.11.4). Times of several connections are separated by commas like addresses in the [$upstream\\\\_addr](#var_upstream_addr) variable."},{"m":"ngx_stream_upstream_module","n":"$upstream_session_time","d":"session duration in seconds with millisecond resolution (1.11.4). Times of several connections are separated by commas like addresses in the [$upstream\\\\_addr](#var_upstream_addr) variable."},{"m":"ngx_stream_upstream_hc_module","n":"summary","d":"The `ngx_stream_upstream_hc_module` module (1.9.0) allows enabling periodic health checks of the servers in a [group](ngx_stream_upstream_module.html#upstream). The server group must reside in the [shared memory](ngx_stream_upstream_module.html#zone).\\nIf a health check fails, the server will be considered unhealthy. If several health checks are defined for the same group of servers, a single failure of any check will make the corresponding server be considered unhealthy. Client connections are not passed to unhealthy servers and servers in the \u201cchecking\u201d state.\\n\\nThis module is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_stream_upstream_hc_module","n":"health_check","d":"Enables periodic health checks of the servers in a [group](ngx_stream_upstream_module.html#upstream).\\nThe following optional parameters are supported:\\n`interval`\\\\=`_time_`\\n\\nsets the interval between two consecutive health checks, by default, 5 seconds.\\n\\n`jitter`\\\\=`_time_`\\n\\nsets the time within which each health check will be randomly delayed, by default, there is no delay.\\n\\n`fails`\\\\=`_number_`\\n\\nsets the number of consecutive failed health checks of a particular server after which this server will be considered unhealthy, by default, 1.\\n\\n`passes`\\\\=`_number_`\\n\\nsets the number of consecutive passed health checks of a particular server after which the server will be considered healthy, by default, 1.\\n\\n`mandatory`\\n\\nsets the initial \u201cchecking\u201d state for a server until the first health check is completed (1.11.7). Client connections are not passed to servers in the \u201cchecking\u201d state. If the parameter is not specified, the server will be initially considered healthy.\\n\\n`match`\\\\=`_name_`\\n\\nspecifies the `match` block configuring the tests that a successful connection should pass in order for a health check to pass. By default, for TCP, only the ability to establish a TCP connection with the server is checked. For [UDP](#health_check_udp), the absence of ICMP \u201c`Destination Unreachable`\u201d message is expected in reply to the sent string \u201c`nginx health check`\u201d.\\n\\n> Prior to version 1.11.7, by default, UDP health check required a [match](#hc_match) block with the [send](#match_send) and [expect](#match_expect) parameters.\\n\\n`port`\\\\=`_number_`\\n\\ndefines the port used when connecting to a server to perform a health check (1.9.7). By default, equals the [server](ngx_stream_upstream_module.html#server) port.\\n\\n`udp`\\n\\nspecifies that the `UDP` protocol should be used for health checks instead of the default `TCP` protocol (1.9.13).\\n"},{"m":"ngx_stream_upstream_hc_module","n":"health_check_timeout","d":"Overrides the [proxy\\\\_timeout](ngx_stream_proxy_module.html#proxy_timeout) value for health checks."},{"m":"ngx_stream_zone_sync_module","n":"summary","d":"The `ngx_stream_zone_sync_module` module (1.13.8) provides the necessary support for synchronizing contents of [shared memory zones](ngx_stream_upstream_module.html#zone) between nodes of a cluster. To enable synchronization for a particular zone, a corresponding module must support this feature. Currently, it is possible to synchronize HTTP [sticky](../http/ngx_http_upstream_module.html#sticky) sessions, information about [excessive HTTP requests](../http/ngx_http_limit_req_module.html), and key-value pairs both in [http](../http/ngx_http_keyval_module.html) and [stream](../stream/ngx_stream_keyval_module.html).\\n\\nThis module is available as part of our [commercial subscription](http://nginx.com/products/).\\n"},{"m":"ngx_stream_zone_sync_module","n":"zone_sync","d":"Enables the synchronization of shared memory zones between cluster nodes. Cluster nodes are defined using [zone\\\\_sync\\\\_server](#zone_sync_server) directives."},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_buffers","d":"Sets the `_number_` and `_size_` of the per-zone buffers used for pushing zone contents. By default, the buffer size is equal to one memory page. This is either 4K or 8K, depending on a platform.\\n\\nA single buffer must be large enough to hold any entry of each zone being synchronized.\\n"},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_connect_retry_interval","d":"Defines an interval between connection attempts to another cluster node."},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_connect_timeout","d":"Defines a timeout for establishing a connection with another cluster node."},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_interval","d":"Defines an interval for polling updates in a shared memory zone."},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_recv_buffer_size","d":"Sets `_size_` of a per-connection receive buffer used to parse incoming stream of synchronization messages. The buffer size must be equal or greater than one of the [zone\\\\_sync\\\\_buffers](#zone_sync_buffers). By default, the buffer size is equal to [zone\\\\_sync\\\\_buffers](#zone_sync_buffers) `_size_` multiplied by `_number_`."},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_server","d":"Defines the `_address_` of a cluster node. The address can be specified as a domain name or IP address with a mandatory port, or as a UNIX-domain socket path specified after the \u201c`unix:`\u201d prefix. A domain name that resolves to several IP addresses defines multiple nodes at once."},{"m":"ngx_stream_zone_sync_module","n":"resolve","d":"The `resolve` parameter instructs nginx to monitor changes of the IP addresses that correspond to a domain name of the node and automatically modify the configuration without the need of restarting nginx.\\nCluster nodes are specified either dynamically as a single `zone_sync_server` directive with the `resolve` parameter, or statically as a series of several directives without the parameter.\\nEach cluster node should be specified only once.\\n\\nAll cluster nodes should use the same configuration.\\n\\nIn order for the `resolve` parameter to work, the [resolver](ngx_stream_core_module.html#resolver) directive must be specified in the [stream](ngx_stream_core_module.html#stream) block. Example:\\n```\\nstream {\\n    resolver 10.0.0.1;\\n\\n    server {\\n        zone_sync;\\n        zone_sync_server cluster.example.com:12345 resolve;\\n        ...\\n    }\\n}\\n\\n```\\n"},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_ssl","d":"Enables the SSL/TLS protocol for connections to another cluster server."},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_ssl_certificate","d":"Specifies a `_file_` with the certificate in the PEM format used for authentication to another cluster server."},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_ssl_certificate_key","d":"Specifies a `_file_` with the secret key in the PEM format used for authentication to another cluster server."},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_ssl_ciphers","d":"Specifies the enabled ciphers for connections to another cluster server. The ciphers are specified in the format understood by the OpenSSL library.\\nThe full list can be viewed using the \u201c`openssl ciphers`\u201d command."},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_ssl_conf_command","d":"Sets arbitrary OpenSSL configuration [commands](https://www.openssl.org/docs/man1.1.1/man3/SSL_CONF_cmd.html) when establishing a connection with another cluster server.\\nThe directive is supported when using OpenSSL 1.0.2 or higher.\\n\\nSeveral `zone_sync_ssl_conf_command` directives can be specified on the same level. These directives are inherited from the previous configuration level if and only if there are no `zone_sync_ssl_conf_command` directives defined on the current level.\\n\\nNote that configuring OpenSSL directly might result in unexpected behavior.\\n"},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_ssl_crl","d":"Specifies a `_file_` with revoked certificates (CRL) in the PEM format used to [verify](#zone_sync_ssl_verify) the certificate of another cluster server."},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_ssl_name","d":"Allows overriding the server name used to [verify](#zone_sync_ssl_verify) the certificate of a cluster server and to be [passed through SNI](#zone_sync_ssl_server_name) when establishing a connection with the cluster server.\\nBy default, the host part of the [zone\\\\_sync\\\\_server](#zone_sync_server) address is used, or resolved IP address if the [resolve](#resolve) parameter is specified."},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_ssl_password_file","d":"Specifies a `_file_` with passphrases for [secret keys](#zone_sync_ssl_certificate_key) where each passphrase is specified on a separate line. Passphrases are tried in turn when loading the key."},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_ssl_protocols","d":"Enables the specified protocols for connections to another cluster server."},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_ssl_server_name","d":"Enables or disables passing of the server name through [TLS Server Name Indication extension](http://en.wikipedia.org/wiki/Server_Name_Indication) (SNI, RFC 6066) when establishing a connection with another cluster server."},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_ssl_trusted_certificate","d":"Specifies a `_file_` with trusted CA certificates in the PEM format used to [verify](#zone_sync_ssl_verify) the certificate of another cluster server."},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_ssl_verify","d":"Enables or disables verification of another cluster server certificate."},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_ssl_verify_depth","d":"Sets the verification depth in another cluster server certificates chain."},{"m":"ngx_stream_zone_sync_module","n":"zone_sync_timeout","d":"Sets the `_timeout_` between two successive read or write operations on connection to another cluster node. If no data is transmitted within this time, the connection is closed."},{"m":"ngx_stream_zone_sync_module","n":"stream_zone_sync_status","d":"#### API endpoints\\nThe synchronization status of a node is available via the [/stream/zone\\\\_sync/](../http/ngx_http_api_module.html#stream_zone_sync_) endpoint of the API which returns the [following](../http/ngx_http_api_module.html#def_nginx_stream_zone_sync) metrics."},{"m":"ngx_google_perftools_module","n":"summary","d":"The `ngx_google_perftools_module` module (0.6.29) enables profiling of nginx worker processes using [Google Performance Tools](https://github.com/gperftools/gperftools). The module is intended for nginx developers.\\nThis module is not built by default, it should be enabled with the `--with-google_perftools_module` configuration parameter.\\nThis module requires the [gperftools](https://github.com/gperftools/gperftools) library.\\n"}]')},237:function(e,t,n){e.exports={header:"Header_header__358aw",title:"Header_title__2UH-p",filename:"Header_filename__1Bl32"}},292:function(e,t,n){e.exports={button:"LoadFile_button__1Rr5N"}},370:function(e,t,n){},373:function(e,t,n){"use strict";n.r(t);var s=n(115),r=n.n(s),i=n(291),o=n.n(i),a=n(21),l=n(293),d=n(237),h=n.n(d),c=n(292),m=n.n(c),u=n(90);function _(e){var t=e.onLoadContent,n=Object(s.useRef)(null),r=Object(s.useRef)(new FileReader),i=Object(s.useRef)();function o(e){var t=e.target;t.files&&t.files[0]&&(i.current=t.files[0],r.current.readAsText(t.files[0]))}return Object(s.useEffect)((function(){var e=n.current;return e&&(r.current.onload=function(e){e.target&&e.target.result&&t&&t(e.target.result.toString(),e,i.current)},e.addEventListener("change",o,!1)),function(){e&&e.removeEventListener("change",o,!1)}}),[]),Object(u.jsxs)("button",{onClick:function(){n.current.click()},className:m.a.button,children:[Object(u.jsx)("input",{type:"file",multiple:!1,ref:n,accept:"text/conf",style:{display:"none"}}),"Open..."]})}var p=function(){return Object(u.jsx)("svg",{viewBox:"0 0 1024 1024",width:"18",height:"18",children:Object(u.jsx)("path",{fill:"currentColor",d:"M512 0L68.48 256v512L512 1024l443.52-256V256L512 0z m256 707.84c0 30.08-27.562667 55.04-65.237333 55.04-26.922667 0-57.642667-10.88-76.842667-34.56l-256-304.682667v284.16c0 30.762667-24.32 55.04-54.357333 55.04H312.32c-30.762667 0-55.04-25.6-55.04-55.04V316.16c0-30.08 26.88-55.04 64-55.04 27.562667 0 58.88 10.88 78.08 34.56l254.72 304.682667V316.16c0-30.762667 25.6-55.04 55.04-55.04h3.2c30.72 0 55.04 25.6 55.04 55.04v391.68H768z"})})},f=function(){return Object(u.jsx)("svg",{viewBox:"0 0 1024 1024",width:"18",height:"18",children:Object(u.jsx)("path",{fill:"currentColor",d:"M512 0C229.12 0 0 229.12 0 512c0 226.56 146.56 417.92 350.08 485.76 25.6 4.48 35.2-10.88 35.2-24.32 0-12.16-0.64-52.48-0.64-95.36-128.64 23.68-161.92-31.36-172.16-60.16-5.76-14.72-30.72-60.16-52.48-72.32-17.92-9.6-43.52-33.28-0.64-33.92 40.32-0.64 69.12 37.12 78.72 52.48 46.08 77.44 119.68 55.68 149.12 42.24 4.48-33.28 17.92-55.68 32.64-68.48-113.92-12.8-232.96-56.96-232.96-252.8 0-55.68 19.84-101.76 52.48-137.6-5.12-12.8-23.04-65.28 5.12-135.68 0 0 42.88-13.44 140.8 52.48 40.96-11.52 84.48-17.28 128-17.28 43.52 0 87.04 5.76 128 17.28 97.92-66.56 140.8-52.48 140.8-52.48 28.16 70.4 10.24 122.88 5.12 135.68 32.64 35.84 52.48 81.28 52.48 137.6 0 196.48-119.68 240-233.6 252.8 18.56 16 34.56 46.72 34.56 94.72 0 68.48-0.64 123.52-0.64 140.8 0 13.44 9.6 29.44 35.2 24.32A512.832 512.832 0 0 0 1024 512C1024 229.12 794.88 0 512 0z"})})};function g(e){var t=e.onLoadContent,n=Object(s.useState)("nginx.example.conf"),r=Object(a.a)(n,2),i=r[0],o=r[1];return Object(u.jsxs)("div",{className:h.a.header,children:[Object(u.jsx)(p,{}),Object(u.jsx)("div",{className:h.a.title,children:"nginx editor"}),Object(u.jsx)("div",{className:h.a.filename,children:i}),Object(u.jsx)(_,{onLoadContent:function(e,n,s){o(s.name||""),t&&t(e,n)}}),Object(u.jsx)("a",{href:"https://github.com/jaywcjlove/nginx-editor",target:"__blank",children:Object(u.jsx)(f,{})})]})}n(370);var v=n(100),b=n(294),y=n(236);function x(e){return[].concat(Object(b.a)(function(e){return y.map((function(t){return{label:t.n,kind:v.languages.CompletionItemKind.Keyword,insertText:t.n,documentation:t.d,range:e}}))}(e)),[{label:"upstream",kind:v.languages.CompletionItemKind.Snippet,insertText:["upstream ${1:upstream_name} {","\tserver ${0:127.0.0.1:3110};","}"].join("\n"),insertTextRules:v.languages.CompletionItemInsertTextRule.InsertAsSnippet,detail:"Upstream Example",range:e},{label:"proxy_pass",kind:v.languages.CompletionItemKind.Snippet,insertText:["proxy_pass    ${1:http}://${0192.168.188.222:32001};"].join("\n"),insertTextRules:v.languages.CompletionItemInsertTextRule.InsertAsSnippet,detail:"proxy_pass Example",range:e},{label:"location",kind:v.languages.CompletionItemKind.Snippet,insertText:["location ${1:/} {\n\t${0}\n}"].join("\n"),insertTextRules:v.languages.CompletionItemInsertTextRule.InsertAsSnippet,detail:"proxy_pass Example",range:e}])}v.languages.register({id:"nginx"}),v.languages.setLanguageConfiguration("nginx",{autoClosingPairs:[{open:"{",close:"}"},{open:'"',close:'"'}]}),v.languages.setMonarchTokensProvider("nginx",{defaultToken:"source",ignoreCase:!0,brackets:[{open:"{",close:"}",token:"delimiter.bracket"}],tokenizer:{root:[[/(")/,"delimiter.bracket"],[/[;,.]/,"delimiter"],[/\\.* |~|~\*|!~|!~\*/,"string.regexp"],[/\b\d+\w+\b/,"number"],[/\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}(:\d{1,5})?\b/,"number"],[/\b(ip_hash|upstream|server)\b/,"http.upstream"],[/\b(add_header|expires|server_tokens)\b/,"http.headers"],[/\b(map|map_hash_max_size|map_hash_bucket_size)\b/,"module.http"],[/\b(http)\b/,"module.http"],[/\b(gzip|gzip_buffers|gzip_comp_level|gzip_disable|gzip_http.version|gzip_min_length|gzip_proxied|gzip_types|gzip_vary)\b/,"module.http"],[/\b(on|off)\b/,"module.main"],[/\b(access_log|log_format)\b/,"module.log"],[/\b(proxy_buffer_size|proxy_buffering|proxy_buffers|proxy_busy_buffers_size|proxy_cache|proxy_cache_background_update|proxy_cache_bypass|proxy_cache_convert_head|proxy_cache_key|proxy_cache_lock|proxy_cache_lock_age|proxy_cache_lock_timeout|proxy_cache_max_range_offset|proxy_cache_methods|proxy_cache_min_uses|proxy_cache_path|proxy_cache_purge|proxy_cache_revalidate|proxy_cache_use_stale|proxy_cache_valid|proxy_connect_timeout|proxy_headers_hash_bucket_size|proxy_headers_hash_max_size|proxy_hide_header|proxy_http_version|proxy_ignore_client_abort|proxy_intercept_errors|proxy_max_temp_file_size|proxy_method|proxy_next_upstream|proxy_next_upstream_tries|proxy_next_upstream_timeout|proxy_pass|proxy_pass_header|proxy_pass_request_body|proxy_pass_request_headers|proxy_read_timeout|proxy_redirect|proxy_redirect_errors|proxy_send_lowat|proxy_send_timeout|proxy_set_body|proxy_set_header|proxy_store|proxy_store_access|proxy_temp_file_write_size|proxy_t|emp_pathproxy_upstream_fail_timeout|proxy_upstream_max_fails)\b/,"http.proxy"],[/\b(ssl|ssl_buffer_size|ssl_certificate|ssl_certificate_key|ssl_ciphers|ssl_client_certificate|ssl_crl|ssl_dhparam|ssl_ecdh_curve|ssl_password_file|ssl_prefer_server_ciphers|ssl_protocols|ssl_session_cache|ssl_session_ticket_key|ssl_session_tickets|ssl_session_timeout|ssl_stapling|ssl_stapling_file|ssl_stapling_responder|ssl_stapling_verify|ssl_trusted_certificate|ssl_verify_client|ssl_verify_depth)\b/,"module.http"],[/\b(daemon|env|debug_points|error_log|log_not_found|include|lock_file|master_process|pid|ssl_engine|timer_resolution|types_hash_max_size|user|worker_cpu_affinity|worker_priority|worker_processes|worker_rlimit_core|worker_rlimit_nofile|worker_rlimit_sigpending|working_directory|try_files)\b/,"module.main"],[/\b(alias|chunked_transfer_encoding|client_body_in_file_only|client_body_buffer_size|client_body_temp_path|client_body_timeout|client_header_buffer_size|client_header_timeout|client_max_body_size|default_type|error_page|index |internal|keepalive_timeout|keepalive_requests|large_client_header_buffers|limit_except|limit_rate|listen|location|msie_padding|msie_refresh|optimize_server_names|port_in_redirect|recursive_error_pages|reset_timedout_connection|resolver|resolver_timeout|root|satisfy_any|send_timeout|sendfile|server|server_name|server_names_hash_max_size|server_names_hash_bucket_size|tcp_nodelay|tcp_nopush|types |try_files)\b/,"module.http"],[/\b(accept_mutex|accept_mutex_delay|debug_connection|devpoll_changes|devpoll_events|epoll_events|kqueue_changes|kqueue_events|multi_accept|rtsig_signo|rtsig_overflow_events|rtsig_overflow_test|rtsig_overflow_threshold|use|worker_connections)\b/,"module.events"],[/\b(add_before_body|add_after_body|addition_types)\b/,"module.http.addition"],[/\b(events)\b/,"module.events"],[/\b(fastcgi_index|fastcgi_hide_header|fastcgi_ignore_client_abort|fastcgi_intercept_errors|fastcgi_param|fastcgi_pass|fastcgi_pass_header|fastcgi_read_timeout|fastcgi_redirect_errors|fa|stcgi_storefastcgi_store_access|fastcgi_buffers|fastcgi_buffers_size|fastcgi_temp_path|fastcgi_buffer_size|fastcgi_connect_timeout|fastcgi_send_timeout|fastcgi_split_path_info)\b/,"module.http"],[/\$\w+/,"variable"],[/#.*$/,"comment"]],comment:[[/#.*$/,"comment"]],numbers:[["-?(\\d*\\.)?\\d+([eE][\\-+]?\\d+)?",{token:"attribute.value.number",next:"@units"}],["#[0-9a-fA-F_]+(?!\\w)","attribute.value.hex"]],units:[["(M)?","attribute.value.unit","@pop"]]}}),v.editor.defineTheme("nginx-theme",{colors:{},base:"vs-dark",inherit:!0,rules:[{token:"module.http",foreground:"#00bbbb"},{token:"module.events",foreground:"#00bbbb"},{token:"http.headers",foreground:"#00bbbb"},{token:"http.proxy",foreground:"#58f18e"},{token:"module.main",foreground:"#c152e4",fontStyle:"bold"},{token:"module.log",foreground:"#4d6aab"},{token:"module.http.addition",foreground:"#c152e4"},{token:"keywords",foreground:"#9effff",fontStyle:"bold"},{token:"http.upstream",foreground:"#0078d0",fontStyle:"bold"},{token:"identifier",foreground:"#8e44ad"},{token:"delimiter.bracket",foreground:"#737373"},{token:"delimiter",foreground:"#737373"}]}),v.languages.registerCompletionItemProvider("nginx",{provideCompletionItems:function(e,t){var n=e.getWordUntilPosition(t);return{suggestions:x({startLineNumber:t.lineNumber,endLineNumber:t.lineNumber,startColumn:n.startColumn,endColumn:n.endColumn})}}}),v.languages.registerHoverProvider("nginx",{provideHover:function(e,t,n){var s=e.getWordAtPosition(t);if(s){var r=y.find((function(e){return e.n===s.word||e.n==="$".concat(s.word)}));if(r){var i={startLineNumber:t.lineNumber,endLineNumber:t.lineNumber,startColumn:s.startColumn,endColumn:s.endColumn};return{contents:[{value:"**`".concat(r.n,"`** ").concat(r.m)},{value:"".concat(r.d)}],range:i}}}}});var w=function(){var e=Object(s.useState)('user       www www;  ## Default: nobody\nworker_processes  5;  ## Default: 1\nerror_log  logs/error.log;\npid        logs/nginx.pid;\nworker_rlimit_nofile 8192;\n\nevents {\n  worker_connections  4096;  ## Default: 1024\n}\n\nhttp {\n  include    conf/mime.types;\n  include    /etc/nginx/proxy.conf;\n  include    /etc/nginx/fastcgi.conf;\n  index    index.html index.htm index.php;\n\n  default_type application/octet-stream;\n  log_format   main \'$remote_addr - $remote_user [$time_local]  $status \'\n    \'"$request" $body_bytes_sent "$http_referer" \'\n    \'"$http_user_agent" "$http_x_forwarded_for"\';\n  access_log   logs/access.log  main;\n  sendfile     on;\n  tcp_nopush   on;\n  server_names_hash_bucket_size 128; # this seems to be required for some vhosts\n\n  server { # php/fastcgi\n    listen       80;\n    server_name  domain1.com www.domain1.com;\n    access_log   logs/domain1.access.log  main;\n    root         html;\n\n    location ~ \\.php$ {\n      fastcgi_pass   127.0.0.1:1025;\n    }\n  }\n\n  server { # simple reverse-proxy\n    listen       80;\n    server_name  domain2.com www.domain2.com;\n    access_log   logs/domain2.access.log  main;\n\n    # serve static files\n    location ~ ^/(images|javascript|js|css|flash|media|static)/  {\n      root    /var/www/virtual/big.server.com/htdocs;\n      expires 30d;\n    }\n\n    # pass requests for dynamic content to rails/turbogears/zope, et al\n    location / {\n      proxy_pass      http://127.0.0.1:8080;\n    }\n  }\n\n  upstream big_server_com {\n    server 127.0.0.3:8000 weight=5;\n    server 127.0.0.3:8001 weight=5;\n    server 192.168.0.1:8000;\n    server 192.168.0.1:8001;\n  }\n\n  server { # simple load balancing\n    listen          80;\n    server_name     big.server.com;\n    access_log      logs/big.server.access.log main;\n\n    location / {\n      proxy_pass      http://big_server_com;\n    }\n  }\n}'),t=Object(a.a)(e,2),n=t[0],i=t[1],o=r.a.useRef();function d(e){var t=e.target,n=t.innerWidth,s=t.innerHeight;o.current&&o.current.editor&&o.current.editor.layout({width:n,height:s-36})}return Object(s.useEffect)((function(){return o.current&&o.current.editor&&window&&window.addEventListener("resize",d,!1),function(){window&&window.removeEventListener("resize",d,!1)}}),[]),Object(u.jsxs)("div",{className:"App",children:[Object(u.jsx)(g,{onLoadContent:function(e){i(e)}}),Object(u.jsx)(l.a,{ref:function(e){e&&(o.current=e)},theme:"nginx-theme",language:"nginx",value:n,height:"calc(100vh - 36px)",options:{theme:"vs-dark"}})]})};o.a.render(Object(u.jsx)(w,{}),document.getElementById("root"))}},[[373,3,4]]]);
//# sourceMappingURL=main.1e5ff5b8.chunk.js.map